{
  "testsource": {
    "overall": {
      "total_comparisons": 27252,
      "line0_exact_matches": 0,
      "line0_exact_match_rate": 0.0,
      "proximity_matches": 0,
      "proximity_match_rate": 0.0,
      "avg_levenshtein": 38.63,
      "avg_edit_similarity": 0.12,
      "avg_first_line_edit_similarity": 0.12,
      "avg_cosine": 0.0
    },
    "categories": {
      "api_usage": {
        "total_comparisons": 4500,
        "line0_exact_matches": 0,
        "line0_exact_match_rate": 0.0,
        "proximity_matches": 0,
        "proximity_match_rate": 0.0,
        "avg_levenshtein": 43.97,
        "avg_edit_similarity": 0.13,
        "avg_first_line_edit_similarity": 0.13,
        "avg_cosine": 0.0
      },
      "code2NL_NL2code": {
        "total_comparisons": 4500,
        "line0_exact_matches": 0,
        "line0_exact_match_rate": 0.0,
        "proximity_matches": 0,
        "proximity_match_rate": 0.0,
        "avg_levenshtein": 36.32,
        "avg_edit_similarity": 0.06,
        "avg_first_line_edit_similarity": 0.06,
        "avg_cosine": 0.0
      },
      "code_purpose_understanding": {
        "total_comparisons": 4500,
        "line0_exact_matches": 0,
        "line0_exact_match_rate": 0.0,
        "proximity_matches": 0,
        "proximity_match_rate": 0.0,
        "avg_levenshtein": 43.31,
        "avg_edit_similarity": 0.14,
        "avg_first_line_edit_similarity": 0.14,
        "avg_cosine": 0.0
      },
      "low_context": {
        "total_comparisons": 4452,
        "line0_exact_matches": 0,
        "line0_exact_match_rate": 0.0,
        "proximity_matches": 0,
        "proximity_match_rate": 0.0,
        "avg_levenshtein": 29.73,
        "avg_edit_similarity": 0.11,
        "avg_first_line_edit_similarity": 0.12,
        "avg_cosine": 0.0
      },
      "pattern_matching": {
        "total_comparisons": 4500,
        "line0_exact_matches": 0,
        "line0_exact_match_rate": 0.0,
        "proximity_matches": 0,
        "proximity_match_rate": 0.0,
        "avg_levenshtein": 41.18,
        "avg_edit_similarity": 0.15,
        "avg_first_line_edit_similarity": 0.15,
        "avg_cosine": 0.0
      },
      "syntax_completion": {
        "total_comparisons": 4500,
        "line0_exact_matches": 0,
        "line0_exact_match_rate": 0.0,
        "proximity_matches": 0,
        "proximity_match_rate": 0.0,
        "avg_levenshtein": 37.5,
        "avg_edit_similarity": 0.13,
        "avg_first_line_edit_similarity": 0.13,
        "avg_cosine": 0.0
      },
      "dogfood/idiomatic": {
        "total_comparisons": 75,
        "line0_exact_matches": 0,
        "line0_exact_match_rate": 0.0,
        "proximity_matches": 0,
        "proximity_match_rate": 0.0,
        "avg_levenshtein": 30.8,
        "avg_edit_similarity": 0.12,
        "avg_first_line_edit_similarity": 0.12,
        "avg_cosine": 0.0
      },
      "dogfood/nl2code": {
        "total_comparisons": 105,
        "line0_exact_matches": 0,
        "line0_exact_match_rate": 0.0,
        "proximity_matches": 0,
        "proximity_match_rate": 0.0,
        "avg_levenshtein": 35.43,
        "avg_edit_similarity": 0.12,
        "avg_first_line_edit_similarity": 0.12,
        "avg_cosine": 0.0
      },
      "dogfood/organization": {
        "total_comparisons": 120,
        "line0_exact_matches": 0,
        "line0_exact_match_rate": 0.0,
        "proximity_matches": 0,
        "proximity_match_rate": 0.0,
        "avg_levenshtein": 35.12,
        "avg_edit_similarity": 0.07,
        "avg_first_line_edit_similarity": 0.07,
        "avg_cosine": 0.0
      }
    },
    "languages": {
      "cpp": {
        "total_comparisons": 4500,
        "line0_exact_matches": 0,
        "line0_exact_match_rate": 0.0,
        "proximity_matches": 0,
        "proximity_match_rate": 0.0,
        "avg_levenshtein": 37.14,
        "avg_edit_similarity": 0.12,
        "avg_first_line_edit_similarity": 0.12,
        "avg_cosine": 0.0
      },
      "c_sharp": {
        "total_comparisons": 4500,
        "line0_exact_matches": 0,
        "line0_exact_match_rate": 0.0,
        "proximity_matches": 0,
        "proximity_match_rate": 0.0,
        "avg_levenshtein": 43.36,
        "avg_edit_similarity": 0.13,
        "avg_first_line_edit_similarity": 0.13,
        "avg_cosine": 0.0
      },
      "java": {
        "total_comparisons": 4500,
        "line0_exact_matches": 0,
        "line0_exact_match_rate": 0.0,
        "proximity_matches": 0,
        "proximity_match_rate": 0.0,
        "avg_levenshtein": 41.37,
        "avg_edit_similarity": 0.12,
        "avg_first_line_edit_similarity": 0.12,
        "avg_cosine": 0.0
      },
      "javascript": {
        "total_comparisons": 4500,
        "line0_exact_matches": 0,
        "line0_exact_match_rate": 0.0,
        "proximity_matches": 0,
        "proximity_match_rate": 0.0,
        "avg_levenshtein": 37.42,
        "avg_edit_similarity": 0.12,
        "avg_first_line_edit_similarity": 0.12,
        "avg_cosine": 0.0
      },
      "python": {
        "total_comparisons": 4752,
        "line0_exact_matches": 0,
        "line0_exact_match_rate": 0.0,
        "proximity_matches": 0,
        "proximity_match_rate": 0.0,
        "avg_levenshtein": 32.87,
        "avg_edit_similarity": 0.12,
        "avg_first_line_edit_similarity": 0.12,
        "avg_cosine": 0.0
      },
      "typescript": {
        "total_comparisons": 4500,
        "line0_exact_matches": 0,
        "line0_exact_match_rate": 0.0,
        "proximity_matches": 0,
        "proximity_match_rate": 0.0,
        "avg_levenshtein": 39.97,
        "avg_edit_similarity": 0.12,
        "avg_first_line_edit_similarity": 0.12,
        "avg_cosine": 0.0
      }
    }
  },
  "language": {
    "overall": {
      "total_comparisons": 27252,
      "line0_exact_matches": 0,
      "line0_exact_match_rate": 0.0,
      "proximity_matches": 719,
      "proximity_match_rate": 2.64,
      "avg_levenshtein": 38.42,
      "avg_edit_similarity": 0.07,
      "avg_first_line_edit_similarity": 0.07,
      "avg_cosine": 0.0
    },
    "categories": {
      "api_usage": {
        "total_comparisons": 4500,
        "line0_exact_matches": 0,
        "line0_exact_match_rate": 0.0,
        "proximity_matches": 120,
        "proximity_match_rate": 2.67,
        "avg_levenshtein": 46.92,
        "avg_edit_similarity": 0.07,
        "avg_first_line_edit_similarity": 0.07,
        "avg_cosine": 0.0
      },
      "code2NL_NL2code": {
        "total_comparisons": 4500,
        "line0_exact_matches": 0,
        "line0_exact_match_rate": 0.0,
        "proximity_matches": 45,
        "proximity_match_rate": 1.0,
        "avg_levenshtein": 28.84,
        "avg_edit_similarity": 0.05,
        "avg_first_line_edit_similarity": 0.05,
        "avg_cosine": 0.0
      },
      "code_purpose_understanding": {
        "total_comparisons": 4500,
        "line0_exact_matches": 0,
        "line0_exact_match_rate": 0.0,
        "proximity_matches": 135,
        "proximity_match_rate": 3.0,
        "avg_levenshtein": 44.2,
        "avg_edit_similarity": 0.07,
        "avg_first_line_edit_similarity": 0.07,
        "avg_cosine": 0.0
      },
      "low_context": {
        "total_comparisons": 4452,
        "line0_exact_matches": 0,
        "line0_exact_match_rate": 0.0,
        "proximity_matches": 14,
        "proximity_match_rate": 0.31,
        "avg_levenshtein": 29.23,
        "avg_edit_similarity": 0.06,
        "avg_first_line_edit_similarity": 0.07,
        "avg_cosine": 0.0
      },
      "pattern_matching": {
        "total_comparisons": 4500,
        "line0_exact_matches": 0,
        "line0_exact_match_rate": 0.0,
        "proximity_matches": 360,
        "proximity_match_rate": 8.0,
        "avg_levenshtein": 44.54,
        "avg_edit_similarity": 0.07,
        "avg_first_line_edit_similarity": 0.07,
        "avg_cosine": 0.0
      },
      "syntax_completion": {
        "total_comparisons": 4500,
        "line0_exact_matches": 0,
        "line0_exact_match_rate": 0.0,
        "proximity_matches": 30,
        "proximity_match_rate": 0.67,
        "avg_levenshtein": 37.52,
        "avg_edit_similarity": 0.07,
        "avg_first_line_edit_similarity": 0.07,
        "avg_cosine": 0.0
      },
      "dogfood/idiomatic": {
        "total_comparisons": 75,
        "line0_exact_matches": 0,
        "line0_exact_match_rate": 0.0,
        "proximity_matches": 15,
        "proximity_match_rate": 20.0,
        "avg_levenshtein": 21.6,
        "avg_edit_similarity": 0.2,
        "avg_first_line_edit_similarity": 0.2,
        "avg_cosine": 0.0
      },
      "dogfood/nl2code": {
        "total_comparisons": 105,
        "line0_exact_matches": 0,
        "line0_exact_match_rate": 0.0,
        "proximity_matches": 0,
        "proximity_match_rate": 0.0,
        "avg_levenshtein": 36.43,
        "avg_edit_similarity": 0.07,
        "avg_first_line_edit_similarity": 0.07,
        "avg_cosine": 0.0
      },
      "dogfood/organization": {
        "total_comparisons": 120,
        "line0_exact_matches": 0,
        "line0_exact_match_rate": 0.0,
        "proximity_matches": 0,
        "proximity_match_rate": 0.0,
        "avg_levenshtein": 19.12,
        "avg_edit_similarity": 0.02,
        "avg_first_line_edit_similarity": 0.02,
        "avg_cosine": 0.0
      }
    },
    "languages": {
      "cpp": {
        "total_comparisons": 4500,
        "line0_exact_matches": 0,
        "line0_exact_match_rate": 0.0,
        "proximity_matches": 240,
        "proximity_match_rate": 5.33,
        "avg_levenshtein": 37.83,
        "avg_edit_similarity": 0.03,
        "avg_first_line_edit_similarity": 0.03,
        "avg_cosine": 0.0
      },
      "c_sharp": {
        "total_comparisons": 4500,
        "line0_exact_matches": 0,
        "line0_exact_match_rate": 0.0,
        "proximity_matches": 30,
        "proximity_match_rate": 0.67,
        "avg_levenshtein": 44.94,
        "avg_edit_similarity": 0.08,
        "avg_first_line_edit_similarity": 0.08,
        "avg_cosine": 0.0
      },
      "java": {
        "total_comparisons": 4500,
        "line0_exact_matches": 0,
        "line0_exact_match_rate": 0.0,
        "proximity_matches": 315,
        "proximity_match_rate": 7.0,
        "avg_levenshtein": 43.51,
        "avg_edit_similarity": 0.03,
        "avg_first_line_edit_similarity": 0.03,
        "avg_cosine": 0.0
      },
      "javascript": {
        "total_comparisons": 4500,
        "line0_exact_matches": 0,
        "line0_exact_match_rate": 0.0,
        "proximity_matches": 0,
        "proximity_match_rate": 0.0,
        "avg_levenshtein": 35.46,
        "avg_edit_similarity": 0.08,
        "avg_first_line_edit_similarity": 0.08,
        "avg_cosine": 0.0
      },
      "python": {
        "total_comparisons": 4752,
        "line0_exact_matches": 0,
        "line0_exact_match_rate": 0.0,
        "proximity_matches": 44,
        "proximity_match_rate": 0.93,
        "avg_levenshtein": 30.87,
        "avg_edit_similarity": 0.08,
        "avg_first_line_edit_similarity": 0.08,
        "avg_cosine": 0.0
      },
      "typescript": {
        "total_comparisons": 4500,
        "line0_exact_matches": 0,
        "line0_exact_match_rate": 0.0,
        "proximity_matches": 90,
        "proximity_match_rate": 2.0,
        "avg_levenshtein": 38.35,
        "avg_edit_similarity": 0.1,
        "avg_first_line_edit_similarity": 0.1,
        "avg_cosine": 0.0
      }
    }
  },
  "prefix": {
    "overall": {
      "total_comparisons": 27252,
      "line0_exact_matches": 30,
      "line0_exact_match_rate": 0.11,
      "proximity_matches": 4509,
      "proximity_match_rate": 16.55,
      "avg_levenshtein": 38.01,
      "avg_edit_similarity": 0.15,
      "avg_first_line_edit_similarity": 0.15,
      "avg_cosine": 0.03
    },
    "categories": {
      "api_usage": {
        "total_comparisons": 4500,
        "line0_exact_matches": 0,
        "line0_exact_match_rate": 0.0,
        "proximity_matches": 780,
        "proximity_match_rate": 17.33,
        "avg_levenshtein": 45.51,
        "avg_edit_similarity": 0.16,
        "avg_first_line_edit_similarity": 0.15,
        "avg_cosine": 0.03
      },
      "code2NL_NL2code": {
        "total_comparisons": 4500,
        "line0_exact_matches": 15,
        "line0_exact_match_rate": 0.33,
        "proximity_matches": 435,
        "proximity_match_rate": 9.67,
        "avg_levenshtein": 35.58,
        "avg_edit_similarity": 0.09,
        "avg_first_line_edit_similarity": 0.09,
        "avg_cosine": 0.02
      },
      "code_purpose_understanding": {
        "total_comparisons": 4500,
        "line0_exact_matches": 0,
        "line0_exact_match_rate": 0.0,
        "proximity_matches": 705,
        "proximity_match_rate": 15.67,
        "avg_levenshtein": 40.67,
        "avg_edit_similarity": 0.16,
        "avg_first_line_edit_similarity": 0.15,
        "avg_cosine": 0.02
      },
      "low_context": {
        "total_comparisons": 4452,
        "line0_exact_matches": 0,
        "line0_exact_match_rate": 0.0,
        "proximity_matches": 699,
        "proximity_match_rate": 15.7,
        "avg_levenshtein": 28.81,
        "avg_edit_similarity": 0.16,
        "avg_first_line_edit_similarity": 0.15,
        "avg_cosine": 0.05
      },
      "pattern_matching": {
        "total_comparisons": 4500,
        "line0_exact_matches": 0,
        "line0_exact_match_rate": 0.0,
        "proximity_matches": 780,
        "proximity_match_rate": 17.33,
        "avg_levenshtein": 40.8,
        "avg_edit_similarity": 0.17,
        "avg_first_line_edit_similarity": 0.16,
        "avg_cosine": 0.02
      },
      "syntax_completion": {
        "total_comparisons": 4500,
        "line0_exact_matches": 0,
        "line0_exact_match_rate": 0.0,
        "proximity_matches": 990,
        "proximity_match_rate": 22.0,
        "avg_levenshtein": 36.3,
        "avg_edit_similarity": 0.15,
        "avg_first_line_edit_similarity": 0.15,
        "avg_cosine": 0.03
      },
      "dogfood/idiomatic": {
        "total_comparisons": 75,
        "line0_exact_matches": 15,
        "line0_exact_match_rate": 20.0,
        "proximity_matches": 30,
        "proximity_match_rate": 40.0,
        "avg_levenshtein": 34.4,
        "avg_edit_similarity": 0.35,
        "avg_first_line_edit_similarity": 0.35,
        "avg_cosine": 0.27
      },
      "dogfood/nl2code": {
        "total_comparisons": 105,
        "line0_exact_matches": 0,
        "line0_exact_match_rate": 0.0,
        "proximity_matches": 0,
        "proximity_match_rate": 0.0,
        "avg_levenshtein": 31.14,
        "avg_edit_similarity": 0.26,
        "avg_first_line_edit_similarity": 0.26,
        "avg_cosine": 0.17
      },
      "dogfood/organization": {
        "total_comparisons": 120,
        "line0_exact_matches": 0,
        "line0_exact_match_rate": 0.0,
        "proximity_matches": 90,
        "proximity_match_rate": 75.0,
        "avg_levenshtein": 56.75,
        "avg_edit_similarity": 0.21,
        "avg_first_line_edit_similarity": 0.21,
        "avg_cosine": 0.38
      }
    },
    "languages": {
      "cpp": {
        "total_comparisons": 4500,
        "line0_exact_matches": 0,
        "line0_exact_match_rate": 0.0,
        "proximity_matches": 75,
        "proximity_match_rate": 1.67,
        "avg_levenshtein": 35.13,
        "avg_edit_similarity": 0.13,
        "avg_first_line_edit_similarity": 0.13,
        "avg_cosine": 0.0
      },
      "c_sharp": {
        "total_comparisons": 4500,
        "line0_exact_matches": 0,
        "line0_exact_match_rate": 0.0,
        "proximity_matches": 390,
        "proximity_match_rate": 8.67,
        "avg_levenshtein": 42.1,
        "avg_edit_similarity": 0.13,
        "avg_first_line_edit_similarity": 0.12,
        "avg_cosine": 0.0
      },
      "java": {
        "total_comparisons": 4500,
        "line0_exact_matches": 0,
        "line0_exact_match_rate": 0.0,
        "proximity_matches": 225,
        "proximity_match_rate": 5.0,
        "avg_levenshtein": 41.06,
        "avg_edit_similarity": 0.15,
        "avg_first_line_edit_similarity": 0.14,
        "avg_cosine": 0.02
      },
      "javascript": {
        "total_comparisons": 4500,
        "line0_exact_matches": 0,
        "line0_exact_match_rate": 0.0,
        "proximity_matches": 1260,
        "proximity_match_rate": 28.0,
        "avg_levenshtein": 35.54,
        "avg_edit_similarity": 0.18,
        "avg_first_line_edit_similarity": 0.18,
        "avg_cosine": 0.05
      },
      "python": {
        "total_comparisons": 4752,
        "line0_exact_matches": 30,
        "line0_exact_match_rate": 0.63,
        "proximity_matches": 954,
        "proximity_match_rate": 20.08,
        "avg_levenshtein": 32.23,
        "avg_edit_similarity": 0.16,
        "avg_first_line_edit_similarity": 0.16,
        "avg_cosine": 0.06
      },
      "typescript": {
        "total_comparisons": 4500,
        "line0_exact_matches": 0,
        "line0_exact_match_rate": 0.0,
        "proximity_matches": 1605,
        "proximity_match_rate": 35.67,
        "avg_levenshtein": 42.3,
        "avg_edit_similarity": 0.15,
        "avg_first_line_edit_similarity": 0.15,
        "avg_cosine": 0.05
      }
    }
  },
  "suffix": {
    "overall": {
      "total_comparisons": 27180,
      "line0_exact_matches": 419,
      "line0_exact_match_rate": 1.54,
      "proximity_matches": 11890,
      "proximity_match_rate": 43.75,
      "avg_levenshtein": 36.48,
      "avg_edit_similarity": 0.24,
      "avg_first_line_edit_similarity": 0.24,
      "avg_cosine": 0.17
    },
    "categories": {
      "api_usage": {
        "total_comparisons": 4485,
        "line0_exact_matches": 45,
        "line0_exact_match_rate": 1.0,
        "proximity_matches": 2415,
        "proximity_match_rate": 53.85,
        "avg_levenshtein": 41.57,
        "avg_edit_similarity": 0.27,
        "avg_first_line_edit_similarity": 0.26,
        "avg_cosine": 0.19
      },
      "code2NL_NL2code": {
        "total_comparisons": 4500,
        "line0_exact_matches": 90,
        "line0_exact_match_rate": 2.0,
        "proximity_matches": 1350,
        "proximity_match_rate": 30.0,
        "avg_levenshtein": 37.58,
        "avg_edit_similarity": 0.15,
        "avg_first_line_edit_similarity": 0.15,
        "avg_cosine": 0.11
      },
      "code_purpose_understanding": {
        "total_comparisons": 4485,
        "line0_exact_matches": 45,
        "line0_exact_match_rate": 1.0,
        "proximity_matches": 2250,
        "proximity_match_rate": 50.17,
        "avg_levenshtein": 40.83,
        "avg_edit_similarity": 0.25,
        "avg_first_line_edit_similarity": 0.25,
        "avg_cosine": 0.17
      },
      "low_context": {
        "total_comparisons": 4410,
        "line0_exact_matches": 29,
        "line0_exact_match_rate": 0.66,
        "proximity_matches": 1195,
        "proximity_match_rate": 27.1,
        "avg_levenshtein": 30.52,
        "avg_edit_similarity": 0.16,
        "avg_first_line_edit_similarity": 0.16,
        "avg_cosine": 0.12
      },
      "pattern_matching": {
        "total_comparisons": 4500,
        "line0_exact_matches": 120,
        "line0_exact_match_rate": 2.67,
        "proximity_matches": 2520,
        "proximity_match_rate": 56.0,
        "avg_levenshtein": 33.59,
        "avg_edit_similarity": 0.36,
        "avg_first_line_edit_similarity": 0.36,
        "avg_cosine": 0.28
      },
      "syntax_completion": {
        "total_comparisons": 4500,
        "line0_exact_matches": 75,
        "line0_exact_match_rate": 1.67,
        "proximity_matches": 2040,
        "proximity_match_rate": 45.33,
        "avg_levenshtein": 34.7,
        "avg_edit_similarity": 0.26,
        "avg_first_line_edit_similarity": 0.26,
        "avg_cosine": 0.18
      },
      "dogfood/idiomatic": {
        "total_comparisons": 75,
        "line0_exact_matches": 15,
        "line0_exact_match_rate": 20.0,
        "proximity_matches": 60,
        "proximity_match_rate": 80.0,
        "avg_levenshtein": 16.6,
        "avg_edit_similarity": 0.47,
        "avg_first_line_edit_similarity": 0.47,
        "avg_cosine": 0.45
      },
      "dogfood/nl2code": {
        "total_comparisons": 105,
        "line0_exact_matches": 0,
        "line0_exact_match_rate": 0.0,
        "proximity_matches": 15,
        "proximity_match_rate": 14.29,
        "avg_levenshtein": 39.14,
        "avg_edit_similarity": 0.21,
        "avg_first_line_edit_similarity": 0.21,
        "avg_cosine": 0.07
      },
      "dogfood/organization": {
        "total_comparisons": 120,
        "line0_exact_matches": 0,
        "line0_exact_match_rate": 0.0,
        "proximity_matches": 45,
        "proximity_match_rate": 37.5,
        "avg_levenshtein": 47.38,
        "avg_edit_similarity": 0.18,
        "avg_first_line_edit_similarity": 0.18,
        "avg_cosine": 0.14
      }
    },
    "languages": {
      "cpp": {
        "total_comparisons": 4500,
        "line0_exact_matches": 75,
        "line0_exact_match_rate": 1.67,
        "proximity_matches": 1680,
        "proximity_match_rate": 37.33,
        "avg_levenshtein": 35.79,
        "avg_edit_similarity": 0.23,
        "avg_first_line_edit_similarity": 0.22,
        "avg_cosine": 0.16
      },
      "c_sharp": {
        "total_comparisons": 4500,
        "line0_exact_matches": 90,
        "line0_exact_match_rate": 2.0,
        "proximity_matches": 2580,
        "proximity_match_rate": 57.33,
        "avg_levenshtein": 43.05,
        "avg_edit_similarity": 0.26,
        "avg_first_line_edit_similarity": 0.26,
        "avg_cosine": 0.19
      },
      "java": {
        "total_comparisons": 4500,
        "line0_exact_matches": 30,
        "line0_exact_match_rate": 0.67,
        "proximity_matches": 1995,
        "proximity_match_rate": 44.33,
        "avg_levenshtein": 38.62,
        "avg_edit_similarity": 0.24,
        "avg_first_line_edit_similarity": 0.24,
        "avg_cosine": 0.17
      },
      "javascript": {
        "total_comparisons": 4500,
        "line0_exact_matches": 75,
        "line0_exact_match_rate": 1.67,
        "proximity_matches": 1770,
        "proximity_match_rate": 39.33,
        "avg_levenshtein": 32.72,
        "avg_edit_similarity": 0.25,
        "avg_first_line_edit_similarity": 0.24,
        "avg_cosine": 0.18
      },
      "python": {
        "total_comparisons": 4710,
        "line0_exact_matches": 74,
        "line0_exact_match_rate": 1.57,
        "proximity_matches": 1960,
        "proximity_match_rate": 41.61,
        "avg_levenshtein": 31.08,
        "avg_edit_similarity": 0.24,
        "avg_first_line_edit_similarity": 0.24,
        "avg_cosine": 0.17
      },
      "typescript": {
        "total_comparisons": 4470,
        "line0_exact_matches": 75,
        "line0_exact_match_rate": 1.68,
        "proximity_matches": 1905,
        "proximity_match_rate": 42.62,
        "avg_levenshtein": 37.9,
        "avg_edit_similarity": 0.24,
        "avg_first_line_edit_similarity": 0.24,
        "avg_cosine": 0.18
      }
    }
  },
  "golden_completion": {
    "overall": {
      "total_comparisons": 27252,
      "line0_exact_matches": 27252,
      "line0_exact_match_rate": 100.0,
      "proximity_matches": 27133,
      "proximity_match_rate": 99.56,
      "avg_levenshtein": 0.0,
      "avg_edit_similarity": 1.0,
      "avg_first_line_edit_similarity": 1.0,
      "avg_cosine": 1.0
    },
    "categories": {
      "api_usage": {
        "total_comparisons": 4500,
        "line0_exact_matches": 4500,
        "line0_exact_match_rate": 100.0,
        "proximity_matches": 4485,
        "proximity_match_rate": 99.67,
        "avg_levenshtein": 0.0,
        "avg_edit_similarity": 1.0,
        "avg_first_line_edit_similarity": 1.0,
        "avg_cosine": 1.0
      },
      "code2NL_NL2code": {
        "total_comparisons": 4500,
        "line0_exact_matches": 4500,
        "line0_exact_match_rate": 100.0,
        "proximity_matches": 4485,
        "proximity_match_rate": 99.67,
        "avg_levenshtein": 0.0,
        "avg_edit_similarity": 1.0,
        "avg_first_line_edit_similarity": 1.0,
        "avg_cosine": 1.0
      },
      "code_purpose_understanding": {
        "total_comparisons": 4500,
        "line0_exact_matches": 4500,
        "line0_exact_match_rate": 100.0,
        "proximity_matches": 4500,
        "proximity_match_rate": 100.0,
        "avg_levenshtein": 0.0,
        "avg_edit_similarity": 1.0,
        "avg_first_line_edit_similarity": 1.0,
        "avg_cosine": 1.0
      },
      "low_context": {
        "total_comparisons": 4452,
        "line0_exact_matches": 4452,
        "line0_exact_match_rate": 100.0,
        "proximity_matches": 4378,
        "proximity_match_rate": 98.34,
        "avg_levenshtein": 0.0,
        "avg_edit_similarity": 1.0,
        "avg_first_line_edit_similarity": 1.0,
        "avg_cosine": 1.0
      },
      "pattern_matching": {
        "total_comparisons": 4500,
        "line0_exact_matches": 4500,
        "line0_exact_match_rate": 100.0,
        "proximity_matches": 4500,
        "proximity_match_rate": 100.0,
        "avg_levenshtein": 0.0,
        "avg_edit_similarity": 1.0,
        "avg_first_line_edit_similarity": 1.0,
        "avg_cosine": 1.0
      },
      "syntax_completion": {
        "total_comparisons": 4500,
        "line0_exact_matches": 4500,
        "line0_exact_match_rate": 100.0,
        "proximity_matches": 4485,
        "proximity_match_rate": 99.67,
        "avg_levenshtein": 0.0,
        "avg_edit_similarity": 1.0,
        "avg_first_line_edit_similarity": 1.0,
        "avg_cosine": 1.0
      },
      "dogfood/idiomatic": {
        "total_comparisons": 75,
        "line0_exact_matches": 75,
        "line0_exact_match_rate": 100.0,
        "proximity_matches": 75,
        "proximity_match_rate": 100.0,
        "avg_levenshtein": 0.0,
        "avg_edit_similarity": 1.0,
        "avg_first_line_edit_similarity": 1.0,
        "avg_cosine": 1.0
      },
      "dogfood/nl2code": {
        "total_comparisons": 105,
        "line0_exact_matches": 105,
        "line0_exact_match_rate": 100.0,
        "proximity_matches": 105,
        "proximity_match_rate": 100.0,
        "avg_levenshtein": 0.0,
        "avg_edit_similarity": 1.0,
        "avg_first_line_edit_similarity": 1.0,
        "avg_cosine": 1.0
      },
      "dogfood/organization": {
        "total_comparisons": 120,
        "line0_exact_matches": 120,
        "line0_exact_match_rate": 100.0,
        "proximity_matches": 120,
        "proximity_match_rate": 100.0,
        "avg_levenshtein": 0.0,
        "avg_edit_similarity": 1.0,
        "avg_first_line_edit_similarity": 1.0,
        "avg_cosine": 1.0
      }
    },
    "languages": {
      "cpp": {
        "total_comparisons": 4500,
        "line0_exact_matches": 4500,
        "line0_exact_match_rate": 100.0,
        "proximity_matches": 4470,
        "proximity_match_rate": 99.33,
        "avg_levenshtein": 0.0,
        "avg_edit_similarity": 1.0,
        "avg_first_line_edit_similarity": 1.0,
        "avg_cosine": 1.0
      },
      "c_sharp": {
        "total_comparisons": 4500,
        "line0_exact_matches": 4500,
        "line0_exact_match_rate": 100.0,
        "proximity_matches": 4485,
        "proximity_match_rate": 99.67,
        "avg_levenshtein": 0.0,
        "avg_edit_similarity": 1.0,
        "avg_first_line_edit_similarity": 1.0,
        "avg_cosine": 1.0
      },
      "java": {
        "total_comparisons": 4500,
        "line0_exact_matches": 4500,
        "line0_exact_match_rate": 100.0,
        "proximity_matches": 4500,
        "proximity_match_rate": 100.0,
        "avg_levenshtein": 0.0,
        "avg_edit_similarity": 1.0,
        "avg_first_line_edit_similarity": 1.0,
        "avg_cosine": 1.0
      },
      "javascript": {
        "total_comparisons": 4500,
        "line0_exact_matches": 4500,
        "line0_exact_match_rate": 100.0,
        "proximity_matches": 4470,
        "proximity_match_rate": 99.33,
        "avg_levenshtein": 0.0,
        "avg_edit_similarity": 1.0,
        "avg_first_line_edit_similarity": 1.0,
        "avg_cosine": 1.0
      },
      "python": {
        "total_comparisons": 4752,
        "line0_exact_matches": 4752,
        "line0_exact_match_rate": 100.0,
        "proximity_matches": 4738,
        "proximity_match_rate": 99.71,
        "avg_levenshtein": 0.0,
        "avg_edit_similarity": 1.0,
        "avg_first_line_edit_similarity": 1.0,
        "avg_cosine": 1.0
      },
      "typescript": {
        "total_comparisons": 4500,
        "line0_exact_matches": 4500,
        "line0_exact_match_rate": 100.0,
        "proximity_matches": 4470,
        "proximity_match_rate": 99.33,
        "avg_levenshtein": 0.0,
        "avg_edit_similarity": 1.0,
        "avg_first_line_edit_similarity": 1.0,
        "avg_cosine": 1.0
      }
    }
  },
  "LLM_justification": {
    "overall": {
      "total_comparisons": 27252,
      "line0_exact_matches": 0,
      "line0_exact_match_rate": 0.0,
      "proximity_matches": 23341,
      "proximity_match_rate": 85.65,
      "avg_levenshtein": 481.48,
      "avg_edit_similarity": 0.06,
      "avg_first_line_edit_similarity": 0.06,
      "avg_cosine": 0.08
    },
    "categories": {
      "api_usage": {
        "total_comparisons": 4500,
        "line0_exact_matches": 0,
        "line0_exact_match_rate": 0.0,
        "proximity_matches": 4260,
        "proximity_match_rate": 94.67,
        "avg_levenshtein": 465.11,
        "avg_edit_similarity": 0.07,
        "avg_first_line_edit_similarity": 0.07,
        "avg_cosine": 0.1
      },
      "code2NL_NL2code": {
        "total_comparisons": 4500,
        "line0_exact_matches": 0,
        "line0_exact_match_rate": 0.0,
        "proximity_matches": 2400,
        "proximity_match_rate": 53.33,
        "avg_levenshtein": 552.87,
        "avg_edit_similarity": 0.04,
        "avg_first_line_edit_similarity": 0.04,
        "avg_cosine": 0.03
      },
      "code_purpose_understanding": {
        "total_comparisons": 4500,
        "line0_exact_matches": 0,
        "line0_exact_match_rate": 0.0,
        "proximity_matches": 4335,
        "proximity_match_rate": 96.33,
        "avg_levenshtein": 507.13,
        "avg_edit_similarity": 0.07,
        "avg_first_line_edit_similarity": 0.07,
        "avg_cosine": 0.09
      },
      "low_context": {
        "total_comparisons": 4452,
        "line0_exact_matches": 0,
        "line0_exact_match_rate": 0.0,
        "proximity_matches": 3826,
        "proximity_match_rate": 85.94,
        "avg_levenshtein": 421.93,
        "avg_edit_similarity": 0.05,
        "avg_first_line_edit_similarity": 0.05,
        "avg_cosine": 0.07
      },
      "pattern_matching": {
        "total_comparisons": 4500,
        "line0_exact_matches": 0,
        "line0_exact_match_rate": 0.0,
        "proximity_matches": 4260,
        "proximity_match_rate": 94.67,
        "avg_levenshtein": 518.21,
        "avg_edit_similarity": 0.07,
        "avg_first_line_edit_similarity": 0.07,
        "avg_cosine": 0.09
      },
      "syntax_completion": {
        "total_comparisons": 4500,
        "line0_exact_matches": 0,
        "line0_exact_match_rate": 0.0,
        "proximity_matches": 3975,
        "proximity_match_rate": 88.33,
        "avg_levenshtein": 434.82,
        "avg_edit_similarity": 0.06,
        "avg_first_line_edit_similarity": 0.06,
        "avg_cosine": 0.08
      },
      "dogfood/idiomatic": {
        "total_comparisons": 75,
        "line0_exact_matches": 0,
        "line0_exact_match_rate": 0.0,
        "proximity_matches": 60,
        "proximity_match_rate": 80.0,
        "avg_levenshtein": 364.4,
        "avg_edit_similarity": 0.05,
        "avg_first_line_edit_similarity": 0.05,
        "avg_cosine": 0.02
      },
      "dogfood/nl2code": {
        "total_comparisons": 105,
        "line0_exact_matches": 0,
        "line0_exact_match_rate": 0.0,
        "proximity_matches": 105,
        "proximity_match_rate": 100.0,
        "avg_levenshtein": 288.57,
        "avg_edit_similarity": 0.11,
        "avg_first_line_edit_similarity": 0.11,
        "avg_cosine": 0.22
      },
      "dogfood/organization": {
        "total_comparisons": 120,
        "line0_exact_matches": 0,
        "line0_exact_match_rate": 0.0,
        "proximity_matches": 120,
        "proximity_match_rate": 100.0,
        "avg_levenshtein": 279.12,
        "avg_edit_similarity": 0.06,
        "avg_first_line_edit_similarity": 0.06,
        "avg_cosine": 0.3
      }
    },
    "languages": {
      "cpp": {
        "total_comparisons": 4500,
        "line0_exact_matches": 0,
        "line0_exact_match_rate": 0.0,
        "proximity_matches": 3795,
        "proximity_match_rate": 84.33,
        "avg_levenshtein": 519.91,
        "avg_edit_similarity": 0.05,
        "avg_first_line_edit_similarity": 0.05,
        "avg_cosine": 0.07
      },
      "c_sharp": {
        "total_comparisons": 4500,
        "line0_exact_matches": 0,
        "line0_exact_match_rate": 0.0,
        "proximity_matches": 3960,
        "proximity_match_rate": 88.0,
        "avg_levenshtein": 488.61,
        "avg_edit_similarity": 0.07,
        "avg_first_line_edit_similarity": 0.07,
        "avg_cosine": 0.07
      },
      "java": {
        "total_comparisons": 4500,
        "line0_exact_matches": 0,
        "line0_exact_match_rate": 0.0,
        "proximity_matches": 4020,
        "proximity_match_rate": 89.33,
        "avg_levenshtein": 485.59,
        "avg_edit_similarity": 0.07,
        "avg_first_line_edit_similarity": 0.07,
        "avg_cosine": 0.08
      },
      "javascript": {
        "total_comparisons": 4500,
        "line0_exact_matches": 0,
        "line0_exact_match_rate": 0.0,
        "proximity_matches": 3675,
        "proximity_match_rate": 81.67,
        "avg_levenshtein": 477.4,
        "avg_edit_similarity": 0.06,
        "avg_first_line_edit_similarity": 0.06,
        "avg_cosine": 0.08
      },
      "python": {
        "total_comparisons": 4752,
        "line0_exact_matches": 0,
        "line0_exact_match_rate": 0.0,
        "proximity_matches": 4186,
        "proximity_match_rate": 88.09,
        "avg_levenshtein": 428.25,
        "avg_edit_similarity": 0.06,
        "avg_first_line_edit_similarity": 0.06,
        "avg_cosine": 0.09
      },
      "typescript": {
        "total_comparisons": 4500,
        "line0_exact_matches": 0,
        "line0_exact_match_rate": 0.0,
        "proximity_matches": 3705,
        "proximity_match_rate": 82.33,
        "avg_levenshtein": 492.06,
        "avg_edit_similarity": 0.06,
        "avg_first_line_edit_similarity": 0.06,
        "avg_cosine": 0.08
      }
    }
  },
  "4omini_sft39_spm_fix2_5": {
    "overall": {
      "total_comparisons": 1820,
      "line0_exact_matches": 874,
      "line0_exact_match_rate": 48.02,
      "proximity_matches": 1428,
      "proximity_match_rate": 78.46,
      "avg_levenshtein": 17.03,
      "avg_edit_similarity": 0.66,
      "avg_first_line_edit_similarity": 0.66,
      "avg_cosine": 0.65
    },
    "categories": {
      "api_usage": {
        "total_comparisons": 300,
        "line0_exact_matches": 122,
        "line0_exact_match_rate": 40.67,
        "proximity_matches": 233,
        "proximity_match_rate": 77.67,
        "avg_levenshtein": 21.22,
        "avg_edit_similarity": 0.64,
        "avg_first_line_edit_similarity": 0.64,
        "avg_cosine": 0.61
      },
      "code2NL_NL2code": {
        "total_comparisons": 300,
        "line0_exact_matches": 134,
        "line0_exact_match_rate": 44.67,
        "proximity_matches": 171,
        "proximity_match_rate": 57.0,
        "avg_levenshtein": 18.54,
        "avg_edit_similarity": 0.52,
        "avg_first_line_edit_similarity": 0.52,
        "avg_cosine": 0.52
      },
      "code_purpose_understanding": {
        "total_comparisons": 300,
        "line0_exact_matches": 163,
        "line0_exact_match_rate": 54.33,
        "proximity_matches": 264,
        "proximity_match_rate": 88.0,
        "avg_levenshtein": 15.25,
        "avg_edit_similarity": 0.73,
        "avg_first_line_edit_similarity": 0.73,
        "avg_cosine": 0.71
      },
      "low_context": {
        "total_comparisons": 300,
        "line0_exact_matches": 170,
        "line0_exact_match_rate": 56.67,
        "proximity_matches": 262,
        "proximity_match_rate": 87.33,
        "avg_levenshtein": 11.0,
        "avg_edit_similarity": 0.76,
        "avg_first_line_edit_similarity": 0.76,
        "avg_cosine": 0.77
      },
      "pattern_matching": {
        "total_comparisons": 300,
        "line0_exact_matches": 151,
        "line0_exact_match_rate": 50.33,
        "proximity_matches": 250,
        "proximity_match_rate": 83.33,
        "avg_levenshtein": 17.78,
        "avg_edit_similarity": 0.7,
        "avg_first_line_edit_similarity": 0.7,
        "avg_cosine": 0.66
      },
      "syntax_completion": {
        "total_comparisons": 300,
        "line0_exact_matches": 127,
        "line0_exact_match_rate": 42.33,
        "proximity_matches": 237,
        "proximity_match_rate": 79.0,
        "avg_levenshtein": 17.95,
        "avg_edit_similarity": 0.65,
        "avg_first_line_edit_similarity": 0.65,
        "avg_cosine": 0.63
      },
      "dogfood/idiomatic": {
        "total_comparisons": 5,
        "line0_exact_matches": 0,
        "line0_exact_match_rate": 0.0,
        "proximity_matches": 0,
        "proximity_match_rate": 0.0,
        "avg_levenshtein": 33.2,
        "avg_edit_similarity": 0.17,
        "avg_first_line_edit_similarity": 0.17,
        "avg_cosine": 0.05
      },
      "dogfood/nl2code": {
        "total_comparisons": 7,
        "line0_exact_matches": 2,
        "line0_exact_match_rate": 28.57,
        "proximity_matches": 4,
        "proximity_match_rate": 57.14,
        "avg_levenshtein": 24.71,
        "avg_edit_similarity": 0.48,
        "avg_first_line_edit_similarity": 0.48,
        "avg_cosine": 0.35
      },
      "dogfood/organization": {
        "total_comparisons": 8,
        "line0_exact_matches": 5,
        "line0_exact_match_rate": 62.5,
        "proximity_matches": 7,
        "proximity_match_rate": 87.5,
        "avg_levenshtein": 17.62,
        "avg_edit_similarity": 0.67,
        "avg_first_line_edit_similarity": 0.67,
        "avg_cosine": 0.73
      }
    },
    "languages": {
      "cpp": {
        "total_comparisons": 300,
        "line0_exact_matches": 171,
        "line0_exact_match_rate": 57.0,
        "proximity_matches": 241,
        "proximity_match_rate": 80.33,
        "avg_levenshtein": 12.82,
        "avg_edit_similarity": 0.72,
        "avg_first_line_edit_similarity": 0.72,
        "avg_cosine": 0.71
      },
      "c_sharp": {
        "total_comparisons": 300,
        "line0_exact_matches": 144,
        "line0_exact_match_rate": 48.0,
        "proximity_matches": 254,
        "proximity_match_rate": 84.67,
        "avg_levenshtein": 19.18,
        "avg_edit_similarity": 0.69,
        "avg_first_line_edit_similarity": 0.69,
        "avg_cosine": 0.67
      },
      "java": {
        "total_comparisons": 300,
        "line0_exact_matches": 182,
        "line0_exact_match_rate": 60.67,
        "proximity_matches": 259,
        "proximity_match_rate": 86.33,
        "avg_levenshtein": 13.1,
        "avg_edit_similarity": 0.76,
        "avg_first_line_edit_similarity": 0.76,
        "avg_cosine": 0.75
      },
      "javascript": {
        "total_comparisons": 300,
        "line0_exact_matches": 134,
        "line0_exact_match_rate": 44.67,
        "proximity_matches": 225,
        "proximity_match_rate": 75.0,
        "avg_levenshtein": 17.38,
        "avg_edit_similarity": 0.62,
        "avg_first_line_edit_similarity": 0.62,
        "avg_cosine": 0.61
      },
      "python": {
        "total_comparisons": 320,
        "line0_exact_matches": 145,
        "line0_exact_match_rate": 45.31,
        "proximity_matches": 248,
        "proximity_match_rate": 77.5,
        "avg_levenshtein": 15.12,
        "avg_edit_similarity": 0.65,
        "avg_first_line_edit_similarity": 0.65,
        "avg_cosine": 0.64
      },
      "typescript": {
        "total_comparisons": 300,
        "line0_exact_matches": 98,
        "line0_exact_match_rate": 32.67,
        "proximity_matches": 201,
        "proximity_match_rate": 67.0,
        "avg_levenshtein": 24.73,
        "avg_edit_similarity": 0.53,
        "avg_first_line_edit_similarity": 0.53,
        "avg_cosine": 0.51
      }
    }
  },
  "claude-3-5-sonnet": {
    "overall": {
      "total_comparisons": 1804,
      "line0_exact_matches": 904,
      "line0_exact_match_rate": 50.11,
      "proximity_matches": 1469,
      "proximity_match_rate": 81.43,
      "avg_levenshtein": 15.35,
      "avg_edit_similarity": 0.69,
      "avg_first_line_edit_similarity": 0.69,
      "avg_cosine": 0.68
    },
    "categories": {
      "api_usage": {
        "total_comparisons": 300,
        "line0_exact_matches": 107,
        "line0_exact_match_rate": 35.67,
        "proximity_matches": 236,
        "proximity_match_rate": 78.67,
        "avg_levenshtein": 21.01,
        "avg_edit_similarity": 0.62,
        "avg_first_line_edit_similarity": 0.62,
        "avg_cosine": 0.6
      },
      "code2NL_NL2code": {
        "total_comparisons": 291,
        "line0_exact_matches": 145,
        "line0_exact_match_rate": 49.83,
        "proximity_matches": 179,
        "proximity_match_rate": 61.51,
        "avg_levenshtein": 15.95,
        "avg_edit_similarity": 0.58,
        "avg_first_line_edit_similarity": 0.58,
        "avg_cosine": 0.57
      },
      "code_purpose_understanding": {
        "total_comparisons": 300,
        "line0_exact_matches": 163,
        "line0_exact_match_rate": 54.33,
        "proximity_matches": 266,
        "proximity_match_rate": 88.67,
        "avg_levenshtein": 14.67,
        "avg_edit_similarity": 0.74,
        "avg_first_line_edit_similarity": 0.73,
        "avg_cosine": 0.73
      },
      "low_context": {
        "total_comparisons": 295,
        "line0_exact_matches": 175,
        "line0_exact_match_rate": 59.32,
        "proximity_matches": 259,
        "proximity_match_rate": 87.8,
        "avg_levenshtein": 9.03,
        "avg_edit_similarity": 0.78,
        "avg_first_line_edit_similarity": 0.78,
        "avg_cosine": 0.78
      },
      "pattern_matching": {
        "total_comparisons": 298,
        "line0_exact_matches": 162,
        "line0_exact_match_rate": 54.36,
        "proximity_matches": 269,
        "proximity_match_rate": 90.27,
        "avg_levenshtein": 14.46,
        "avg_edit_similarity": 0.76,
        "avg_first_line_edit_similarity": 0.76,
        "avg_cosine": 0.73
      },
      "syntax_completion": {
        "total_comparisons": 300,
        "line0_exact_matches": 142,
        "line0_exact_match_rate": 47.33,
        "proximity_matches": 247,
        "proximity_match_rate": 82.33,
        "avg_levenshtein": 16.74,
        "avg_edit_similarity": 0.68,
        "avg_first_line_edit_similarity": 0.68,
        "avg_cosine": 0.67
      },
      "dogfood/idiomatic": {
        "total_comparisons": 5,
        "line0_exact_matches": 2,
        "line0_exact_match_rate": 40.0,
        "proximity_matches": 2,
        "proximity_match_rate": 40.0,
        "avg_levenshtein": 18.2,
        "avg_edit_similarity": 0.48,
        "avg_first_line_edit_similarity": 0.48,
        "avg_cosine": 0.4
      },
      "dogfood/nl2code": {
        "total_comparisons": 7,
        "line0_exact_matches": 2,
        "line0_exact_match_rate": 28.57,
        "proximity_matches": 4,
        "proximity_match_rate": 57.14,
        "avg_levenshtein": 25.29,
        "avg_edit_similarity": 0.47,
        "avg_first_line_edit_similarity": 0.47,
        "avg_cosine": 0.35
      },
      "dogfood/organization": {
        "total_comparisons": 8,
        "line0_exact_matches": 6,
        "line0_exact_match_rate": 75.0,
        "proximity_matches": 7,
        "proximity_match_rate": 87.5,
        "avg_levenshtein": 10.38,
        "avg_edit_similarity": 0.78,
        "avg_first_line_edit_similarity": 0.78,
        "avg_cosine": 0.81
      }
    },
    "languages": {
      "cpp": {
        "total_comparisons": 295,
        "line0_exact_matches": 181,
        "line0_exact_match_rate": 61.36,
        "proximity_matches": 258,
        "proximity_match_rate": 87.46,
        "avg_levenshtein": 10.29,
        "avg_edit_similarity": 0.78,
        "avg_first_line_edit_similarity": 0.78,
        "avg_cosine": 0.78
      },
      "c_sharp": {
        "total_comparisons": 300,
        "line0_exact_matches": 147,
        "line0_exact_match_rate": 49.0,
        "proximity_matches": 253,
        "proximity_match_rate": 84.33,
        "avg_levenshtein": 17.27,
        "avg_edit_similarity": 0.71,
        "avg_first_line_edit_similarity": 0.71,
        "avg_cosine": 0.69
      },
      "java": {
        "total_comparisons": 297,
        "line0_exact_matches": 180,
        "line0_exact_match_rate": 60.61,
        "proximity_matches": 261,
        "proximity_match_rate": 87.88,
        "avg_levenshtein": 11.55,
        "avg_edit_similarity": 0.78,
        "avg_first_line_edit_similarity": 0.78,
        "avg_cosine": 0.78
      },
      "javascript": {
        "total_comparisons": 295,
        "line0_exact_matches": 126,
        "line0_exact_match_rate": 42.71,
        "proximity_matches": 219,
        "proximity_match_rate": 74.24,
        "avg_levenshtein": 19.05,
        "avg_edit_similarity": 0.62,
        "avg_first_line_edit_similarity": 0.62,
        "avg_cosine": 0.6
      },
      "python": {
        "total_comparisons": 320,
        "line0_exact_matches": 158,
        "line0_exact_match_rate": 49.38,
        "proximity_matches": 258,
        "proximity_match_rate": 80.62,
        "avg_levenshtein": 12.57,
        "avg_edit_similarity": 0.7,
        "avg_first_line_edit_similarity": 0.7,
        "avg_cosine": 0.69
      },
      "typescript": {
        "total_comparisons": 297,
        "line0_exact_matches": 112,
        "line0_exact_match_rate": 37.71,
        "proximity_matches": 220,
        "proximity_match_rate": 74.07,
        "avg_levenshtein": 21.55,
        "avg_edit_similarity": 0.57,
        "avg_first_line_edit_similarity": 0.57,
        "avg_cosine": 0.55
      }
    }
  },
  "claude-3-7-sonnet": {
    "overall": {
      "total_comparisons": 1807,
      "line0_exact_matches": 850,
      "line0_exact_match_rate": 47.04,
      "proximity_matches": 1433,
      "proximity_match_rate": 79.3,
      "avg_levenshtein": 18.09,
      "avg_edit_similarity": 0.65,
      "avg_first_line_edit_similarity": 0.65,
      "avg_cosine": 0.63
    },
    "categories": {
      "api_usage": {
        "total_comparisons": 298,
        "line0_exact_matches": 90,
        "line0_exact_match_rate": 30.2,
        "proximity_matches": 225,
        "proximity_match_rate": 75.5,
        "avg_levenshtein": 26.28,
        "avg_edit_similarity": 0.53,
        "avg_first_line_edit_similarity": 0.53,
        "avg_cosine": 0.51
      },
      "code2NL_NL2code": {
        "total_comparisons": 296,
        "line0_exact_matches": 149,
        "line0_exact_match_rate": 50.34,
        "proximity_matches": 192,
        "proximity_match_rate": 64.86,
        "avg_levenshtein": 16.68,
        "avg_edit_similarity": 0.58,
        "avg_first_line_edit_similarity": 0.58,
        "avg_cosine": 0.58
      },
      "code_purpose_understanding": {
        "total_comparisons": 299,
        "line0_exact_matches": 147,
        "line0_exact_match_rate": 49.16,
        "proximity_matches": 251,
        "proximity_match_rate": 83.95,
        "avg_levenshtein": 19.32,
        "avg_edit_similarity": 0.67,
        "avg_first_line_edit_similarity": 0.67,
        "avg_cosine": 0.65
      },
      "low_context": {
        "total_comparisons": 297,
        "line0_exact_matches": 178,
        "line0_exact_match_rate": 59.93,
        "proximity_matches": 250,
        "proximity_match_rate": 84.18,
        "avg_levenshtein": 9.96,
        "avg_edit_similarity": 0.76,
        "avg_first_line_edit_similarity": 0.76,
        "avg_cosine": 0.76
      },
      "pattern_matching": {
        "total_comparisons": 299,
        "line0_exact_matches": 150,
        "line0_exact_match_rate": 50.17,
        "proximity_matches": 261,
        "proximity_match_rate": 87.29,
        "avg_levenshtein": 17.29,
        "avg_edit_similarity": 0.71,
        "avg_first_line_edit_similarity": 0.71,
        "avg_cosine": 0.69
      },
      "syntax_completion": {
        "total_comparisons": 298,
        "line0_exact_matches": 128,
        "line0_exact_match_rate": 42.95,
        "proximity_matches": 241,
        "proximity_match_rate": 80.87,
        "avg_levenshtein": 18.66,
        "avg_edit_similarity": 0.63,
        "avg_first_line_edit_similarity": 0.63,
        "avg_cosine": 0.61
      },
      "dogfood/idiomatic": {
        "total_comparisons": 5,
        "line0_exact_matches": 2,
        "line0_exact_match_rate": 40.0,
        "proximity_matches": 2,
        "proximity_match_rate": 40.0,
        "avg_levenshtein": 18.2,
        "avg_edit_similarity": 0.48,
        "avg_first_line_edit_similarity": 0.48,
        "avg_cosine": 0.4
      },
      "dogfood/nl2code": {
        "total_comparisons": 7,
        "line0_exact_matches": 1,
        "line0_exact_match_rate": 14.29,
        "proximity_matches": 4,
        "proximity_match_rate": 57.14,
        "avg_levenshtein": 30.14,
        "avg_edit_similarity": 0.33,
        "avg_first_line_edit_similarity": 0.33,
        "avg_cosine": 0.22
      },
      "dogfood/organization": {
        "total_comparisons": 8,
        "line0_exact_matches": 5,
        "line0_exact_match_rate": 62.5,
        "proximity_matches": 7,
        "proximity_match_rate": 87.5,
        "avg_levenshtein": 19.0,
        "avg_edit_similarity": 0.68,
        "avg_first_line_edit_similarity": 0.68,
        "avg_cosine": 0.77
      }
    },
    "languages": {
      "cpp": {
        "total_comparisons": 297,
        "line0_exact_matches": 163,
        "line0_exact_match_rate": 54.88,
        "proximity_matches": 238,
        "proximity_match_rate": 80.13,
        "avg_levenshtein": 13.39,
        "avg_edit_similarity": 0.7,
        "avg_first_line_edit_similarity": 0.7,
        "avg_cosine": 0.69
      },
      "c_sharp": {
        "total_comparisons": 299,
        "line0_exact_matches": 143,
        "line0_exact_match_rate": 47.83,
        "proximity_matches": 246,
        "proximity_match_rate": 82.27,
        "avg_levenshtein": 20.7,
        "avg_edit_similarity": 0.67,
        "avg_first_line_edit_similarity": 0.67,
        "avg_cosine": 0.66
      },
      "java": {
        "total_comparisons": 299,
        "line0_exact_matches": 165,
        "line0_exact_match_rate": 55.18,
        "proximity_matches": 252,
        "proximity_match_rate": 84.28,
        "avg_levenshtein": 15.28,
        "avg_edit_similarity": 0.72,
        "avg_first_line_edit_similarity": 0.72,
        "avg_cosine": 0.7
      },
      "javascript": {
        "total_comparisons": 299,
        "line0_exact_matches": 134,
        "line0_exact_match_rate": 44.82,
        "proximity_matches": 227,
        "proximity_match_rate": 75.92,
        "avg_levenshtein": 19.01,
        "avg_edit_similarity": 0.61,
        "avg_first_line_edit_similarity": 0.61,
        "avg_cosine": 0.6
      },
      "python": {
        "total_comparisons": 319,
        "line0_exact_matches": 142,
        "line0_exact_match_rate": 44.51,
        "proximity_matches": 258,
        "proximity_match_rate": 80.88,
        "avg_levenshtein": 15.64,
        "avg_edit_similarity": 0.65,
        "avg_first_line_edit_similarity": 0.65,
        "avg_cosine": 0.64
      },
      "typescript": {
        "total_comparisons": 294,
        "line0_exact_matches": 103,
        "line0_exact_match_rate": 35.03,
        "proximity_matches": 212,
        "proximity_match_rate": 72.11,
        "avg_levenshtein": 24.77,
        "avg_edit_similarity": 0.52,
        "avg_first_line_edit_similarity": 0.52,
        "avg_cosine": 0.51
      }
    }
  },
  "DeepSeek-R1": {
    "overall": {
      "total_comparisons": 1815,
      "line0_exact_matches": 816,
      "line0_exact_match_rate": 44.96,
      "proximity_matches": 1405,
      "proximity_match_rate": 77.41,
      "avg_levenshtein": 17.26,
      "avg_edit_similarity": 0.66,
      "avg_first_line_edit_similarity": 0.66,
      "avg_cosine": 0.65
    },
    "categories": {
      "api_usage": {
        "total_comparisons": 298,
        "line0_exact_matches": 105,
        "line0_exact_match_rate": 35.23,
        "proximity_matches": 238,
        "proximity_match_rate": 79.87,
        "avg_levenshtein": 21.84,
        "avg_edit_similarity": 0.65,
        "avg_first_line_edit_similarity": 0.64,
        "avg_cosine": 0.64
      },
      "code2NL_NL2code": {
        "total_comparisons": 299,
        "line0_exact_matches": 114,
        "line0_exact_match_rate": 38.13,
        "proximity_matches": 158,
        "proximity_match_rate": 52.84,
        "avg_levenshtein": 20.55,
        "avg_edit_similarity": 0.48,
        "avg_first_line_edit_similarity": 0.48,
        "avg_cosine": 0.47
      },
      "code_purpose_understanding": {
        "total_comparisons": 300,
        "line0_exact_matches": 152,
        "line0_exact_match_rate": 50.67,
        "proximity_matches": 255,
        "proximity_match_rate": 85.0,
        "avg_levenshtein": 16.13,
        "avg_edit_similarity": 0.71,
        "avg_first_line_edit_similarity": 0.71,
        "avg_cosine": 0.7
      },
      "low_context": {
        "total_comparisons": 299,
        "line0_exact_matches": 162,
        "line0_exact_match_rate": 54.18,
        "proximity_matches": 258,
        "proximity_match_rate": 86.29,
        "avg_levenshtein": 10.04,
        "avg_edit_similarity": 0.77,
        "avg_first_line_edit_similarity": 0.77,
        "avg_cosine": 0.77
      },
      "pattern_matching": {
        "total_comparisons": 299,
        "line0_exact_matches": 146,
        "line0_exact_match_rate": 48.83,
        "proximity_matches": 252,
        "proximity_match_rate": 84.28,
        "avg_levenshtein": 16.87,
        "avg_edit_similarity": 0.72,
        "avg_first_line_edit_similarity": 0.72,
        "avg_cosine": 0.68
      },
      "syntax_completion": {
        "total_comparisons": 300,
        "line0_exact_matches": 128,
        "line0_exact_match_rate": 42.67,
        "proximity_matches": 232,
        "proximity_match_rate": 77.33,
        "avg_levenshtein": 18.0,
        "avg_edit_similarity": 0.65,
        "avg_first_line_edit_similarity": 0.65,
        "avg_cosine": 0.64
      },
      "dogfood/idiomatic": {
        "total_comparisons": 5,
        "line0_exact_matches": 1,
        "line0_exact_match_rate": 20.0,
        "proximity_matches": 2,
        "proximity_match_rate": 40.0,
        "avg_levenshtein": 24.6,
        "avg_edit_similarity": 0.37,
        "avg_first_line_edit_similarity": 0.37,
        "avg_cosine": 0.22
      },
      "dogfood/nl2code": {
        "total_comparisons": 7,
        "line0_exact_matches": 2,
        "line0_exact_match_rate": 28.57,
        "proximity_matches": 3,
        "proximity_match_rate": 42.86,
        "avg_levenshtein": 26.43,
        "avg_edit_similarity": 0.42,
        "avg_first_line_edit_similarity": 0.42,
        "avg_cosine": 0.3
      },
      "dogfood/organization": {
        "total_comparisons": 8,
        "line0_exact_matches": 6,
        "line0_exact_match_rate": 75.0,
        "proximity_matches": 7,
        "proximity_match_rate": 87.5,
        "avg_levenshtein": 10.12,
        "avg_edit_similarity": 0.8,
        "avg_first_line_edit_similarity": 0.8,
        "avg_cosine": 0.85
      }
    },
    "languages": {
      "cpp": {
        "total_comparisons": 300,
        "line0_exact_matches": 163,
        "line0_exact_match_rate": 54.33,
        "proximity_matches": 250,
        "proximity_match_rate": 83.33,
        "avg_levenshtein": 12.0,
        "avg_edit_similarity": 0.73,
        "avg_first_line_edit_similarity": 0.73,
        "avg_cosine": 0.73
      },
      "c_sharp": {
        "total_comparisons": 300,
        "line0_exact_matches": 129,
        "line0_exact_match_rate": 43.0,
        "proximity_matches": 235,
        "proximity_match_rate": 78.33,
        "avg_levenshtein": 18.76,
        "avg_edit_similarity": 0.68,
        "avg_first_line_edit_similarity": 0.68,
        "avg_cosine": 0.65
      },
      "java": {
        "total_comparisons": 297,
        "line0_exact_matches": 158,
        "line0_exact_match_rate": 53.2,
        "proximity_matches": 241,
        "proximity_match_rate": 81.14,
        "avg_levenshtein": 16.13,
        "avg_edit_similarity": 0.71,
        "avg_first_line_edit_similarity": 0.71,
        "avg_cosine": 0.69
      },
      "javascript": {
        "total_comparisons": 300,
        "line0_exact_matches": 122,
        "line0_exact_match_rate": 40.67,
        "proximity_matches": 217,
        "proximity_match_rate": 72.33,
        "avg_levenshtein": 18.8,
        "avg_edit_similarity": 0.62,
        "avg_first_line_edit_similarity": 0.62,
        "avg_cosine": 0.6
      },
      "python": {
        "total_comparisons": 318,
        "line0_exact_matches": 142,
        "line0_exact_match_rate": 44.65,
        "proximity_matches": 252,
        "proximity_match_rate": 79.25,
        "avg_levenshtein": 14.57,
        "avg_edit_similarity": 0.67,
        "avg_first_line_edit_similarity": 0.67,
        "avg_cosine": 0.67
      },
      "typescript": {
        "total_comparisons": 300,
        "line0_exact_matches": 102,
        "line0_exact_match_rate": 34.0,
        "proximity_matches": 210,
        "proximity_match_rate": 70.0,
        "avg_levenshtein": 23.45,
        "avg_edit_similarity": 0.56,
        "avg_first_line_edit_similarity": 0.56,
        "avg_cosine": 0.55
      }
    }
  },
  "DeepSeek-V3-0324": {
    "overall": {
      "total_comparisons": 1810,
      "line0_exact_matches": 902,
      "line0_exact_match_rate": 49.83,
      "proximity_matches": 1448,
      "proximity_match_rate": 80.0,
      "avg_levenshtein": 15.21,
      "avg_edit_similarity": 0.69,
      "avg_first_line_edit_similarity": 0.69,
      "avg_cosine": 0.68
    },
    "categories": {
      "api_usage": {
        "total_comparisons": 297,
        "line0_exact_matches": 111,
        "line0_exact_match_rate": 37.37,
        "proximity_matches": 231,
        "proximity_match_rate": 77.78,
        "avg_levenshtein": 20.44,
        "avg_edit_similarity": 0.65,
        "avg_first_line_edit_similarity": 0.64,
        "avg_cosine": 0.63
      },
      "code2NL_NL2code": {
        "total_comparisons": 299,
        "line0_exact_matches": 135,
        "line0_exact_match_rate": 45.15,
        "proximity_matches": 175,
        "proximity_match_rate": 58.53,
        "avg_levenshtein": 17.37,
        "avg_edit_similarity": 0.53,
        "avg_first_line_edit_similarity": 0.53,
        "avg_cosine": 0.53
      },
      "code_purpose_understanding": {
        "total_comparisons": 300,
        "line0_exact_matches": 163,
        "line0_exact_match_rate": 54.33,
        "proximity_matches": 264,
        "proximity_match_rate": 88.0,
        "avg_levenshtein": 14.64,
        "avg_edit_similarity": 0.74,
        "avg_first_line_edit_similarity": 0.74,
        "avg_cosine": 0.73
      },
      "low_context": {
        "total_comparisons": 296,
        "line0_exact_matches": 177,
        "line0_exact_match_rate": 59.8,
        "proximity_matches": 263,
        "proximity_match_rate": 88.85,
        "avg_levenshtein": 8.31,
        "avg_edit_similarity": 0.8,
        "avg_first_line_edit_similarity": 0.8,
        "avg_cosine": 0.8
      },
      "pattern_matching": {
        "total_comparisons": 299,
        "line0_exact_matches": 170,
        "line0_exact_match_rate": 56.86,
        "proximity_matches": 258,
        "proximity_match_rate": 86.29,
        "avg_levenshtein": 14.01,
        "avg_edit_similarity": 0.77,
        "avg_first_line_edit_similarity": 0.77,
        "avg_cosine": 0.75
      },
      "syntax_completion": {
        "total_comparisons": 299,
        "line0_exact_matches": 136,
        "line0_exact_match_rate": 45.48,
        "proximity_matches": 243,
        "proximity_match_rate": 81.27,
        "avg_levenshtein": 16.21,
        "avg_edit_similarity": 0.68,
        "avg_first_line_edit_similarity": 0.68,
        "avg_cosine": 0.67
      },
      "dogfood/idiomatic": {
        "total_comparisons": 5,
        "line0_exact_matches": 2,
        "line0_exact_match_rate": 40.0,
        "proximity_matches": 2,
        "proximity_match_rate": 40.0,
        "avg_levenshtein": 16.8,
        "avg_edit_similarity": 0.49,
        "avg_first_line_edit_similarity": 0.49,
        "avg_cosine": 0.4
      },
      "dogfood/nl2code": {
        "total_comparisons": 7,
        "line0_exact_matches": 2,
        "line0_exact_match_rate": 28.57,
        "proximity_matches": 4,
        "proximity_match_rate": 57.14,
        "avg_levenshtein": 24.71,
        "avg_edit_similarity": 0.48,
        "avg_first_line_edit_similarity": 0.48,
        "avg_cosine": 0.35
      },
      "dogfood/organization": {
        "total_comparisons": 8,
        "line0_exact_matches": 6,
        "line0_exact_match_rate": 75.0,
        "proximity_matches": 8,
        "proximity_match_rate": 100.0,
        "avg_levenshtein": 14.62,
        "avg_edit_similarity": 0.79,
        "avg_first_line_edit_similarity": 0.79,
        "avg_cosine": 0.86
      }
    },
    "languages": {
      "cpp": {
        "total_comparisons": 300,
        "line0_exact_matches": 177,
        "line0_exact_match_rate": 59.0,
        "proximity_matches": 248,
        "proximity_match_rate": 82.67,
        "avg_levenshtein": 10.42,
        "avg_edit_similarity": 0.75,
        "avg_first_line_edit_similarity": 0.75,
        "avg_cosine": 0.75
      },
      "c_sharp": {
        "total_comparisons": 300,
        "line0_exact_matches": 134,
        "line0_exact_match_rate": 44.67,
        "proximity_matches": 248,
        "proximity_match_rate": 82.67,
        "avg_levenshtein": 18.07,
        "avg_edit_similarity": 0.7,
        "avg_first_line_edit_similarity": 0.7,
        "avg_cosine": 0.68
      },
      "java": {
        "total_comparisons": 299,
        "line0_exact_matches": 184,
        "line0_exact_match_rate": 61.54,
        "proximity_matches": 255,
        "proximity_match_rate": 85.28,
        "avg_levenshtein": 12.33,
        "avg_edit_similarity": 0.77,
        "avg_first_line_edit_similarity": 0.77,
        "avg_cosine": 0.76
      },
      "javascript": {
        "total_comparisons": 297,
        "line0_exact_matches": 131,
        "line0_exact_match_rate": 44.11,
        "proximity_matches": 215,
        "proximity_match_rate": 72.39,
        "avg_levenshtein": 16.39,
        "avg_edit_similarity": 0.64,
        "avg_first_line_edit_similarity": 0.64,
        "avg_cosine": 0.63
      },
      "python": {
        "total_comparisons": 318,
        "line0_exact_matches": 157,
        "line0_exact_match_rate": 49.37,
        "proximity_matches": 262,
        "proximity_match_rate": 82.39,
        "avg_levenshtein": 13.13,
        "avg_edit_similarity": 0.7,
        "avg_first_line_edit_similarity": 0.7,
        "avg_cosine": 0.7
      },
      "typescript": {
        "total_comparisons": 296,
        "line0_exact_matches": 119,
        "line0_exact_match_rate": 40.2,
        "proximity_matches": 220,
        "proximity_match_rate": 74.32,
        "avg_levenshtein": 21.1,
        "avg_edit_similarity": 0.6,
        "avg_first_line_edit_similarity": 0.6,
        "avg_cosine": 0.58
      }
    }
  },
  "gpt-35-turbo-completions": {
    "overall": {
      "total_comparisons": 1683,
      "line0_exact_matches": 735,
      "line0_exact_match_rate": 43.67,
      "proximity_matches": 1312,
      "proximity_match_rate": 77.96,
      "avg_levenshtein": 19.12,
      "avg_edit_similarity": 0.63,
      "avg_first_line_edit_similarity": 0.63,
      "avg_cosine": 0.6
    },
    "categories": {
      "api_usage": {
        "total_comparisons": 285,
        "line0_exact_matches": 91,
        "line0_exact_match_rate": 31.93,
        "proximity_matches": 227,
        "proximity_match_rate": 79.65,
        "avg_levenshtein": 23.71,
        "avg_edit_similarity": 0.57,
        "avg_first_line_edit_similarity": 0.57,
        "avg_cosine": 0.56
      },
      "code2NL_NL2code": {
        "total_comparisons": 276,
        "line0_exact_matches": 149,
        "line0_exact_match_rate": 53.99,
        "proximity_matches": 190,
        "proximity_match_rate": 68.84,
        "avg_levenshtein": 18.56,
        "avg_edit_similarity": 0.63,
        "avg_first_line_edit_similarity": 0.63,
        "avg_cosine": 0.62
      },
      "code_purpose_understanding": {
        "total_comparisons": 280,
        "line0_exact_matches": 125,
        "line0_exact_match_rate": 44.64,
        "proximity_matches": 231,
        "proximity_match_rate": 82.5,
        "avg_levenshtein": 18.65,
        "avg_edit_similarity": 0.65,
        "avg_first_line_edit_similarity": 0.65,
        "avg_cosine": 0.61
      },
      "low_context": {
        "total_comparisons": 272,
        "line0_exact_matches": 127,
        "line0_exact_match_rate": 46.69,
        "proximity_matches": 203,
        "proximity_match_rate": 74.63,
        "avg_levenshtein": 14.08,
        "avg_edit_similarity": 0.65,
        "avg_first_line_edit_similarity": 0.64,
        "avg_cosine": 0.64
      },
      "pattern_matching": {
        "total_comparisons": 267,
        "line0_exact_matches": 122,
        "line0_exact_match_rate": 45.69,
        "proximity_matches": 224,
        "proximity_match_rate": 83.9,
        "avg_levenshtein": 20.27,
        "avg_edit_similarity": 0.66,
        "avg_first_line_edit_similarity": 0.66,
        "avg_cosine": 0.62
      },
      "syntax_completion": {
        "total_comparisons": 283,
        "line0_exact_matches": 113,
        "line0_exact_match_rate": 39.93,
        "proximity_matches": 221,
        "proximity_match_rate": 78.09,
        "avg_levenshtein": 19.27,
        "avg_edit_similarity": 0.62,
        "avg_first_line_edit_similarity": 0.62,
        "avg_cosine": 0.6
      },
      "dogfood/idiomatic": {
        "total_comparisons": 5,
        "line0_exact_matches": 1,
        "line0_exact_match_rate": 20.0,
        "proximity_matches": 2,
        "proximity_match_rate": 40.0,
        "avg_levenshtein": 25.4,
        "avg_edit_similarity": 0.33,
        "avg_first_line_edit_similarity": 0.33,
        "avg_cosine": 0.2
      },
      "dogfood/nl2code": {
        "total_comparisons": 7,
        "line0_exact_matches": 1,
        "line0_exact_match_rate": 14.29,
        "proximity_matches": 6,
        "proximity_match_rate": 85.71,
        "avg_levenshtein": 26.29,
        "avg_edit_similarity": 0.41,
        "avg_first_line_edit_similarity": 0.41,
        "avg_cosine": 0.29
      },
      "dogfood/organization": {
        "total_comparisons": 8,
        "line0_exact_matches": 6,
        "line0_exact_match_rate": 75.0,
        "proximity_matches": 8,
        "proximity_match_rate": 100.0,
        "avg_levenshtein": 8.75,
        "avg_edit_similarity": 0.81,
        "avg_first_line_edit_similarity": 0.81,
        "avg_cosine": 0.9
      }
    },
    "languages": {
      "cpp": {
        "total_comparisons": 286,
        "line0_exact_matches": 137,
        "line0_exact_match_rate": 47.9,
        "proximity_matches": 212,
        "proximity_match_rate": 74.13,
        "avg_levenshtein": 17.94,
        "avg_edit_similarity": 0.64,
        "avg_first_line_edit_similarity": 0.64,
        "avg_cosine": 0.61
      },
      "c_sharp": {
        "total_comparisons": 282,
        "line0_exact_matches": 119,
        "line0_exact_match_rate": 42.2,
        "proximity_matches": 233,
        "proximity_match_rate": 82.62,
        "avg_levenshtein": 20.21,
        "avg_edit_similarity": 0.65,
        "avg_first_line_edit_similarity": 0.65,
        "avg_cosine": 0.62
      },
      "java": {
        "total_comparisons": 279,
        "line0_exact_matches": 156,
        "line0_exact_match_rate": 55.91,
        "proximity_matches": 234,
        "proximity_match_rate": 83.87,
        "avg_levenshtein": 16.07,
        "avg_edit_similarity": 0.71,
        "avg_first_line_edit_similarity": 0.71,
        "avg_cosine": 0.7
      },
      "javascript": {
        "total_comparisons": 278,
        "line0_exact_matches": 107,
        "line0_exact_match_rate": 38.49,
        "proximity_matches": 204,
        "proximity_match_rate": 73.38,
        "avg_levenshtein": 21.14,
        "avg_edit_similarity": 0.58,
        "avg_first_line_edit_similarity": 0.58,
        "avg_cosine": 0.55
      },
      "python": {
        "total_comparisons": 296,
        "line0_exact_matches": 140,
        "line0_exact_match_rate": 47.3,
        "proximity_matches": 243,
        "proximity_match_rate": 82.09,
        "avg_levenshtein": 12.75,
        "avg_edit_similarity": 0.7,
        "avg_first_line_edit_similarity": 0.7,
        "avg_cosine": 0.69
      },
      "typescript": {
        "total_comparisons": 262,
        "line0_exact_matches": 76,
        "line0_exact_match_rate": 29.01,
        "proximity_matches": 186,
        "proximity_match_rate": 70.99,
        "avg_levenshtein": 27.53,
        "avg_edit_similarity": 0.48,
        "avg_first_line_edit_similarity": 0.47,
        "avg_cosine": 0.45
      }
    }
  },
  "gpt-4.1-mini": {
    "overall": {
      "total_comparisons": 1710,
      "line0_exact_matches": 882,
      "line0_exact_match_rate": 51.58,
      "proximity_matches": 1368,
      "proximity_match_rate": 80.0,
      "avg_levenshtein": 14.93,
      "avg_edit_similarity": 0.71,
      "avg_first_line_edit_similarity": 0.7,
      "avg_cosine": 0.69
    },
    "categories": {
      "api_usage": {
        "total_comparisons": 283,
        "line0_exact_matches": 112,
        "line0_exact_match_rate": 39.58,
        "proximity_matches": 224,
        "proximity_match_rate": 79.15,
        "avg_levenshtein": 20.45,
        "avg_edit_similarity": 0.67,
        "avg_first_line_edit_similarity": 0.67,
        "avg_cosine": 0.66
      },
      "code2NL_NL2code": {
        "total_comparisons": 265,
        "line0_exact_matches": 126,
        "line0_exact_match_rate": 47.55,
        "proximity_matches": 161,
        "proximity_match_rate": 60.75,
        "avg_levenshtein": 17.04,
        "avg_edit_similarity": 0.56,
        "avg_first_line_edit_similarity": 0.56,
        "avg_cosine": 0.56
      },
      "code_purpose_understanding": {
        "total_comparisons": 292,
        "line0_exact_matches": 164,
        "line0_exact_match_rate": 56.16,
        "proximity_matches": 256,
        "proximity_match_rate": 87.67,
        "avg_levenshtein": 13.37,
        "avg_edit_similarity": 0.75,
        "avg_first_line_edit_similarity": 0.75,
        "avg_cosine": 0.74
      },
      "low_context": {
        "total_comparisons": 294,
        "line0_exact_matches": 185,
        "line0_exact_match_rate": 62.93,
        "proximity_matches": 253,
        "proximity_match_rate": 86.05,
        "avg_levenshtein": 8.45,
        "avg_edit_similarity": 0.8,
        "avg_first_line_edit_similarity": 0.8,
        "avg_cosine": 0.79
      },
      "pattern_matching": {
        "total_comparisons": 272,
        "line0_exact_matches": 152,
        "line0_exact_match_rate": 55.88,
        "proximity_matches": 238,
        "proximity_match_rate": 87.5,
        "avg_levenshtein": 13.22,
        "avg_edit_similarity": 0.77,
        "avg_first_line_edit_similarity": 0.77,
        "avg_cosine": 0.74
      },
      "syntax_completion": {
        "total_comparisons": 284,
        "line0_exact_matches": 133,
        "line0_exact_match_rate": 46.83,
        "proximity_matches": 221,
        "proximity_match_rate": 77.82,
        "avg_levenshtein": 17.3,
        "avg_edit_similarity": 0.68,
        "avg_first_line_edit_similarity": 0.68,
        "avg_cosine": 0.66
      },
      "dogfood/idiomatic": {
        "total_comparisons": 5,
        "line0_exact_matches": 2,
        "line0_exact_match_rate": 40.0,
        "proximity_matches": 2,
        "proximity_match_rate": 40.0,
        "avg_levenshtein": 16.8,
        "avg_edit_similarity": 0.49,
        "avg_first_line_edit_similarity": 0.49,
        "avg_cosine": 0.4
      },
      "dogfood/nl2code": {
        "total_comparisons": 7,
        "line0_exact_matches": 2,
        "line0_exact_match_rate": 28.57,
        "proximity_matches": 6,
        "proximity_match_rate": 85.71,
        "avg_levenshtein": 24.14,
        "avg_edit_similarity": 0.49,
        "avg_first_line_edit_similarity": 0.49,
        "avg_cosine": 0.35
      },
      "dogfood/organization": {
        "total_comparisons": 8,
        "line0_exact_matches": 6,
        "line0_exact_match_rate": 75.0,
        "proximity_matches": 7,
        "proximity_match_rate": 87.5,
        "avg_levenshtein": 10.38,
        "avg_edit_similarity": 0.78,
        "avg_first_line_edit_similarity": 0.78,
        "avg_cosine": 0.81
      }
    },
    "languages": {
      "cpp": {
        "total_comparisons": 287,
        "line0_exact_matches": 174,
        "line0_exact_match_rate": 60.63,
        "proximity_matches": 234,
        "proximity_match_rate": 81.53,
        "avg_levenshtein": 10.99,
        "avg_edit_similarity": 0.75,
        "avg_first_line_edit_similarity": 0.75,
        "avg_cosine": 0.75
      },
      "c_sharp": {
        "total_comparisons": 281,
        "line0_exact_matches": 138,
        "line0_exact_match_rate": 49.11,
        "proximity_matches": 241,
        "proximity_match_rate": 85.77,
        "avg_levenshtein": 16.15,
        "avg_edit_similarity": 0.73,
        "avg_first_line_edit_similarity": 0.73,
        "avg_cosine": 0.7
      },
      "java": {
        "total_comparisons": 282,
        "line0_exact_matches": 165,
        "line0_exact_match_rate": 58.51,
        "proximity_matches": 242,
        "proximity_match_rate": 85.82,
        "avg_levenshtein": 12.27,
        "avg_edit_similarity": 0.77,
        "avg_first_line_edit_similarity": 0.77,
        "avg_cosine": 0.77
      },
      "javascript": {
        "total_comparisons": 277,
        "line0_exact_matches": 132,
        "line0_exact_match_rate": 47.65,
        "proximity_matches": 204,
        "proximity_match_rate": 73.65,
        "avg_levenshtein": 15.9,
        "avg_edit_similarity": 0.67,
        "avg_first_line_edit_similarity": 0.67,
        "avg_cosine": 0.65
      },
      "python": {
        "total_comparisons": 313,
        "line0_exact_matches": 163,
        "line0_exact_match_rate": 52.08,
        "proximity_matches": 256,
        "proximity_match_rate": 81.79,
        "avg_levenshtein": 12.16,
        "avg_edit_similarity": 0.71,
        "avg_first_line_edit_similarity": 0.71,
        "avg_cosine": 0.71
      },
      "typescript": {
        "total_comparisons": 270,
        "line0_exact_matches": 110,
        "line0_exact_match_rate": 40.74,
        "proximity_matches": 191,
        "proximity_match_rate": 70.74,
        "avg_levenshtein": 22.86,
        "avg_edit_similarity": 0.58,
        "avg_first_line_edit_similarity": 0.58,
        "avg_cosine": 0.57
      }
    }
  },
  "gpt-4.1-nano": {
    "overall": {
      "total_comparisons": 1792,
      "line0_exact_matches": 667,
      "line0_exact_match_rate": 37.22,
      "proximity_matches": 1301,
      "proximity_match_rate": 72.6,
      "avg_levenshtein": 20.24,
      "avg_edit_similarity": 0.6,
      "avg_first_line_edit_similarity": 0.6,
      "avg_cosine": 0.58
    },
    "categories": {
      "api_usage": {
        "total_comparisons": 298,
        "line0_exact_matches": 90,
        "line0_exact_match_rate": 30.2,
        "proximity_matches": 219,
        "proximity_match_rate": 73.49,
        "avg_levenshtein": 24.62,
        "avg_edit_similarity": 0.59,
        "avg_first_line_edit_similarity": 0.59,
        "avg_cosine": 0.57
      },
      "code2NL_NL2code": {
        "total_comparisons": 295,
        "line0_exact_matches": 87,
        "line0_exact_match_rate": 29.49,
        "proximity_matches": 143,
        "proximity_match_rate": 48.47,
        "avg_levenshtein": 24.82,
        "avg_edit_similarity": 0.4,
        "avg_first_line_edit_similarity": 0.4,
        "avg_cosine": 0.4
      },
      "code_purpose_understanding": {
        "total_comparisons": 300,
        "line0_exact_matches": 127,
        "line0_exact_match_rate": 42.33,
        "proximity_matches": 246,
        "proximity_match_rate": 82.0,
        "avg_levenshtein": 19.6,
        "avg_edit_similarity": 0.66,
        "avg_first_line_edit_similarity": 0.66,
        "avg_cosine": 0.64
      },
      "low_context": {
        "total_comparisons": 298,
        "line0_exact_matches": 147,
        "line0_exact_match_rate": 49.33,
        "proximity_matches": 245,
        "proximity_match_rate": 82.21,
        "avg_levenshtein": 11.68,
        "avg_edit_similarity": 0.73,
        "avg_first_line_edit_similarity": 0.73,
        "avg_cosine": 0.73
      },
      "pattern_matching": {
        "total_comparisons": 288,
        "line0_exact_matches": 115,
        "line0_exact_match_rate": 39.93,
        "proximity_matches": 228,
        "proximity_match_rate": 79.17,
        "avg_levenshtein": 19.79,
        "avg_edit_similarity": 0.65,
        "avg_first_line_edit_similarity": 0.65,
        "avg_cosine": 0.61
      },
      "syntax_completion": {
        "total_comparisons": 293,
        "line0_exact_matches": 96,
        "line0_exact_match_rate": 32.76,
        "proximity_matches": 207,
        "proximity_match_rate": 70.65,
        "avg_levenshtein": 20.83,
        "avg_edit_similarity": 0.58,
        "avg_first_line_edit_similarity": 0.58,
        "avg_cosine": 0.55
      },
      "dogfood/idiomatic": {
        "total_comparisons": 5,
        "line0_exact_matches": 0,
        "line0_exact_match_rate": 0.0,
        "proximity_matches": 2,
        "proximity_match_rate": 40.0,
        "avg_levenshtein": 30.2,
        "avg_edit_similarity": 0.17,
        "avg_first_line_edit_similarity": 0.17,
        "avg_cosine": 0.09
      },
      "dogfood/nl2code": {
        "total_comparisons": 7,
        "line0_exact_matches": 1,
        "line0_exact_match_rate": 14.29,
        "proximity_matches": 6,
        "proximity_match_rate": 85.71,
        "avg_levenshtein": 26.57,
        "avg_edit_similarity": 0.42,
        "avg_first_line_edit_similarity": 0.42,
        "avg_cosine": 0.29
      },
      "dogfood/organization": {
        "total_comparisons": 8,
        "line0_exact_matches": 4,
        "line0_exact_match_rate": 50.0,
        "proximity_matches": 5,
        "proximity_match_rate": 62.5,
        "avg_levenshtein": 12.88,
        "avg_edit_similarity": 0.56,
        "avg_first_line_edit_similarity": 0.56,
        "avg_cosine": 0.64
      }
    },
    "languages": {
      "cpp": {
        "total_comparisons": 299,
        "line0_exact_matches": 145,
        "line0_exact_match_rate": 48.49,
        "proximity_matches": 225,
        "proximity_match_rate": 75.25,
        "avg_levenshtein": 16.93,
        "avg_edit_similarity": 0.65,
        "avg_first_line_edit_similarity": 0.65,
        "avg_cosine": 0.64
      },
      "c_sharp": {
        "total_comparisons": 299,
        "line0_exact_matches": 103,
        "line0_exact_match_rate": 34.45,
        "proximity_matches": 232,
        "proximity_match_rate": 77.59,
        "avg_levenshtein": 21.2,
        "avg_edit_similarity": 0.64,
        "avg_first_line_edit_similarity": 0.64,
        "avg_cosine": 0.6
      },
      "java": {
        "total_comparisons": 299,
        "line0_exact_matches": 136,
        "line0_exact_match_rate": 45.48,
        "proximity_matches": 234,
        "proximity_match_rate": 78.26,
        "avg_levenshtein": 17.47,
        "avg_edit_similarity": 0.67,
        "avg_first_line_edit_similarity": 0.67,
        "avg_cosine": 0.66
      },
      "javascript": {
        "total_comparisons": 290,
        "line0_exact_matches": 90,
        "line0_exact_match_rate": 31.03,
        "proximity_matches": 192,
        "proximity_match_rate": 66.21,
        "avg_levenshtein": 22.73,
        "avg_edit_similarity": 0.55,
        "avg_first_line_edit_similarity": 0.55,
        "avg_cosine": 0.52
      },
      "python": {
        "total_comparisons": 318,
        "line0_exact_matches": 111,
        "line0_exact_match_rate": 34.91,
        "proximity_matches": 228,
        "proximity_match_rate": 71.7,
        "avg_levenshtein": 17.01,
        "avg_edit_similarity": 0.59,
        "avg_first_line_edit_similarity": 0.59,
        "avg_cosine": 0.58
      },
      "typescript": {
        "total_comparisons": 287,
        "line0_exact_matches": 82,
        "line0_exact_match_rate": 28.57,
        "proximity_matches": 190,
        "proximity_match_rate": 66.2,
        "avg_levenshtein": 26.62,
        "avg_edit_similarity": 0.5,
        "avg_first_line_edit_similarity": 0.5,
        "avg_cosine": 0.49
      }
    }
  },
  "gpt-4.5-preview": {
    "overall": {
      "total_comparisons": 1755,
      "line0_exact_matches": 932,
      "line0_exact_match_rate": 53.11,
      "proximity_matches": 1448,
      "proximity_match_rate": 82.51,
      "avg_levenshtein": 14.82,
      "avg_edit_similarity": 0.72,
      "avg_first_line_edit_similarity": 0.72,
      "avg_cosine": 0.71
    },
    "categories": {
      "api_usage": {
        "total_comparisons": 297,
        "line0_exact_matches": 128,
        "line0_exact_match_rate": 43.1,
        "proximity_matches": 250,
        "proximity_match_rate": 84.18,
        "avg_levenshtein": 19.53,
        "avg_edit_similarity": 0.69,
        "avg_first_line_edit_similarity": 0.69,
        "avg_cosine": 0.68
      },
      "code2NL_NL2code": {
        "total_comparisons": 251,
        "line0_exact_matches": 132,
        "line0_exact_match_rate": 52.59,
        "proximity_matches": 164,
        "proximity_match_rate": 65.34,
        "avg_levenshtein": 15.77,
        "avg_edit_similarity": 0.62,
        "avg_first_line_edit_similarity": 0.62,
        "avg_cosine": 0.61
      },
      "code_purpose_understanding": {
        "total_comparisons": 299,
        "line0_exact_matches": 174,
        "line0_exact_match_rate": 58.19,
        "proximity_matches": 261,
        "proximity_match_rate": 87.29,
        "avg_levenshtein": 13.83,
        "avg_edit_similarity": 0.75,
        "avg_first_line_edit_similarity": 0.75,
        "avg_cosine": 0.74
      },
      "low_context": {
        "total_comparisons": 297,
        "line0_exact_matches": 191,
        "line0_exact_match_rate": 64.31,
        "proximity_matches": 262,
        "proximity_match_rate": 88.22,
        "avg_levenshtein": 8.04,
        "avg_edit_similarity": 0.82,
        "avg_first_line_edit_similarity": 0.82,
        "avg_cosine": 0.81
      },
      "pattern_matching": {
        "total_comparisons": 296,
        "line0_exact_matches": 162,
        "line0_exact_match_rate": 54.73,
        "proximity_matches": 258,
        "proximity_match_rate": 87.16,
        "avg_levenshtein": 14.83,
        "avg_edit_similarity": 0.75,
        "avg_first_line_edit_similarity": 0.75,
        "avg_cosine": 0.72
      },
      "syntax_completion": {
        "total_comparisons": 295,
        "line0_exact_matches": 135,
        "line0_exact_match_rate": 45.76,
        "proximity_matches": 240,
        "proximity_match_rate": 81.36,
        "avg_levenshtein": 16.91,
        "avg_edit_similarity": 0.68,
        "avg_first_line_edit_similarity": 0.68,
        "avg_cosine": 0.68
      },
      "dogfood/idiomatic": {
        "total_comparisons": 5,
        "line0_exact_matches": 2,
        "line0_exact_match_rate": 40.0,
        "proximity_matches": 2,
        "proximity_match_rate": 40.0,
        "avg_levenshtein": 18.2,
        "avg_edit_similarity": 0.48,
        "avg_first_line_edit_similarity": 0.48,
        "avg_cosine": 0.4
      },
      "dogfood/nl2code": {
        "total_comparisons": 7,
        "line0_exact_matches": 1,
        "line0_exact_match_rate": 14.29,
        "proximity_matches": 3,
        "proximity_match_rate": 42.86,
        "avg_levenshtein": 30.71,
        "avg_edit_similarity": 0.31,
        "avg_first_line_edit_similarity": 0.31,
        "avg_cosine": 0.24
      },
      "dogfood/organization": {
        "total_comparisons": 8,
        "line0_exact_matches": 7,
        "line0_exact_match_rate": 87.5,
        "proximity_matches": 8,
        "proximity_match_rate": 100.0,
        "avg_levenshtein": 6.25,
        "avg_edit_similarity": 0.9,
        "avg_first_line_edit_similarity": 0.9,
        "avg_cosine": 0.94
      }
    },
    "languages": {
      "cpp": {
        "total_comparisons": 286,
        "line0_exact_matches": 189,
        "line0_exact_match_rate": 66.08,
        "proximity_matches": 250,
        "proximity_match_rate": 87.41,
        "avg_levenshtein": 10.19,
        "avg_edit_similarity": 0.8,
        "avg_first_line_edit_similarity": 0.8,
        "avg_cosine": 0.79
      },
      "c_sharp": {
        "total_comparisons": 297,
        "line0_exact_matches": 145,
        "line0_exact_match_rate": 48.82,
        "proximity_matches": 253,
        "proximity_match_rate": 85.19,
        "avg_levenshtein": 16.75,
        "avg_edit_similarity": 0.73,
        "avg_first_line_edit_similarity": 0.73,
        "avg_cosine": 0.71
      },
      "java": {
        "total_comparisons": 290,
        "line0_exact_matches": 179,
        "line0_exact_match_rate": 61.72,
        "proximity_matches": 258,
        "proximity_match_rate": 88.97,
        "avg_levenshtein": 12.01,
        "avg_edit_similarity": 0.8,
        "avg_first_line_edit_similarity": 0.79,
        "avg_cosine": 0.79
      },
      "javascript": {
        "total_comparisons": 289,
        "line0_exact_matches": 138,
        "line0_exact_match_rate": 47.75,
        "proximity_matches": 218,
        "proximity_match_rate": 75.43,
        "avg_levenshtein": 16.7,
        "avg_edit_similarity": 0.66,
        "avg_first_line_edit_similarity": 0.66,
        "avg_cosine": 0.65
      },
      "python": {
        "total_comparisons": 316,
        "line0_exact_matches": 166,
        "line0_exact_match_rate": 52.53,
        "proximity_matches": 255,
        "proximity_match_rate": 80.7,
        "avg_levenshtein": 12.58,
        "avg_edit_similarity": 0.71,
        "avg_first_line_edit_similarity": 0.71,
        "avg_cosine": 0.7
      },
      "typescript": {
        "total_comparisons": 277,
        "line0_exact_matches": 115,
        "line0_exact_match_rate": 41.52,
        "proximity_matches": 214,
        "proximity_match_rate": 77.26,
        "avg_levenshtein": 21.08,
        "avg_edit_similarity": 0.62,
        "avg_first_line_edit_similarity": 0.62,
        "avg_cosine": 0.61
      }
    }
  },
  "gpt-4o-mini": {
    "overall": {
      "total_comparisons": 1817,
      "line0_exact_matches": 808,
      "line0_exact_match_rate": 44.47,
      "proximity_matches": 1374,
      "proximity_match_rate": 75.62,
      "avg_levenshtein": 17.79,
      "avg_edit_similarity": 0.65,
      "avg_first_line_edit_similarity": 0.64,
      "avg_cosine": 0.63
    },
    "categories": {
      "api_usage": {
        "total_comparisons": 299,
        "line0_exact_matches": 113,
        "line0_exact_match_rate": 37.79,
        "proximity_matches": 228,
        "proximity_match_rate": 76.25,
        "avg_levenshtein": 20.59,
        "avg_edit_similarity": 0.64,
        "avg_first_line_edit_similarity": 0.64,
        "avg_cosine": 0.62
      },
      "code2NL_NL2code": {
        "total_comparisons": 300,
        "line0_exact_matches": 110,
        "line0_exact_match_rate": 36.67,
        "proximity_matches": 153,
        "proximity_match_rate": 51.0,
        "avg_levenshtein": 21.65,
        "avg_edit_similarity": 0.46,
        "avg_first_line_edit_similarity": 0.46,
        "avg_cosine": 0.46
      },
      "code_purpose_understanding": {
        "total_comparisons": 300,
        "line0_exact_matches": 153,
        "line0_exact_match_rate": 51.0,
        "proximity_matches": 259,
        "proximity_match_rate": 86.33,
        "avg_levenshtein": 15.61,
        "avg_edit_similarity": 0.71,
        "avg_first_line_edit_similarity": 0.71,
        "avg_cosine": 0.7
      },
      "low_context": {
        "total_comparisons": 300,
        "line0_exact_matches": 171,
        "line0_exact_match_rate": 57.0,
        "proximity_matches": 260,
        "proximity_match_rate": 86.67,
        "avg_levenshtein": 10.88,
        "avg_edit_similarity": 0.77,
        "avg_first_line_edit_similarity": 0.77,
        "avg_cosine": 0.78
      },
      "pattern_matching": {
        "total_comparisons": 299,
        "line0_exact_matches": 140,
        "line0_exact_match_rate": 46.82,
        "proximity_matches": 246,
        "proximity_match_rate": 82.27,
        "avg_levenshtein": 18.63,
        "avg_edit_similarity": 0.68,
        "avg_first_line_edit_similarity": 0.68,
        "avg_cosine": 0.64
      },
      "syntax_completion": {
        "total_comparisons": 299,
        "line0_exact_matches": 114,
        "line0_exact_match_rate": 38.13,
        "proximity_matches": 217,
        "proximity_match_rate": 72.58,
        "avg_levenshtein": 19.25,
        "avg_edit_similarity": 0.61,
        "avg_first_line_edit_similarity": 0.61,
        "avg_cosine": 0.59
      },
      "dogfood/idiomatic": {
        "total_comparisons": 5,
        "line0_exact_matches": 0,
        "line0_exact_match_rate": 0.0,
        "proximity_matches": 1,
        "proximity_match_rate": 20.0,
        "avg_levenshtein": 29.8,
        "avg_edit_similarity": 0.17,
        "avg_first_line_edit_similarity": 0.17,
        "avg_cosine": 0.09
      },
      "dogfood/nl2code": {
        "total_comparisons": 7,
        "line0_exact_matches": 2,
        "line0_exact_match_rate": 28.57,
        "proximity_matches": 4,
        "proximity_match_rate": 57.14,
        "avg_levenshtein": 24.71,
        "avg_edit_similarity": 0.48,
        "avg_first_line_edit_similarity": 0.48,
        "avg_cosine": 0.35
      },
      "dogfood/organization": {
        "total_comparisons": 8,
        "line0_exact_matches": 5,
        "line0_exact_match_rate": 62.5,
        "proximity_matches": 6,
        "proximity_match_rate": 75.0,
        "avg_levenshtein": 11.0,
        "avg_edit_similarity": 0.68,
        "avg_first_line_edit_similarity": 0.68,
        "avg_cosine": 0.69
      }
    },
    "languages": {
      "cpp": {
        "total_comparisons": 300,
        "line0_exact_matches": 169,
        "line0_exact_match_rate": 56.33,
        "proximity_matches": 232,
        "proximity_match_rate": 77.33,
        "avg_levenshtein": 13.19,
        "avg_edit_similarity": 0.7,
        "avg_first_line_edit_similarity": 0.7,
        "avg_cosine": 0.7
      },
      "c_sharp": {
        "total_comparisons": 300,
        "line0_exact_matches": 128,
        "line0_exact_match_rate": 42.67,
        "proximity_matches": 246,
        "proximity_match_rate": 82.0,
        "avg_levenshtein": 19.03,
        "avg_edit_similarity": 0.68,
        "avg_first_line_edit_similarity": 0.68,
        "avg_cosine": 0.66
      },
      "java": {
        "total_comparisons": 300,
        "line0_exact_matches": 163,
        "line0_exact_match_rate": 54.33,
        "proximity_matches": 243,
        "proximity_match_rate": 81.0,
        "avg_levenshtein": 15.43,
        "avg_edit_similarity": 0.71,
        "avg_first_line_edit_similarity": 0.71,
        "avg_cosine": 0.7
      },
      "javascript": {
        "total_comparisons": 300,
        "line0_exact_matches": 120,
        "line0_exact_match_rate": 40.0,
        "proximity_matches": 214,
        "proximity_match_rate": 71.33,
        "avg_levenshtein": 19.27,
        "avg_edit_similarity": 0.6,
        "avg_first_line_edit_similarity": 0.6,
        "avg_cosine": 0.58
      },
      "python": {
        "total_comparisons": 320,
        "line0_exact_matches": 137,
        "line0_exact_match_rate": 42.81,
        "proximity_matches": 241,
        "proximity_match_rate": 75.31,
        "avg_levenshtein": 15.18,
        "avg_edit_similarity": 0.64,
        "avg_first_line_edit_similarity": 0.64,
        "avg_cosine": 0.63
      },
      "typescript": {
        "total_comparisons": 297,
        "line0_exact_matches": 91,
        "line0_exact_match_rate": 30.64,
        "proximity_matches": 198,
        "proximity_match_rate": 66.67,
        "avg_levenshtein": 24.91,
        "avg_edit_similarity": 0.53,
        "avg_first_line_edit_similarity": 0.53,
        "avg_cosine": 0.51
      }
    }
  },
  "gpt-4o": {
    "overall": {
      "total_comparisons": 1818,
      "line0_exact_matches": 936,
      "line0_exact_match_rate": 51.49,
      "proximity_matches": 1434,
      "proximity_match_rate": 78.88,
      "avg_levenshtein": 15.32,
      "avg_edit_similarity": 0.69,
      "avg_first_line_edit_similarity": 0.69,
      "avg_cosine": 0.68
    },
    "categories": {
      "api_usage": {
        "total_comparisons": 299,
        "line0_exact_matches": 130,
        "line0_exact_match_rate": 43.48,
        "proximity_matches": 244,
        "proximity_match_rate": 81.61,
        "avg_levenshtein": 18.48,
        "avg_edit_similarity": 0.69,
        "avg_first_line_edit_similarity": 0.69,
        "avg_cosine": 0.68
      },
      "code2NL_NL2code": {
        "total_comparisons": 299,
        "line0_exact_matches": 131,
        "line0_exact_match_rate": 43.81,
        "proximity_matches": 160,
        "proximity_match_rate": 53.51,
        "avg_levenshtein": 18.18,
        "avg_edit_similarity": 0.51,
        "avg_first_line_edit_similarity": 0.51,
        "avg_cosine": 0.51
      },
      "code_purpose_understanding": {
        "total_comparisons": 300,
        "line0_exact_matches": 170,
        "line0_exact_match_rate": 56.67,
        "proximity_matches": 262,
        "proximity_match_rate": 87.33,
        "avg_levenshtein": 13.97,
        "avg_edit_similarity": 0.74,
        "avg_first_line_edit_similarity": 0.74,
        "avg_cosine": 0.72
      },
      "low_context": {
        "total_comparisons": 300,
        "line0_exact_matches": 195,
        "line0_exact_match_rate": 65.0,
        "proximity_matches": 267,
        "proximity_match_rate": 89.0,
        "avg_levenshtein": 8.29,
        "avg_edit_similarity": 0.82,
        "avg_first_line_edit_similarity": 0.82,
        "avg_cosine": 0.82
      },
      "pattern_matching": {
        "total_comparisons": 300,
        "line0_exact_matches": 165,
        "line0_exact_match_rate": 55.0,
        "proximity_matches": 254,
        "proximity_match_rate": 84.67,
        "avg_levenshtein": 15.06,
        "avg_edit_similarity": 0.74,
        "avg_first_line_edit_similarity": 0.74,
        "avg_cosine": 0.71
      },
      "syntax_completion": {
        "total_comparisons": 300,
        "line0_exact_matches": 136,
        "line0_exact_match_rate": 45.33,
        "proximity_matches": 234,
        "proximity_match_rate": 78.0,
        "avg_levenshtein": 17.76,
        "avg_edit_similarity": 0.67,
        "avg_first_line_edit_similarity": 0.67,
        "avg_cosine": 0.65
      },
      "dogfood/idiomatic": {
        "total_comparisons": 5,
        "line0_exact_matches": 2,
        "line0_exact_match_rate": 40.0,
        "proximity_matches": 2,
        "proximity_match_rate": 40.0,
        "avg_levenshtein": 16.8,
        "avg_edit_similarity": 0.51,
        "avg_first_line_edit_similarity": 0.51,
        "avg_cosine": 0.4
      },
      "dogfood/nl2code": {
        "total_comparisons": 7,
        "line0_exact_matches": 1,
        "line0_exact_match_rate": 14.29,
        "proximity_matches": 4,
        "proximity_match_rate": 57.14,
        "avg_levenshtein": 29.0,
        "avg_edit_similarity": 0.37,
        "avg_first_line_edit_similarity": 0.37,
        "avg_cosine": 0.29
      },
      "dogfood/organization": {
        "total_comparisons": 8,
        "line0_exact_matches": 6,
        "line0_exact_match_rate": 75.0,
        "proximity_matches": 7,
        "proximity_match_rate": 87.5,
        "avg_levenshtein": 10.38,
        "avg_edit_similarity": 0.78,
        "avg_first_line_edit_similarity": 0.78,
        "avg_cosine": 0.81
      }
    },
    "languages": {
      "cpp": {
        "total_comparisons": 300,
        "line0_exact_matches": 185,
        "line0_exact_match_rate": 61.67,
        "proximity_matches": 244,
        "proximity_match_rate": 81.33,
        "avg_levenshtein": 9.93,
        "avg_edit_similarity": 0.76,
        "avg_first_line_edit_similarity": 0.76,
        "avg_cosine": 0.75
      },
      "c_sharp": {
        "total_comparisons": 300,
        "line0_exact_matches": 153,
        "line0_exact_match_rate": 51.0,
        "proximity_matches": 253,
        "proximity_match_rate": 84.33,
        "avg_levenshtein": 17.18,
        "avg_edit_similarity": 0.72,
        "avg_first_line_edit_similarity": 0.72,
        "avg_cosine": 0.69
      },
      "java": {
        "total_comparisons": 299,
        "line0_exact_matches": 187,
        "line0_exact_match_rate": 62.54,
        "proximity_matches": 253,
        "proximity_match_rate": 84.62,
        "avg_levenshtein": 12.25,
        "avg_edit_similarity": 0.77,
        "avg_first_line_edit_similarity": 0.77,
        "avg_cosine": 0.76
      },
      "javascript": {
        "total_comparisons": 299,
        "line0_exact_matches": 143,
        "line0_exact_match_rate": 47.83,
        "proximity_matches": 219,
        "proximity_match_rate": 73.24,
        "avg_levenshtein": 16.45,
        "avg_edit_similarity": 0.65,
        "avg_first_line_edit_similarity": 0.65,
        "avg_cosine": 0.63
      },
      "python": {
        "total_comparisons": 320,
        "line0_exact_matches": 155,
        "line0_exact_match_rate": 48.44,
        "proximity_matches": 252,
        "proximity_match_rate": 78.75,
        "avg_levenshtein": 13.06,
        "avg_edit_similarity": 0.69,
        "avg_first_line_edit_similarity": 0.69,
        "avg_cosine": 0.68
      },
      "typescript": {
        "total_comparisons": 300,
        "line0_exact_matches": 113,
        "line0_exact_match_rate": 37.67,
        "proximity_matches": 213,
        "proximity_match_rate": 71.0,
        "avg_levenshtein": 23.2,
        "avg_edit_similarity": 0.57,
        "avg_first_line_edit_similarity": 0.57,
        "avg_cosine": 0.56
      }
    }
  },
  "Ministral-3B": {
    "overall": {
      "total_comparisons": 1820,
      "line0_exact_matches": 421,
      "line0_exact_match_rate": 23.13,
      "proximity_matches": 1119,
      "proximity_match_rate": 61.48,
      "avg_levenshtein": 26.21,
      "avg_edit_similarity": 0.48,
      "avg_first_line_edit_similarity": 0.48,
      "avg_cosine": 0.45
    },
    "categories": {
      "api_usage": {
        "total_comparisons": 300,
        "line0_exact_matches": 56,
        "line0_exact_match_rate": 18.67,
        "proximity_matches": 196,
        "proximity_match_rate": 65.33,
        "avg_levenshtein": 30.28,
        "avg_edit_similarity": 0.48,
        "avg_first_line_edit_similarity": 0.48,
        "avg_cosine": 0.45
      },
      "code2NL_NL2code": {
        "total_comparisons": 300,
        "line0_exact_matches": 66,
        "line0_exact_match_rate": 22.0,
        "proximity_matches": 126,
        "proximity_match_rate": 42.0,
        "avg_levenshtein": 28.23,
        "avg_edit_similarity": 0.34,
        "avg_first_line_edit_similarity": 0.34,
        "avg_cosine": 0.32
      },
      "code_purpose_understanding": {
        "total_comparisons": 300,
        "line0_exact_matches": 84,
        "line0_exact_match_rate": 28.0,
        "proximity_matches": 216,
        "proximity_match_rate": 72.0,
        "avg_levenshtein": 25.65,
        "avg_edit_similarity": 0.55,
        "avg_first_line_edit_similarity": 0.54,
        "avg_cosine": 0.51
      },
      "low_context": {
        "total_comparisons": 300,
        "line0_exact_matches": 79,
        "line0_exact_match_rate": 26.33,
        "proximity_matches": 180,
        "proximity_match_rate": 60.0,
        "avg_levenshtein": 20.75,
        "avg_edit_similarity": 0.51,
        "avg_first_line_edit_similarity": 0.51,
        "avg_cosine": 0.5
      },
      "pattern_matching": {
        "total_comparisons": 300,
        "line0_exact_matches": 71,
        "line0_exact_match_rate": 23.67,
        "proximity_matches": 205,
        "proximity_match_rate": 68.33,
        "avg_levenshtein": 26.09,
        "avg_edit_similarity": 0.53,
        "avg_first_line_edit_similarity": 0.53,
        "avg_cosine": 0.46
      },
      "syntax_completion": {
        "total_comparisons": 300,
        "line0_exact_matches": 58,
        "line0_exact_match_rate": 19.33,
        "proximity_matches": 184,
        "proximity_match_rate": 61.33,
        "avg_levenshtein": 26.38,
        "avg_edit_similarity": 0.47,
        "avg_first_line_edit_similarity": 0.46,
        "avg_cosine": 0.43
      },
      "dogfood/idiomatic": {
        "total_comparisons": 5,
        "line0_exact_matches": 1,
        "line0_exact_match_rate": 20.0,
        "proximity_matches": 3,
        "proximity_match_rate": 60.0,
        "avg_levenshtein": 25.8,
        "avg_edit_similarity": 0.35,
        "avg_first_line_edit_similarity": 0.35,
        "avg_cosine": 0.22
      },
      "dogfood/nl2code": {
        "total_comparisons": 7,
        "line0_exact_matches": 1,
        "line0_exact_match_rate": 14.29,
        "proximity_matches": 3,
        "proximity_match_rate": 42.86,
        "avg_levenshtein": 30.86,
        "avg_edit_similarity": 0.31,
        "avg_first_line_edit_similarity": 0.31,
        "avg_cosine": 0.29
      },
      "dogfood/organization": {
        "total_comparisons": 8,
        "line0_exact_matches": 5,
        "line0_exact_match_rate": 62.5,
        "proximity_matches": 6,
        "proximity_match_rate": 75.0,
        "avg_levenshtein": 17.38,
        "avg_edit_similarity": 0.68,
        "avg_first_line_edit_similarity": 0.68,
        "avg_cosine": 0.69
      }
    },
    "languages": {
      "cpp": {
        "total_comparisons": 300,
        "line0_exact_matches": 68,
        "line0_exact_match_rate": 22.67,
        "proximity_matches": 154,
        "proximity_match_rate": 51.33,
        "avg_levenshtein": 24.68,
        "avg_edit_similarity": 0.46,
        "avg_first_line_edit_similarity": 0.46,
        "avg_cosine": 0.42
      },
      "c_sharp": {
        "total_comparisons": 300,
        "line0_exact_matches": 76,
        "line0_exact_match_rate": 25.33,
        "proximity_matches": 225,
        "proximity_match_rate": 75.0,
        "avg_levenshtein": 27.44,
        "avg_edit_similarity": 0.54,
        "avg_first_line_edit_similarity": 0.54,
        "avg_cosine": 0.51
      },
      "java": {
        "total_comparisons": 300,
        "line0_exact_matches": 83,
        "line0_exact_match_rate": 27.67,
        "proximity_matches": 199,
        "proximity_match_rate": 66.33,
        "avg_levenshtein": 25.99,
        "avg_edit_similarity": 0.54,
        "avg_first_line_edit_similarity": 0.53,
        "avg_cosine": 0.5
      },
      "javascript": {
        "total_comparisons": 300,
        "line0_exact_matches": 56,
        "line0_exact_match_rate": 18.67,
        "proximity_matches": 161,
        "proximity_match_rate": 53.67,
        "avg_levenshtein": 27.04,
        "avg_edit_similarity": 0.42,
        "avg_first_line_edit_similarity": 0.42,
        "avg_cosine": 0.38
      },
      "python": {
        "total_comparisons": 320,
        "line0_exact_matches": 94,
        "line0_exact_match_rate": 29.38,
        "proximity_matches": 212,
        "proximity_match_rate": 66.25,
        "avg_levenshtein": 20.52,
        "avg_edit_similarity": 0.52,
        "avg_first_line_edit_similarity": 0.52,
        "avg_cosine": 0.51
      },
      "typescript": {
        "total_comparisons": 300,
        "line0_exact_matches": 44,
        "line0_exact_match_rate": 14.67,
        "proximity_matches": 168,
        "proximity_match_rate": 56.0,
        "avg_levenshtein": 31.96,
        "avg_edit_similarity": 0.39,
        "avg_first_line_edit_similarity": 0.39,
        "avg_cosine": 0.35
      }
    }
  },
  "o1-mini": {
    "overall": {
      "total_comparisons": 64,
      "line0_exact_matches": 42,
      "line0_exact_match_rate": 65.62,
      "proximity_matches": 56,
      "proximity_match_rate": 87.5,
      "avg_levenshtein": 8.92,
      "avg_edit_similarity": 0.83,
      "avg_first_line_edit_similarity": 0.83,
      "avg_cosine": 0.81
    },
    "categories": {
      "api_usage": {
        "total_comparisons": 15,
        "line0_exact_matches": 9,
        "line0_exact_match_rate": 60.0,
        "proximity_matches": 13,
        "proximity_match_rate": 86.67,
        "avg_levenshtein": 7.93,
        "avg_edit_similarity": 0.86,
        "avg_first_line_edit_similarity": 0.86,
        "avg_cosine": 0.84
      },
      "code2NL_NL2code": {
        "total_comparisons": 8,
        "line0_exact_matches": 6,
        "line0_exact_match_rate": 75.0,
        "proximity_matches": 7,
        "proximity_match_rate": 87.5,
        "avg_levenshtein": 9.0,
        "avg_edit_similarity": 0.86,
        "avg_first_line_edit_similarity": 0.86,
        "avg_cosine": 0.86
      },
      "code_purpose_understanding": {
        "total_comparisons": 10,
        "line0_exact_matches": 6,
        "line0_exact_match_rate": 60.0,
        "proximity_matches": 9,
        "proximity_match_rate": 90.0,
        "avg_levenshtein": 13.7,
        "avg_edit_similarity": 0.8,
        "avg_first_line_edit_similarity": 0.8,
        "avg_cosine": 0.82
      },
      "low_context": {
        "total_comparisons": 18,
        "line0_exact_matches": 13,
        "line0_exact_match_rate": 72.22,
        "proximity_matches": 15,
        "proximity_match_rate": 83.33,
        "avg_levenshtein": 4.39,
        "avg_edit_similarity": 0.85,
        "avg_first_line_edit_similarity": 0.85,
        "avg_cosine": 0.86
      },
      "syntax_completion": {
        "total_comparisons": 7,
        "line0_exact_matches": 5,
        "line0_exact_match_rate": 71.43,
        "proximity_matches": 6,
        "proximity_match_rate": 85.71,
        "avg_levenshtein": 6.57,
        "avg_edit_similarity": 0.82,
        "avg_first_line_edit_similarity": 0.83,
        "avg_cosine": 0.83
      },
      "pattern_matching": {
        "total_comparisons": 5,
        "line0_exact_matches": 3,
        "line0_exact_match_rate": 60.0,
        "proximity_matches": 5,
        "proximity_match_rate": 100.0,
        "avg_levenshtein": 16.4,
        "avg_edit_similarity": 0.75,
        "avg_first_line_edit_similarity": 0.75,
        "avg_cosine": 0.6
      },
      "dogfood/nl2code": {
        "total_comparisons": 1,
        "line0_exact_matches": 0,
        "line0_exact_match_rate": 0.0,
        "proximity_matches": 1,
        "proximity_match_rate": 100.0,
        "avg_levenshtein": 36.0,
        "avg_edit_similarity": 0.28,
        "avg_first_line_edit_similarity": 0.28,
        "avg_cosine": 0.09
      }
    },
    "languages": {
      "cpp": {
        "total_comparisons": 18,
        "line0_exact_matches": 16,
        "line0_exact_match_rate": 88.89,
        "proximity_matches": 17,
        "proximity_match_rate": 94.44,
        "avg_levenshtein": 0.72,
        "avg_edit_similarity": 0.98,
        "avg_first_line_edit_similarity": 0.98,
        "avg_cosine": 0.99
      },
      "c_sharp": {
        "total_comparisons": 11,
        "line0_exact_matches": 7,
        "line0_exact_match_rate": 63.64,
        "proximity_matches": 9,
        "proximity_match_rate": 81.82,
        "avg_levenshtein": 12.73,
        "avg_edit_similarity": 0.75,
        "avg_first_line_edit_similarity": 0.75,
        "avg_cosine": 0.72
      },
      "java": {
        "total_comparisons": 15,
        "line0_exact_matches": 12,
        "line0_exact_match_rate": 80.0,
        "proximity_matches": 14,
        "proximity_match_rate": 93.33,
        "avg_levenshtein": 5.6,
        "avg_edit_similarity": 0.9,
        "avg_first_line_edit_similarity": 0.89,
        "avg_cosine": 0.84
      },
      "javascript": {
        "total_comparisons": 4,
        "line0_exact_matches": 3,
        "line0_exact_match_rate": 75.0,
        "proximity_matches": 3,
        "proximity_match_rate": 75.0,
        "avg_levenshtein": 4.5,
        "avg_edit_similarity": 0.78,
        "avg_first_line_edit_similarity": 0.78,
        "avg_cosine": 0.75
      },
      "python": {
        "total_comparisons": 6,
        "line0_exact_matches": 3,
        "line0_exact_match_rate": 50.0,
        "proximity_matches": 5,
        "proximity_match_rate": 83.33,
        "avg_levenshtein": 17.5,
        "avg_edit_similarity": 0.72,
        "avg_first_line_edit_similarity": 0.72,
        "avg_cosine": 0.76
      },
      "typescript": {
        "total_comparisons": 10,
        "line0_exact_matches": 1,
        "line0_exact_match_rate": 10.0,
        "proximity_matches": 8,
        "proximity_match_rate": 80.0,
        "avg_levenshtein": 21.1,
        "avg_edit_similarity": 0.61,
        "avg_first_line_edit_similarity": 0.61,
        "avg_cosine": 0.62
      }
    }
  },
  "o1-preview": {
    "overall": {
      "total_comparisons": 79,
      "line0_exact_matches": 58,
      "line0_exact_match_rate": 73.42,
      "proximity_matches": 74,
      "proximity_match_rate": 93.67,
      "avg_levenshtein": 4.04,
      "avg_edit_similarity": 0.9,
      "avg_first_line_edit_similarity": 0.9,
      "avg_cosine": 0.89
    },
    "categories": {
      "api_usage": {
        "total_comparisons": 11,
        "line0_exact_matches": 7,
        "line0_exact_match_rate": 63.64,
        "proximity_matches": 10,
        "proximity_match_rate": 90.91,
        "avg_levenshtein": 8.27,
        "avg_edit_similarity": 0.89,
        "avg_first_line_edit_similarity": 0.88,
        "avg_cosine": 0.88
      },
      "code2NL_NL2code": {
        "total_comparisons": 7,
        "line0_exact_matches": 5,
        "line0_exact_match_rate": 71.43,
        "proximity_matches": 6,
        "proximity_match_rate": 85.71,
        "avg_levenshtein": 8.14,
        "avg_edit_similarity": 0.77,
        "avg_first_line_edit_similarity": 0.77,
        "avg_cosine": 0.81
      },
      "code_purpose_understanding": {
        "total_comparisons": 15,
        "line0_exact_matches": 9,
        "line0_exact_match_rate": 60.0,
        "proximity_matches": 13,
        "proximity_match_rate": 86.67,
        "avg_levenshtein": 6.4,
        "avg_edit_similarity": 0.81,
        "avg_first_line_edit_similarity": 0.81,
        "avg_cosine": 0.78
      },
      "low_context": {
        "total_comparisons": 34,
        "line0_exact_matches": 27,
        "line0_exact_match_rate": 79.41,
        "proximity_matches": 33,
        "proximity_match_rate": 97.06,
        "avg_levenshtein": 1.59,
        "avg_edit_similarity": 0.95,
        "avg_first_line_edit_similarity": 0.95,
        "avg_cosine": 0.93
      },
      "pattern_matching": {
        "total_comparisons": 7,
        "line0_exact_matches": 7,
        "line0_exact_match_rate": 100.0,
        "proximity_matches": 7,
        "proximity_match_rate": 100.0,
        "avg_levenshtein": 0.0,
        "avg_edit_similarity": 1.0,
        "avg_first_line_edit_similarity": 1.0,
        "avg_cosine": 1.0
      },
      "syntax_completion": {
        "total_comparisons": 5,
        "line0_exact_matches": 3,
        "line0_exact_match_rate": 60.0,
        "proximity_matches": 5,
        "proximity_match_rate": 100.0,
        "avg_levenshtein": 4.2,
        "avg_edit_similarity": 0.91,
        "avg_first_line_edit_similarity": 0.91,
        "avg_cosine": 0.95
      }
    },
    "languages": {
      "cpp": {
        "total_comparisons": 15,
        "line0_exact_matches": 11,
        "line0_exact_match_rate": 73.33,
        "proximity_matches": 14,
        "proximity_match_rate": 93.33,
        "avg_levenshtein": 4.13,
        "avg_edit_similarity": 0.9,
        "avg_first_line_edit_similarity": 0.9,
        "avg_cosine": 0.9
      },
      "c_sharp": {
        "total_comparisons": 7,
        "line0_exact_matches": 4,
        "line0_exact_match_rate": 57.14,
        "proximity_matches": 7,
        "proximity_match_rate": 100.0,
        "avg_levenshtein": 2.43,
        "avg_edit_similarity": 0.95,
        "avg_first_line_edit_similarity": 0.96,
        "avg_cosine": 0.93
      },
      "java": {
        "total_comparisons": 20,
        "line0_exact_matches": 16,
        "line0_exact_match_rate": 80.0,
        "proximity_matches": 19,
        "proximity_match_rate": 95.0,
        "avg_levenshtein": 4.65,
        "avg_edit_similarity": 0.92,
        "avg_first_line_edit_similarity": 0.92,
        "avg_cosine": 0.92
      },
      "javascript": {
        "total_comparisons": 5,
        "line0_exact_matches": 3,
        "line0_exact_match_rate": 60.0,
        "proximity_matches": 4,
        "proximity_match_rate": 80.0,
        "avg_levenshtein": 1.6,
        "avg_edit_similarity": 0.95,
        "avg_first_line_edit_similarity": 0.94,
        "avg_cosine": 0.82
      },
      "python": {
        "total_comparisons": 28,
        "line0_exact_matches": 20,
        "line0_exact_match_rate": 71.43,
        "proximity_matches": 26,
        "proximity_match_rate": 92.86,
        "avg_levenshtein": 4.96,
        "avg_edit_similarity": 0.85,
        "avg_first_line_edit_similarity": 0.85,
        "avg_cosine": 0.86
      },
      "typescript": {
        "total_comparisons": 4,
        "line0_exact_matches": 4,
        "line0_exact_match_rate": 100.0,
        "proximity_matches": 4,
        "proximity_match_rate": 100.0,
        "avg_levenshtein": 0.0,
        "avg_edit_similarity": 1.0,
        "avg_first_line_edit_similarity": 1.0,
        "avg_cosine": 1.0
      }
    }
  },
  "o3-mini": {
    "overall": {
      "total_comparisons": 1606,
      "line0_exact_matches": 741,
      "line0_exact_match_rate": 46.14,
      "proximity_matches": 1267,
      "proximity_match_rate": 78.89,
      "avg_levenshtein": 17.25,
      "avg_edit_similarity": 0.68,
      "avg_first_line_edit_similarity": 0.68,
      "avg_cosine": 0.66
    },
    "categories": {
      "api_usage": {
        "total_comparisons": 277,
        "line0_exact_matches": 103,
        "line0_exact_match_rate": 37.18,
        "proximity_matches": 222,
        "proximity_match_rate": 80.14,
        "avg_levenshtein": 23.6,
        "avg_edit_similarity": 0.63,
        "avg_first_line_edit_similarity": 0.63,
        "avg_cosine": 0.63
      },
      "code2NL_NL2code": {
        "total_comparisons": 219,
        "line0_exact_matches": 104,
        "line0_exact_match_rate": 47.49,
        "proximity_matches": 143,
        "proximity_match_rate": 65.3,
        "avg_levenshtein": 18.36,
        "avg_edit_similarity": 0.59,
        "avg_first_line_edit_similarity": 0.59,
        "avg_cosine": 0.58
      },
      "code_purpose_understanding": {
        "total_comparisons": 286,
        "line0_exact_matches": 142,
        "line0_exact_match_rate": 49.65,
        "proximity_matches": 240,
        "proximity_match_rate": 83.92,
        "avg_levenshtein": 15.87,
        "avg_edit_similarity": 0.72,
        "avg_first_line_edit_similarity": 0.72,
        "avg_cosine": 0.7
      },
      "low_context": {
        "total_comparisons": 276,
        "line0_exact_matches": 167,
        "line0_exact_match_rate": 60.51,
        "proximity_matches": 241,
        "proximity_match_rate": 87.32,
        "avg_levenshtein": 7.88,
        "avg_edit_similarity": 0.81,
        "avg_first_line_edit_similarity": 0.81,
        "avg_cosine": 0.8
      },
      "pattern_matching": {
        "total_comparisons": 258,
        "line0_exact_matches": 114,
        "line0_exact_match_rate": 44.19,
        "proximity_matches": 204,
        "proximity_match_rate": 79.07,
        "avg_levenshtein": 18.28,
        "avg_edit_similarity": 0.68,
        "avg_first_line_edit_similarity": 0.68,
        "avg_cosine": 0.64
      },
      "syntax_completion": {
        "total_comparisons": 270,
        "line0_exact_matches": 103,
        "line0_exact_match_rate": 38.15,
        "proximity_matches": 205,
        "proximity_match_rate": 75.93,
        "avg_levenshtein": 19.65,
        "avg_edit_similarity": 0.63,
        "avg_first_line_edit_similarity": 0.62,
        "avg_cosine": 0.62
      },
      "dogfood/idiomatic": {
        "total_comparisons": 5,
        "line0_exact_matches": 1,
        "line0_exact_match_rate": 20.0,
        "proximity_matches": 2,
        "proximity_match_rate": 40.0,
        "avg_levenshtein": 26.0,
        "avg_edit_similarity": 0.34,
        "avg_first_line_edit_similarity": 0.34,
        "avg_cosine": 0.22
      },
      "dogfood/nl2code": {
        "total_comparisons": 7,
        "line0_exact_matches": 2,
        "line0_exact_match_rate": 28.57,
        "proximity_matches": 4,
        "proximity_match_rate": 57.14,
        "avg_levenshtein": 25.43,
        "avg_edit_similarity": 0.47,
        "avg_first_line_edit_similarity": 0.47,
        "avg_cosine": 0.38
      },
      "dogfood/organization": {
        "total_comparisons": 8,
        "line0_exact_matches": 5,
        "line0_exact_match_rate": 62.5,
        "proximity_matches": 6,
        "proximity_match_rate": 75.0,
        "avg_levenshtein": 12.12,
        "avg_edit_similarity": 0.67,
        "avg_first_line_edit_similarity": 0.67,
        "avg_cosine": 0.69
      }
    },
    "languages": {
      "cpp": {
        "total_comparisons": 265,
        "line0_exact_matches": 164,
        "line0_exact_match_rate": 61.89,
        "proximity_matches": 230,
        "proximity_match_rate": 86.79,
        "avg_levenshtein": 10.59,
        "avg_edit_similarity": 0.79,
        "avg_first_line_edit_similarity": 0.78,
        "avg_cosine": 0.78
      },
      "c_sharp": {
        "total_comparisons": 262,
        "line0_exact_matches": 109,
        "line0_exact_match_rate": 41.6,
        "proximity_matches": 222,
        "proximity_match_rate": 84.73,
        "avg_levenshtein": 19.29,
        "avg_edit_similarity": 0.69,
        "avg_first_line_edit_similarity": 0.69,
        "avg_cosine": 0.67
      },
      "java": {
        "total_comparisons": 260,
        "line0_exact_matches": 146,
        "line0_exact_match_rate": 56.15,
        "proximity_matches": 219,
        "proximity_match_rate": 84.23,
        "avg_levenshtein": 14.87,
        "avg_edit_similarity": 0.76,
        "avg_first_line_edit_similarity": 0.76,
        "avg_cosine": 0.74
      },
      "javascript": {
        "total_comparisons": 268,
        "line0_exact_matches": 105,
        "line0_exact_match_rate": 39.18,
        "proximity_matches": 189,
        "proximity_match_rate": 70.52,
        "avg_levenshtein": 20.68,
        "avg_edit_similarity": 0.61,
        "avg_first_line_edit_similarity": 0.61,
        "avg_cosine": 0.6
      },
      "python": {
        "total_comparisons": 308,
        "line0_exact_matches": 139,
        "line0_exact_match_rate": 45.13,
        "proximity_matches": 231,
        "proximity_match_rate": 75.0,
        "avg_levenshtein": 14.71,
        "avg_edit_similarity": 0.65,
        "avg_first_line_edit_similarity": 0.65,
        "avg_cosine": 0.64
      },
      "typescript": {
        "total_comparisons": 243,
        "line0_exact_matches": 78,
        "line0_exact_match_rate": 32.1,
        "proximity_matches": 176,
        "proximity_match_rate": 72.43,
        "avg_levenshtein": 24.27,
        "avg_edit_similarity": 0.57,
        "avg_first_line_edit_similarity": 0.56,
        "avg_cosine": 0.55
      }
    }
  },
  "assertions": {
    "overall": {
      "total_comparisons": 13572,
      "line0_exact_matches": 494,
      "line0_exact_match_rate": 3.64,
      "proximity_matches": 5340,
      "proximity_match_rate": 39.35,
      "avg_levenshtein": 43.13,
      "avg_edit_similarity": 0.22,
      "avg_first_line_edit_similarity": 0.22,
      "avg_cosine": 0.12
    },
    "categories": {
      "api_usage": {
        "total_comparisons": 2145,
        "line0_exact_matches": 165,
        "line0_exact_match_rate": 7.69,
        "proximity_matches": 1080,
        "proximity_match_rate": 50.35,
        "avg_levenshtein": 44.69,
        "avg_edit_similarity": 0.27,
        "avg_first_line_edit_similarity": 0.27,
        "avg_cosine": 0.18
      },
      "code2NL_NL2code": {
        "total_comparisons": 2250,
        "line0_exact_matches": 0,
        "line0_exact_match_rate": 0.0,
        "proximity_matches": 795,
        "proximity_match_rate": 35.33,
        "avg_levenshtein": 47.65,
        "avg_edit_similarity": 0.13,
        "avg_first_line_edit_similarity": 0.13,
        "avg_cosine": 0.05
      },
      "code_purpose_understanding": {
        "total_comparisons": 2250,
        "line0_exact_matches": 120,
        "line0_exact_match_rate": 5.33,
        "proximity_matches": 1050,
        "proximity_match_rate": 46.67,
        "avg_levenshtein": 43.08,
        "avg_edit_similarity": 0.26,
        "avg_first_line_edit_similarity": 0.25,
        "avg_cosine": 0.13
      },
      "low_context": {
        "total_comparisons": 2202,
        "line0_exact_matches": 59,
        "line0_exact_match_rate": 2.68,
        "proximity_matches": 630,
        "proximity_match_rate": 28.61,
        "avg_levenshtein": 43.92,
        "avg_edit_similarity": 0.21,
        "avg_first_line_edit_similarity": 0.21,
        "avg_cosine": 0.12
      },
      "pattern_matching": {
        "total_comparisons": 2235,
        "line0_exact_matches": 30,
        "line0_exact_match_rate": 1.34,
        "proximity_matches": 975,
        "proximity_match_rate": 43.62,
        "avg_levenshtein": 41.51,
        "avg_edit_similarity": 0.23,
        "avg_first_line_edit_similarity": 0.23,
        "avg_cosine": 0.1
      },
      "syntax_completion": {
        "total_comparisons": 2220,
        "line0_exact_matches": 120,
        "line0_exact_match_rate": 5.41,
        "proximity_matches": 750,
        "proximity_match_rate": 33.78,
        "avg_levenshtein": 38.8,
        "avg_edit_similarity": 0.24,
        "avg_first_line_edit_similarity": 0.24,
        "avg_cosine": 0.13
      },
      "dogfood/idiomatic": {
        "total_comparisons": 45,
        "line0_exact_matches": 0,
        "line0_exact_match_rate": 0.0,
        "proximity_matches": 0,
        "proximity_match_rate": 0.0,
        "avg_levenshtein": 44.0,
        "avg_edit_similarity": 0.1,
        "avg_first_line_edit_similarity": 0.1,
        "avg_cosine": 0.0
      },
      "dogfood/nl2code": {
        "total_comparisons": 105,
        "line0_exact_matches": 0,
        "line0_exact_match_rate": 0.0,
        "proximity_matches": 15,
        "proximity_match_rate": 14.29,
        "avg_levenshtein": 46.86,
        "avg_edit_similarity": 0.17,
        "avg_first_line_edit_similarity": 0.17,
        "avg_cosine": 0.0
      },
      "dogfood/organization": {
        "total_comparisons": 120,
        "line0_exact_matches": 0,
        "line0_exact_match_rate": 0.0,
        "proximity_matches": 45,
        "proximity_match_rate": 37.5,
        "avg_levenshtein": 23.5,
        "avg_edit_similarity": 0.25,
        "avg_first_line_edit_similarity": 0.25,
        "avg_cosine": 0.19
      }
    },
    "languages": {
      "javascript": {
        "total_comparisons": 4500,
        "line0_exact_matches": 60,
        "line0_exact_match_rate": 1.33,
        "proximity_matches": 1770,
        "proximity_match_rate": 39.33,
        "avg_levenshtein": 41.56,
        "avg_edit_similarity": 0.21,
        "avg_first_line_edit_similarity": 0.2,
        "avg_cosine": 0.09
      },
      "python": {
        "total_comparisons": 4572,
        "line0_exact_matches": 74,
        "line0_exact_match_rate": 1.62,
        "proximity_matches": 1515,
        "proximity_match_rate": 33.14,
        "avg_levenshtein": 42.44,
        "avg_edit_similarity": 0.21,
        "avg_first_line_edit_similarity": 0.21,
        "avg_cosine": 0.11
      },
      "typescript": {
        "total_comparisons": 4500,
        "line0_exact_matches": 360,
        "line0_exact_match_rate": 8.0,
        "proximity_matches": 2055,
        "proximity_match_rate": 45.67,
        "avg_levenshtein": 45.39,
        "avg_edit_similarity": 0.25,
        "avg_first_line_edit_similarity": 0.25,
        "avg_cosine": 0.14
      }
    }
  }
}