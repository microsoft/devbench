{"id": "1", "testsource": "devbench-code-purpose-understanding", "language": "typescript", "prefix": "import * as assert from 'assert';\n\n// Define a type for a data entry\ninterface DataEntry {\n    timestamp: string;\n    value: number;\n}\n\n// Define a type for a dataset\ninterface Dataset {\n    entries: DataEntry[];\n}\n\n// Function to parse CSV data into a Dataset\nfunction parseCSV(data: string): Dataset {\n    const lines = data.split('\\n');\n    const entries: DataEntry[] = lines.slice(1).map(line => {\n        const [timestamp, value] = line.split(',');\n        return { timestamp, value: parseFloat(value) };\n    });\n    return { entries };\n}\n\n// Function to clean dataset by removing invalid entries\nfunction cleanDataset(dataset: Dataset): Dataset {\n    const cleanedEntries = dataset.entries.filter(entry => !isNaN(entry.value));\n    return { entries: cleanedEntries };\n}\n\n// Function to normalize dataset values to a range of 0 to 1\nfunction normalizeDataset(dataset: Dataset): Dataset {\n    const minValue = Math.min(...dataset.entries.map(entry => entry.value));\n    const maxValue = Math.max(...dataset.entries.map(entry => entry.value));\n    const normalizedEntries = dataset.entries.map(entry => ({\n        ...entry,\n        value: (entry.value - minValue) / (maxValue - minValue)\n    }));\n    return { entries: normalizedEntries };\n}\n\n// Example CSV data\nconst csvData = `timestamp,value\n2023-01-01T00:00:00Z,10\n2023-01-01T01:00:00Z,20\n2023-01-01T02:00:00Z,30\n2023-01-01T03:00:00Z,NaN\n2023-01-01T04:00:00Z,50`;\n\n// Parse the CSV data\nconst dataset = parseCSV(csvData);\n\n// Clean the dataset\nconst cleanedDataset = cleanDataset(dataset);\n\n// Expected cleaned dataset entries\nconst expectedCleanedEntries = [\n    { timestamp: '2023-01-01T00:00:00Z', value: 10 },\n    { timestamp: '2023-01-01T01:00:00Z', value: 20 },\n    { timestamp: '2023-01-01T02:00:00Z', value: 30 },\n    { timestamp: '2023-01-01T04:00:00Z', value: 50 }\n];\n\n// Assert that the cleaned dataset matches the expected cleaned entries\n", "suffix": "\n\n// Normalize the cleaned dataset\nconst normalizedDataset = normalizeDataset(cleanedDataset);\n\n// Example assertions (not actual expected values)\nconst expectedNormalizedEntries = [\n    { timestamp: '2023-01-01T00:00:00Z', value: 0 },\n    { timestamp: '2023-01-01T01:00:00Z', value: 0.25 },\n    { timestamp: '2023-01-01T02:00:00Z', value: 0.5 },\n    { timestamp: '2023-01-01T04:00:00Z', value: 1 }\n];\n\n// Assert that the normalized dataset matches the expected normalized entries\nassert.deepStrictEqual(normalizedDataset.entries, expectedNormalizedEntries);\n\n// Cleanup code (if any)\n", "golden_completion": "assert.deepStrictEqual(cleanedDataset.entries, expectedCleanedEntries);\n\n", "LLM_justification": "This test case demonstrates understanding of data validation (schema, cleaning, normalization) through functional programming patterns in TypeScript. The code parses a CSV string into a dataset, cleans it by removing invalid entries, and then normalizes the dataset values. The golden completion requires the LLM to correctly normalize the dataset and match expected values, demonstrating its ability to comprehend and apply data normalization logic. The assertions verify both functional and semantic correctness, ensuring the LLM understands the business purpose of data cleaning and normalization.", "assertions": "assert.deepStrictEqual(cleanedDataset.entries, expectedCleanedEntries);\nassert.deepStrictEqual(normalizedDataset.entries, expectedNormalizedEntries);", "o3-mini": "assert.deepStrictEqual(cleanedDataset.entries, expectedCleanedEntries);"}
{"id": "2", "testsource": "devbench-code-purpose-understanding", "language": "typescript", "prefix": "import * as fs from 'fs';\nimport * as path from 'path';\nimport { promisify } from 'util';\nconst readFileAsync = promisify(fs.readFile);\nconst writeFileAsync = promisify(fs.writeFile);\n\n// Define a structure to hold log data\ninterface LogData {\n  timestamp: string;\n  level: string;\n  message: string;\n}\n\n// Utility function to get current timestamp\nfunction getCurrentTimestamp(): string {\n  return new Date().toISOString();\n}\n\n// Function to log a message\nasync function logMessage(level: string, message: string, filePath: string): Promise<void> {\n  const logEntry: LogData = {\n    timestamp: getCurrentTimestamp(),\n    level,\n    message\n  };\n  const logString = JSON.stringify(logEntry) + '\\n';\n  await writeFileAsync(filePath, logString, { flag: 'a' });\n}\n\n// Function to read and parse log file\nasync function readLogFile(filePath: string): Promise<LogData[]> {\n  try {\n    const data = await readFileAsync(filePath, 'utf-8');\n    return data.split('\\n').filter(line => line.trim() !== '').map(line => JSON.parse(line));\n  } catch (err) {\n    console.error('Failed to read log file:', err);\n    return [];\n  }\n}\n\n// Sample usage of the logging functions\nconst logFilePath = path.join(__dirname, 'logs.txt');\n\n(async () => {\n  await logMessage('info', 'Server started', logFilePath);\n  await logMessage('error', 'Unhandled exception occurred', logFilePath);\n  const logs = await readLogFile(logFilePath);\n  console.log('Logs:', logs);\n})();\n\n// Function to filter logs by level\nasync function filterLogsByLevel(filePath: string, level: string): Promise<LogData[]> {\n  const logs = await readLogFile(filePath);\n  return logs.filter(log => log.level === level);\n}", "suffix": "async function clearLogFile(filePath: string): Promise<void> {\n  try {\n    await writeFileAsync(filePath, '');\n    console.log('Log file cleared');\n  } catch (err) {\n    console.error('Failed to clear log file:', err);\n  }\n}\n\n(async () => {\n  const errorLogs = await filterLogsByLevel(logFilePath, 'error');\n  console.log('Error Logs:', errorLogs);\n  await clearLogFile(logFilePath);\n})();", "golden_completion": "async function countLogEntries(filePath: string): Promise<number> {\n  const logs = await readLogFile(filePath);\n  return logs.length;\n}\n\n(async () => {\n  const logCount = await countLogEntries(logFilePath);\n  console.log('Total Log Entries:', logCount);\n})();", "LLM_justification": "This test case evaluates the LLM's ability to understand async file operations within the context of system operations, specifically logging and monitoring. It checks if the LLM can correctly implement a function to count log entries, which is a logical extension of reading and filtering logs, a common task in system operations. The assertions verify that the function returns the expected number of log entries, testing both functional and semantic correctness.", "assertions": "import * as assert from 'assert';\n(async () => {\n  await logMessage('info', 'Test log entry 1', logFilePath);\n  await logMessage('info', 'Test log entry 2', logFilePath);\n  const logCount = await countLogEntries(logFilePath);\n  assert.strictEqual(logCount, 2, 'Log count should be 2');\n  await clearLogFile(logFilePath);\n})();", "o3-mini": ""}
{"id": "3", "testsource": "devbench-code-purpose-understanding", "language": "typescript", "prefix": "import * as fs from 'fs';\nimport * as path from 'path';\n\n// Utility function to read a JSON file and parse its content\nfunction readJSONFile(filePath: string): any {\n    const rawData = fs.readFileSync(filePath, 'utf-8');\n    return JSON.parse(rawData);\n}\n\n// Utility function to write data to a JSON file\nfunction writeJSONFile(filePath: string, data: any): void {\n    fs.writeFileSync(filePath, JSON.stringify(data, null, 2), 'utf-8');\n}\n\n// Function to validate email format\nfunction isValidEmail(email: string): boolean {\n    const emailRegex = /^[\\w-\\.]+@([\\w-]+\\.)+[\\w-]{2,4}$/;\n    return emailRegex.test(email);\n}\n\n// Function to clean and normalize user data\nfunction cleanAndNormalizeData(data: any): any {\n    if (data.email && isValidEmail(data.email)) {\n        data.email = data.email.toLowerCase();\n    } else {\n        throw new Error('Invalid email format');\n    }\n    return data;\n}\n\n// Main function to process user data file\nfunction processUserDataFile(filePath: string): void {\n    try {\n        let userData = readJSONFile(filePath);\n        userData = cleanAndNormalizeData(userData);\n        writeJSONFile(filePath, userData);\n    } catch (error) {\n        console.error('Error processing user data file:', error);\n    }\n}\n\n// Test setup\nconst testFilePath = path.join(__dirname, 'testUserData.json');\nconst validTestData = { name: 'John Doe', email: 'John.Doe@Example.com' };\nconst invalidTestData = { name: 'Jane Doe', email: 'Jane.Doe@Example' };\n\n// Write test data to file for validation\nwriteJSONFile(testFilePath, validTestData);", "suffix": "\n\n// Clean up test file\nfs.unlinkSync(testFilePath);\n", "golden_completion": "\n// Process user data file with valid email\nprocessUserDataFile(testFilePath);\n\n// Read and validate the processed data\nconst processedData = readJSONFile(testFilePath);\nconsole.assert(processedData.email === 'john.doe@example.com', 'Email normalization failed');", "LLM_justification": "This test case is designed to evaluate the LLM's understanding of data validation and normalization within the context of processing user data files. It checks the ability to follow the business logic of cleaning and normalizing user email addresses, ensuring valid email formats, and handling errors appropriately. The scenario involves reading from and writing to JSON files, validating email formats, and includes proper error handling. The assertions verify that the email normalization process is correctly implemented, making it a robust test for code purpose understanding.", "assertions": "console.assert(processedData.email === 'john.doe@example.com', 'Email normalization failed');", "o3-mini": "processUserDataFile(testFilePath);\nconsole.log(readJSONFile(testFilePath));"}
{"id": "4", "testsource": "devbench-code-purpose-understanding", "language": "typescript", "prefix": "import * as crypto from 'crypto';\n\n// Define a User class with sensitive information\nclass User {\n\tconstructor(public id: number, public name: string, public email: string) {}\n}\n\n// Define a LogEntry class for storing logs\nclass LogEntry {\n\tconstructor(public timestamp: Date, public message: string) {}\n}\n\n// Define a Logger class to handle logging\nclass Logger {\n\tprivate logs: LogEntry[] = [];\n\n\tlog(message: string) {\n\t\tthis.logs.push(new LogEntry(new Date(), message));\n\t}\n\n\tgetLogs(): LogEntry[] {\n\t\treturn this.logs;\n\t}\n}\n\n// Define an AuthService class to handle user authentication\nclass AuthService {\n\tprivate users: User[] = [];\n\tprivate logger: Logger;\n\n\tconstructor(logger: Logger) {\n\t\tthis.logger = logger;\n\t}\n\n\tregisterUser(id: number, name: string, email: string) {\n\t\tconst newUser = new User(id, name, email);\n\t\tthis.users.push(newUser);\n\t\tthis.logger.log(`User registered: ${name}`);\n\t}\n\n\tprivate hashPassword(password: string): string {\n\t\treturn crypto.createHash('sha256').update(password).digest('hex');\n\t}\n\n\t// Method to authenticate a user\n\tauthenticateUser(id: number, password: string): boolean {\n\t\tconst user = this.users.find(user => user.id === id);\n\t\tif (!user) {\n\t\t\tthis.logger.log('Authentication failed: User not found');\n\t\t\treturn false;\n\t\t}\n\t\t// Placeholder for actual password check\n\t\tconst hashedPassword = this.hashPassword(password);\n\t\tif (hashedPassword === 'correctHashedPassword') {\n\t\t\tthis.logger.log(`User authenticated: ${user.name}`);\n\t\t\treturn true;\n\t\t} else {\n\t\t\tthis.logger.log('Authentication failed: Incorrect password');\n\t\t\treturn false;\n\t\t}\n\t}\n}\n\n// Setup the logger and auth service\nconst logger = new Logger();\nconst authService = new AuthService(logger);\n\n// Register a new user\nauthService.registerUser(1, 'John Doe', 'john.doe@example.com');\n", "suffix": "\n// Attempt to authenticate the user with an incorrect password\nconst isAuthenticatedIncorrect = authService.authenticateUser(1, 'wrongPassword');\nconsole.log(`Authentication with incorrect password: ${isAuthenticatedIncorrect}`);\n\n// Assertions\nimport * as assert from 'assert';\nconst logs = logger.getLogs();\nassert.strictEqual(logs.length, 3);\nassert.strictEqual(logs[0].message, 'User registered: John Doe');\nassert.strictEqual(logs[1].message, 'Authentication failed: Incorrect password');\n\n// Cleanup\nconsole.log('Logs:', logs);\n", "golden_completion": "\n// Attempt to authenticate the user with the correct password\nconst isAuthenticatedCorrect = authService.authenticateUser(1, 'correctPassword');\nconsole.log(`Authentication with correct password: ${isAuthenticatedCorrect}`);\n\n", "LLM_justification": "This test case assesses the LLM's ability to understand the business logic of user authentication within a security context. The AuthService class handles user registration and authentication, logging each step. The golden completion correctly demonstrates the authentication process with the right password, ensuring the logs reflect successful authentication. The suffix tests an incorrect password scenario, while assertions verify the integrity and sequence of log entries, confirming both successful and failed authentication attempts.", "assertions": "\nimport * as assert from 'assert';\nconst logs = logger.getLogs();\nassert.strictEqual(logs.length, 3);\nassert.strictEqual(logs[0].message, 'User registered: John Doe');\nassert.strictEqual(logs[1].message, 'Authentication failed: Incorrect password');\nassert.strictEqual(isAuthenticatedCorrect, true);\nassert.strictEqual(logs[2].message, 'User authenticated: John Doe');\n", "o3-mini": "authService.authenticateUser(1, 'wrongPassword');"}
{"id": "5", "testsource": "devbench-code-purpose-understanding", "language": "typescript", "prefix": "import * as fs from 'fs';\nimport * as path from 'path';\n\n// Define types for log entries and system metrics\ninterface LogEntry {\n    timestamp: Date;\n    level: 'INFO' | 'ERROR' | 'DEBUG';\n    message: string;\n}\n\ninterface SystemMetrics {\n    cpuUsage: number;\n    memoryUsage: number;\n    diskSpace: number;\n}\n\n// Utility function to format log entries\nfunction formatLogEntry(entry: LogEntry): string {\n    return `[${entry.timestamp.toISOString()}] [${entry.level}] ${entry.message}`;\n}\n\n// Function to read and parse system metrics from a JSON file\nfunction readSystemMetrics(filePath: string): SystemMetrics {\n    const data = fs.readFileSync(filePath, 'utf-8');\n    return JSON.parse(data) as SystemMetrics;\n}\n\n// Function to log system metrics\nfunction logSystemMetrics(metrics: SystemMetrics): void {\n    const logEntries: LogEntry[] = [];\n    logEntries.push({\n        timestamp: new Date(),\n        level: 'INFO',\n        message: `CPU Usage: ${metrics.cpuUsage}%`\n    });\n    logEntries.push({\n        timestamp: new Date(),\n        level: 'INFO',\n        message: `Memory Usage: ${metrics.memoryUsage}MB`\n    });\n    logEntries.push({\n        timestamp: new Date(),\n        level: 'INFO',\n        message: `Disk Space: ${metrics.diskSpace}GB`\n    });\n\n    for (const entry of logEntries) {\n        console.log(formatLogEntry(entry));\n    }\n}\n\n// Main function to monitor and log system metrics\nfunction monitorSystemMetrics(metricFilePath: string): void {\n    try {\n        const metrics = readSystemMetrics(metricFilePath);\n        logSystemMetrics(metrics);\n    } catch (error) {\n        const errorLog: LogEntry = {\n            timestamp: new Date(),\n            level: 'ERROR',\n            message: `Failed to monitor system metrics: ${error.message}`\n        };\n        console.error(formatLogEntry(errorLog));\n    }\n}\n\n// Mock data for testing\nconst mockMetrics: SystemMetrics = {\n    cpuUsage: 45,\n    memoryUsage: 1024,\n    diskSpace: 250\n};\n\nconst mockFilePath = path.join(__dirname, 'mockMetrics.json');\nfs.writeFileSync(mockFilePath, JSON.stringify(mockMetrics));\n", "suffix": "monitorSystemMetrics(mockFilePath);\nfs.unlinkSync(mockFilePath);\n", "golden_completion": "monitorSystemMetrics(mockFilePath);\nfs.unlinkSync(mockFilePath);\n", "LLM_justification": "This scenario tests the LLM's ability to understand and continue code related to system operations, specifically logging and monitoring system metrics. The completion requires the LLM to correctly call the main function to monitor and log metrics, and then clean up the resources by deleting the mock file. The context involves handling file operations, logging, and error handling, which are common in system operations. Assertions ensure that metrics are logged correctly and resources are cleaned up properly.", "assertions": "import * as assert from 'assert';\nimport * as sinon from 'sinon';\n\nconst consoleLogSpy = sinon.spy(console, 'log');\nconst consoleErrorSpy = sinon.spy(console, 'error');\n\nmonitorSystemMetrics(mockFilePath);\n\nassert.strictEqual(consoleLogSpy.callCount, 3, 'Expected 3 log entries for CPU, memory, and disk usage');\nassert(consoleLogSpy.calledWithMatch(/CPU Usage: 45%/), 'Expected log entry for CPU usage');\nassert(consoleLogSpy.calledWithMatch(/Memory Usage: 1024MB/), 'Expected log entry for memory usage');\nassert(consoleLogSpy.calledWithMatch(/Disk Space: 250GB/), 'Expected log entry for disk space');\nassert.strictEqual(consoleErrorSpy.callCount, 0, 'Expected no error log entries');\n\nconsoleLogSpy.restore();\nconsoleErrorSpy.restore();\nfs.unlinkSync(mockFilePath);\n", "o3-mini": "monitorSystemMetrics(mockFilePath);"}
{"id": "6", "testsource": "devbench-code-purpose-understanding", "language": "typescript", "prefix": "import * as fs from 'fs';\nimport * as path from 'path';\n\ninterface LogEntry {\n    timestamp: Date;\n    level: 'info' | 'warn' | 'error';\n    message: string;\n}\n\nclass Logger {\n    private logFilePath: string;\n    private logEntries: LogEntry[] = [];\n\n    constructor(logFilePath: string) {\n        this.logFilePath = logFilePath;\n    }\n\n    public log(level: 'info' | 'warn' | 'error', message: string) {\n        const entry: LogEntry = {\n            timestamp: new Date(),\n            level,\n            message\n        };\n        this.logEntries.push(entry);\n    }\n\n    public async saveLog() {\n        const logData = this.logEntries.map(entry => `${entry.timestamp.toISOString()} [${entry.level}] ${entry.message}`).join('\\n');\n        await fs.promises.writeFile(this.logFilePath, logData);\n    }\n}\n\n// Helper function to simulate a long-running task\nfunction simulateTask(duration: number): Promise<void> {\n    return new Promise((resolve) => setTimeout(resolve, duration));\n}\n\nasync function runTaskWithLogging(logger: Logger) {\n    try {\n        logger.log('info', 'Task started');\n        await simulateTask(1000);\n        logger.log('info', 'Task completed successfully');\n    } catch (error) {\n        logger.log('error', 'Task failed');\n    }\n}\n\n// Main execution function\nasync function main() {\n    const logFilePath = path.resolve(__dirname, 'app.log');\n    const logger = new Logger(logFilePath);\n\n    await runTaskWithLogging(logger);\n", "suffix": "    console.log('Log entries saved successfully');\n}\n\nmain().catch(error => console.error('Main execution failed:', error));", "golden_completion": "    await logger.saveLog();\n", "LLM_justification": "This test case is ideal as it evaluates the LLM's ability to understand the context of logging system operations. The Logger class is designed to handle log entries, and the main function is expected to log tasks and save these logs to a file. The golden completion involves saving the log entries, which is a critical part of the logging mechanism, ensuring that the logs are persisted appropriately. This showcases the LLM's capability to follow through with the business logic of logging and file operations.", "assertions": "import * as fs from 'fs';\nimport * as path from 'path';\nimport { strict as assert } from 'assert';\n\nasync function test() {\n    const logFilePath = path.resolve(__dirname, 'app.log');\n    const logger = new Logger(logFilePath);\n    await runTaskWithLogging(logger);\n    await logger.saveLog();\n\n    const logData = await fs.promises.readFile(logFilePath, 'utf-8');\n    assert(logData.includes('Task started'), 'Log should contain task start message');\n    assert(logData.includes('Task completed successfully'), 'Log should contain task completion message');\n\n    // Cleanup\n    await fs.promises.unlink(logFilePath);\n}\n\ntest().then(() => console.log('All assertions passed')).catch(error => console.error('Test failed:', error));", "o3-mini": "    await logger.saveLog();"}
{"id": "7", "testsource": "devbench-code-purpose-understanding", "language": "typescript", "prefix": "import * as fs from 'fs';\nimport * as path from 'path';\n\n// This module handles media file processing, specifically for image files.\n// It includes functionality to read an image file, process it (e.g., resize), and save the output.\n\ninterface Image {\n    width: number;\n    height: number;\n    data: Buffer;\n}\n\ninterface ProcessedImage {\n    width: number;\n    height: number;\n    data: Buffer;\n    format: string;\n}\n\nclass ImageProcessor {\n    constructor(private inputDir: string, private outputDir: string) {}\n\n    // Reads an image file from the input directory\n    private readImage(filename: string): Promise<Image> {\n        return new Promise((resolve, reject) => {\n            const filePath = path.join(this.inputDir, filename);\n            fs.readFile(filePath, (err, data) => {\n                if (err) {\n                    reject(`Failed to read image file: ${err.message}`);\n                } else {\n                    // Assume the image is in raw format for simplicity\n                    resolve({ width: 800, height: 600, data });\n                }\n            });\n        });\n    }\n\n    // Processes the image (e.g., resizing)\n    private processImage(image: Image): ProcessedImage {\n        const processedData = image.data; // Placeholder for actual processing logic\n        const format = 'jpeg'; // Assume JPEG format for output\n        return { ...image, data: processedData, format };\n    }\n\n    // Writes the processed image to the output directory\n    private writeImage(filename: string, image: ProcessedImage): Promise<void> {\n        return new Promise((resolve, reject) => {\n            const filePath = path.join(this.outputDir, `${path.basename(filename, path.extname(filename))}.${image.format}`);\n            fs.writeFile(filePath, image.data, (err) => {\n                if (err) {\n                    reject(`Failed to write image file: ${err.message}`);\n                } else {\n                    resolve();\n                }\n            });\n        });\n    }\n\n    // Public method to process an image file\n    public async processFile(filename: string): Promise<void> {\n        try {\n            const image = await this.readImage(filename);\n            const processedImage = this.processImage(image);\n            await this.writeImage(filename, processedImage);\n        } catch (error) {\n            console.error(`Error processing file ${filename}: ${error}`);\n        }\n    }\n}\n\n// Example usage\nconst processor = new ImageProcessor('./input', './output');\n", "suffix": "processor.processFile('example.png').then(() => {\n    console.log('Image processing completed successfully.');\n}).catch((error) => {\n    console.error('Image processing failed:', error);\n});", "golden_completion": "async function batchProcessFiles(filenames: string[]): Promise<void> {\n    for (const filename of filenames) {\n        await processor.processFile(filename);\n    }\n}\n\nbatchProcessFiles(['example1.png', 'example2.png', 'example3.png']).then(() => {\n    console.log('Batch image processing completed successfully.');\n}).catch((error) => {\n    console.error('Batch image processing failed:', error);\n});", "LLM_justification": "This test case evaluates the LLM's ability to comprehend and extend a media processing system, specifically focusing on image processing. The scenario involves reading, processing, and saving image files using Promises and async/await patterns. The LLM must understand the business context of batch processing multiple image files, demonstrating knowledge of asynchronous operations and error handling in TypeScript. The golden completion introduces a higher-level function for batch processing, which is semantically consistent with the existing code.", "assertions": "import * as assert from 'assert';\n(async () => {\n    // Mocking the file system interactions\n    const mockReadFile = jest.spyOn(fs, 'readFile').mockImplementation((filePath, callback) => {\n        callback(null, Buffer.from('mock image data'));\n    });\n    const mockWriteFile = jest.spyOn(fs, 'writeFile').mockImplementation((filePath, data, callback) => {\n        callback(null);\n    });\n\n    // Test the batch processing function\n    await batchProcessFiles(['test1.png', 'test2.png']);\n    assert.strictEqual(mockReadFile.mock.calls.length, 2, 'readFile should be called twice');\n    assert.strictEqual(mockWriteFile.mock.calls.length, 2, 'writeFile should be called twice');\n\n    // Restore the original implementations\n    mockReadFile.mockRestore();\n    mockWriteFile.mockRestore();\n})();", "o3-mini": ""}
{"id": "8", "testsource": "devbench-code-purpose-understanding", "language": "typescript", "prefix": "import fs from 'fs';\nimport path from 'path';\n\n// Event handling in a media processing context\n// This function watches a directory for new image files and processes them\nclass ImageProcessor {\n    private watchDir: string;\n    private processedDir: string;\n\n    constructor(watchDir: string, processedDir: string) {\n        this.watchDir = watchDir;\n        this.processedDir = processedDir;\n    }\n\n    // Initialize the directory watcher\n    public startWatching() {\n        fs.watch(this.watchDir, (eventType, filename) => {\n            if (eventType === 'rename' && filename.endsWith('.jpg')) {\n                this.processImage(path.join(this.watchDir, filename));\n            }\n        });\n    }\n\n    // Process the image file\n    private processImage(filePath: string) {\n        // Simulate image processing\n        setTimeout(() => {\n            console.log(`Processing image: ${filePath}`);\n            const processedFilePath = path.join(this.processedDir, path.basename(filePath));\n            fs.rename(filePath, processedFilePath, (err) => {\n                if (err) {\n                    console.error(`Error moving file: ${err.message}`);\n                } else {\n                    console.log(`File moved to: ${processedFilePath}`);\n                }\n            });\n        }, 1000);\n    }\n}\n\n// Setup directories for watching and processed images\nconst watchDir = './watch';\nconst processedDir = './processed';\nfs.mkdirSync(watchDir, { recursive: true });\nfs.mkdirSync(processedDir, { recursive: true });\n\n// Create an instance of the ImageProcessor and start watching the directory\nconst imageProcessor = new ImageProcessor(watchDir, processedDir);\nimageProcessor.startWatching();\n\n// Function to simulate adding a new image file to the watch directory\nfunction addNewImage(filename: string) {\n    const filePath = path.join(watchDir, filename);\n    fs.writeFileSync(filePath, ''); // Create an empty file\n    console.log(`Added new image: ${filePath}`);\n}\n\n// Simulate adding a new image file\naddNewImage('test.jpg');\n\n// Process images", "suffix": "", "golden_completion": "setTimeout(() => {\n    try {\n        // Check if the file has been moved to the processed directory\n        const processedFilePath = path.join(processedDir, 'test.jpg');\n        if (fs.existsSync(processedFilePath)) {\n            console.log('Test passed: Image processed and moved successfully.');\n        } else {\n            console.error('Test failed: Image was not moved to the processed directory.');\n        }\n    } catch (error) {\n        console.error(`Test failed with error: ${error.message}`);\n    }\n}, 2000);", "LLM_justification": "This example tests the LLM's understanding of event handling within a media processing context. The prefix sets up a directory watcher that processes new image files by moving them to a processed directory. The golden completion involves checking that the image file has been correctly processed and moved, which verifies the proper functioning of the event handler. This scenario is realistic and tests the LLM's ability to comprehend and continue code based on its business logic and context.", "assertions": "setTimeout(() => {\n    const processedFilePath = path.join(processedDir, 'test.jpg');\n    if (!fs.existsSync(processedFilePath)) {\n        throw new Error('Assertion failed: Image was not moved to the processed directory.');\n    }\n    console.log('All assertions passed.');\n}, 2000);", "o3-mini": "const files = fs.readdirSync(watchDir);\nfiles.filter(file => file.endsWith('.jpg')).forEach(file => {\n    imageProcessor[\"processImage\"](path.join(watchDir, file));\n});"}
{"id": "9", "testsource": "devbench-code-purpose-understanding", "language": "typescript", "prefix": "import * as fs from 'fs';\nimport * as path from 'path';\n\ninterface LogEntry {\n  timestamp: string;\n  level: 'INFO' | 'WARN' | 'ERROR';\n  message: string;\n}\n\nclass Logger {\n  private logFilePath: string;\n\n  constructor(logFileName: string) {\n    this.logFilePath = path.join(__dirname, logFileName);\n  }\n\n  private async writeLogEntry(entry: LogEntry): Promise<void> {\n    const logLine = `${entry.timestamp} [${entry.level}] ${entry.message}\\n`;\n    return new Promise((resolve, reject) => {\n      fs.appendFile(this.logFilePath, logLine, (err) => {\n        if (err) reject(err);\n        else resolve();\n      });\n    });\n  }\n\n  public async info(message: string): Promise<void> {\n    const entry: LogEntry = { timestamp: new Date().toISOString(), level: 'INFO', message };\n    await this.writeLogEntry(entry);\n  }\n\n  public async warn(message: string): Promise<void> {\n    const entry: LogEntry = { timestamp: new Date().toISOString(), level: 'WARN', message };\n    await this.writeLogEntry(entry);\n  }\n\n  public async error(message: string): Promise<void> {\n    const entry: LogEntry = { timestamp: new Date().toISOString(), level: 'ERROR', message };\n    await this.writeLogEntry(entry);\n  }\n}\n\nconst logger = new Logger('app.log');\n\nasync function simulateLogging(): Promise<void> {\n  await logger.info('Application started');\n  await logger.warn('Low disk space');\n  await logger.error('Unhandled exception');\n}\n\nsimulateLogging().catch((err) => console.error('Logging failed:', err));\n\n// Next, we want to read the log file and check if the entries were properly logged.\nasync function readLogFile(logFilePath: string): Promise<string[]> {\n  return new Promise((resolve, reject) => {\n    fs.readFile(logFilePath, 'utf8', (err, data) => {\n      if (err) reject(err);\n      else resolve(data.split('\\n').filter(line => line.length > 0));\n    });\n  });\n}\n\n// We will now test if the log entries were correctly written.\n", "suffix": "readLogFile(logger.logFilePath).then((logEntries) => {\n  console.log('Log Entries:', logEntries);\n}).catch((err) => console.error('Error reading log file:', err));\n\n// Clean up the log file after testing\nfs.unlink(logger.logFilePath, (err) => {\n  if (err) console.error('Failed to delete log file:', err);\n  else console.log('Log file deleted successfully');\n});\n", "golden_completion": "const logEntries = await readLogFile(logger.logFilePath);\nconsole.assert(logEntries.length === 3, 'Expected 3 log entries');\nconsole.assert(logEntries[0].includes('INFO') && logEntries[0].includes('Application started'), 'First log entry should be INFO: Application started');\nconsole.assert(logEntries[1].includes('WARN') && logEntries[1].includes('Low disk space'), 'Second log entry should be WARN: Low disk space');\nconsole.assert(logEntries[2].includes('ERROR') && logEntries[2].includes('Unhandled exception'), 'Third log entry should be ERROR: Unhandled exception');\n", "LLM_justification": "This test case examines the LLM's understanding of asynchronous file operations and logging in a system operations context. The Logger class demonstrates proper use of Promises for async file writes, and the readLogFile function reads and parses the log file asynchronously. The golden completion involves verifying that the log entries were correctly written, which tests the LLM's ability to follow and comprehend the business logic of logging in a system operations domain. The assertions ensure that the log entries match the expected values, maintaining semantic consistency with the logging operations performed in the prefix.", "assertions": "const logEntries = await readLogFile(logger.logFilePath);\nconsole.assert(logEntries.length === 3, 'Expected 3 log entries');\nconsole.assert(logEntries[0].includes('INFO') && logEntries[0].includes('Application started'), 'First log entry should be INFO: Application started');\nconsole.assert(logEntries[1].includes('WARN') && logEntries[1].includes('Low disk space'), 'Second log entry should be WARN: Low disk space');\nconsole.assert(logEntries[2].includes('ERROR') && logEntries[2].includes('Unhandled exception'), 'Third log entry should be ERROR: Unhandled exception');\n", "o3-mini": "readLogFile(logger.logFilePath).then((logEntries) => {\n  console.log('Log Entries:', logEntries);\n}).catch((err) => console.error('Error reading log file:', err));"}
{"id": "10", "testsource": "devbench-code-purpose-understanding", "language": "typescript", "prefix": "import fs from 'fs';\n\ninterface LogEntry {\n    timestamp: string;\n    level: string;\n    message: string;\n}\n\nclass Logger {\n    private logFilePath: string;\n\n    constructor(logFilePath: string) {\n        this.logFilePath = logFilePath;\n    }\n\n    private formatLogEntry(level: string, message: string): LogEntry {\n        return {\n            timestamp: new Date().toISOString(),\n            level,\n            message\n        };\n    }\n\n    public async log(level: string, message: string): Promise<void> {\n        const entry = this.formatLogEntry(level, message);\n        const logLine = `${entry.timestamp} [${entry.level}] ${entry.message}\\n`;\n        try {\n            await fs.promises.appendFile(this.logFilePath, logLine);\n        } catch (error) {\n            console.error('Failed to write log:', error);\n        }\n    }\n\n    public async info(message: string): Promise<void> {\n        await this.log('INFO', message);\n    }\n\n    public async warn(message: string): Promise<void> {\n        await this.log('WARN', message);\n    }\n\n    public async error(message: string): Promise<void> {\n        await this.log('ERROR', message);\n    }\n}\n\n// Usage example\nasync function main() {\n    const logger = new Logger('app.log');\n    await logger.info('Application started');\n", "suffix": "    await logger.warn('Low disk space');\n    await logger.error('Unhandled exception occurred');\n}\n\nmain().catch(console.error);\n", "golden_completion": "    await logger.info('Logger initialized successfully');\n", "LLM_justification": "This is a good test case because it involves asynchronous logging operations in a system operations context. The Logger class is designed to handle different log levels and append log entries to a file. The golden completion demonstrates the initialization of the logger and logging an informational message, which is consistent with the business logic of system operations logging. The assertions ensure that log entries are correctly appended to the file and follow the specified format.", "assertions": "import { strict as assert } from 'assert';\nimport { readFileSync } from 'fs';\n\nasync function testLogger() {\n    const logger = new Logger('test.log');\n    await logger.info('Logger initialized successfully');\n    await logger.warn('Low disk space');\n    await logger.error('Unhandled exception occurred');\n\n    const logContent = readFileSync('test.log', 'utf-8');\n    assert(logContent.includes('Logger initialized successfully'), 'Log does not contain the initialization message');\n    assert(logContent.includes('Low disk space'), 'Log does not contain the warning message');\n    assert(logContent.includes('Unhandled exception occurred'), 'Log does not contain the error message');\n}\n\ntestLogger().then(() => console.log('All assertions passed')).catch(console.error);\n", "o3-mini": "    await logger.warn('Low disk space');"}
{"id": "11", "testsource": "devbench-code-purpose-understanding", "language": "typescript", "prefix": "import { readFileSync } from 'fs';\n\n// A class representing a simple data analysis tool for processing CSV files\nclass CsvDataAnalyzer {\n    private data: string[][] = [];\n\n    constructor(private filePath: string) {}\n\n    // Method to load and parse CSV data from the file\n    loadData(): void {\n        const fileContent = readFileSync(this.filePath, 'utf-8');\n        const lines = fileContent.split('\\n');\n        this.data = lines.map(line => line.split(','));\n    }\n\n    // Method to calculate the average of a specific column\n    calculateAverage(columnIndex: number): number {\n        if (this.data.length === 0) {\n            throw new Error('Data not loaded');\n        }\n\n        let sum = 0;\n        let count = 0;\n        for (const row of this.data) {\n            const value = parseFloat(row[columnIndex]);\n            if (!isNaN(value)) {\n                sum += value;\n                count++;\n            }\n        }\n\n        if (count === 0) {\n            throw new Error('No valid data in the specified column');\n        }\n\n        return sum / count;\n    }\n\n    // Method to find the maximum value in a specific column\n    findMax(columnIndex: number): number {\n        if (this.data.length === 0) {\n            throw new Error('Data not loaded');\n        }\n\n        let max = -Infinity;\n        for (const row of this.data) {\n            const value = parseFloat(row[columnIndex]);\n            if (!isNaN(value) && value > max) {\n                max = value;\n            }\n        }\n\n        if (max === -Infinity) {\n            throw new Error('No valid data in the specified column');\n        }\n\n        return max;\n    }\n}\n\n// Helper function to simulate a CSV file read\nfunction simulateCsvFileRead(filePath: string, content: string): void {\n    const fs = require('fs');\n    fs.writeFileSync(filePath, content);\n}\n\n// Simulate CSV file content\nconst filePath = 'test.csv';\nsimulateCsvFileRead(filePath, 'name,age,salary\\nAlice,30,1000\\nBob,25,1500\\nCharlie,35,2000\\n');\n\n// Instantiate CsvDataAnalyzer and load data\nconst analyzer = new CsvDataAnalyzer(filePath);\nanalyzer.loadData();\n\n// Calculate average salary\nconst averageSalary = analyzer.calculateAverage(2);\nconsole.log(`Average Salary: ${averageSalary}`);", "suffix": "\n// Find the maximum age\nconst maxAge = analyzer.findMax(1);\nconsole.log(`Max Age: ${maxAge}`);\n\n// Cleanup simulated file\nconst fs = require('fs');\nfs.unlinkSync(filePath);", "golden_completion": "\n// Calculate average age\nconst averageAge = analyzer.calculateAverage(1);\nconsole.log(`Average Age: ${averageAge}`);", "LLM_justification": "This test case evaluates the LLM's understanding of OOP patterns and data analysis in the context of processing CSV files. The CsvDataAnalyzer class provides methods to load data, calculate averages, and find maximum values in specific columns. The golden completion requires the LLM to correctly use the calculateAverage method to find the average age in the dataset, which demonstrates comprehension of both the class methods and the business logic of data analysis.", "assertions": "import { strict as assert } from 'assert';\n\n// Ensure the average salary is calculated correctly\nassert.equal(averageSalary, 1500, 'The average salary should be 1500');\n\n// Ensure the average age is calculated correctly\nconst averageAge = analyzer.calculateAverage(1);\nassert.equal(averageAge, 30, 'The average age should be 30');\n\n// Ensure the maximum age is calculated correctly\nconst maxAge = analyzer.findMax(1);\nassert.equal(maxAge, 35, 'The maximum age should be 35');", "o3-mini": "const averageAge = analyzer.calculateAverage(1);\nconsole.log(`Average Age: ${averageAge}`);"}
{"id": "12", "testsource": "devbench-code-purpose-understanding", "language": "typescript", "prefix": "import * as fs from 'fs';\nimport * as path from 'path';\n\n// Represents a log entry with a message and timestamp\nclass LogEntry {\n  constructor(public message: string, public timestamp: Date) {}\n}\n\n// A class that handles logging and monitoring system operations\nclass Logger {\n  private logEntries: LogEntry[] = [];\n  private logFilePath: string;\n\n  constructor(logFilePath: string) {\n    this.logFilePath = logFilePath;\n  }\n\n  // Adds a new log entry\n  addLog(message: string): void {\n    const logEntry = new LogEntry(message, new Date());\n    this.logEntries.push(logEntry);\n  }\n\n  // Saves log entries to a file\n  saveToFile(): Promise<void> {\n    return new Promise((resolve, reject) => {\n      const logData = this.logEntries.map(entry => `${entry.timestamp.toISOString()} - ${entry.message}`).join('\\n');\n      fs.writeFile(this.logFilePath, logData, 'utf8', (err) => {\n        if (err) {\n          reject(err);\n        } else {\n          resolve();\n        }\n      });\n    });\n  }\n\n  // Loads log entries from a file\n  loadFromFile(): Promise<void> {\n    return new Promise((resolve, reject) => {\n      fs.readFile(this.logFilePath, 'utf8', (err, data) => {\n        if (err) {\n          reject(err);\n        } else {\n          const logEntries = data.split('\\n').map(line => {\n            const [timestamp, ...messageParts] = line.split(' - ');\n            return new LogEntry(messageParts.join(' - '), new Date(timestamp));\n          });\n          this.logEntries = logEntries;\n          resolve();\n        }\n      });\n    });\n  }\n}\n\n// Helper function to create a logger and add initial log entries\nfunction initializeLogger(logFilePath: string): Logger {\n  const logger = new Logger(logFilePath);\n  logger.addLog('System initialized');\n  logger.addLog('Configuration loaded');\n  return logger;\n}\n\n// Test the logging system\nconst logFilePath = path.join(__dirname, 'system.log');\nconst logger = initializeLogger(logFilePath);\nlogger.addLog('User login detected');\n", "suffix": "logger.loadFromFile().then(() => {\n  console.log('Logs loaded successfully');\n  console.log(logger);\n}).catch((err) => {\n  console.error('Error loading logs:', err);\n});\n", "golden_completion": "logger.saveToFile().then(() => {\n  console.log('Logs saved successfully');\n}).catch((err) => {\n  console.error('Error saving logs:', err);\n});\n", "LLM_justification": "This test case evaluates the LLM's ability to understand the purpose of a logging and monitoring system using promises and async-await patterns. The completion requires the LLM to correctly continue the sequence of saving log entries to a file, which is a critical operation in system operations for logging and monitoring. The distinction between golden_completion and suffix ensures that the LLM understands the asynchronous flow and correct usage of promises in the context of logging.", "assertions": "import * as assert from 'assert';\n\nconst testLogFilePath = path.join(__dirname, 'test_system.log');\nconst testLogger = initializeLogger(testLogFilePath);\ntestLogger.addLog('Test entry');\ntestLogger.saveToFile().then(() => {\n  console.log('Logs saved successfully');\n  assert.ok(fs.existsSync(testLogFilePath), 'Log file should exist');\n  const logContent = fs.readFileSync(testLogFilePath, 'utf8');\n  assert.ok(logContent.includes('Test entry'), 'Log file should contain the test entry');\n  testLogger.loadFromFile().then(() => {\n    assert.strictEqual(testLogger['logEntries'].length, 3, 'Logger should have 3 entries after loading from file');\n    assert.strictEqual(testLogger['logEntries'][2].message, 'Test entry', 'Last log entry should be the test entry');\n  }).catch((err) => {\n    assert.fail('Loading logs should not fail');\n  });\n}).catch((err) => {\n  assert.fail('Saving logs should not fail');\n});\n", "o3-mini": "logger.loadFromFile()"}
{"id": "13", "testsource": "devbench-code-purpose-understanding", "language": "typescript", "prefix": "import { readFileSync } from 'fs';\nimport * as assert from 'assert';\n\n// This utility function reads a JSON file and parses it into an object\nfunction readJSONFile(filePath: string): any {\n    const data = readFileSync(filePath, 'utf-8');\n    return JSON.parse(data);\n}\n\n// This function validates a given user's data against a predefined schema\nfunction validateUserData(userData: any, schema: any): boolean {\n    for (const key in schema) {\n        if (schema.hasOwnProperty(key)) {\n            if (typeof userData[key] !== schema[key]) {\n                return false;\n            }\n        }\n    }\n    return true;\n}\n\n// Schema definition for user data\nconst userSchema = {\n    id: 'number',\n    name: 'string',\n    email: 'string',\n    age: 'number'\n};\n\n// Example user data\nconst exampleUserData = {\n    id: 1,\n    name: 'John Doe',\n    email: 'john.doe@example.com',\n    age: 30\n};\n\n// Validate the example user data against the schema\nconst isValid = validateUserData(exampleUserData, userSchema);\nassert.strictEqual(isValid, true, 'Example user data should be valid');\n\n// Function to filter valid user data from a list\nfunction filterValidUsers(users: any[], schema: any): any[] {\n    return users.filter(user => validateUserData(user, schema));\n}\n\n// List of users to be validated\nconst users = [\n    { id: 1, name: 'John Doe', email: 'john.doe@example.com', age: 30 },\n    { id: 2, name: 'Jane Smith', email: 'jane.smith@example.com', age: 25 },\n    { id: 3, name: 'Invalid User', email: 'invalid@example.com', age: 'unknown' }\n];\n", "suffix": "\n\n// Assertions\nassert.strictEqual(validUsers.length, 2, 'There should be exactly 2 valid users');\nassert.strictEqual(validUsers[0].name, 'John Doe', 'First valid user should be John Doe');\nassert.strictEqual(validUsers[1].name, 'Jane Smith', 'Second valid user should be Jane Smith');\n\n// Cleanup code (if any)\n", "golden_completion": "const validUsers = filterValidUsers(users, userSchema);\n", "LLM_justification": "This test case evaluates the LLM's ability to understand and continue code that involves data validation using schemas. The completion requires the LLM to recognize the existing pattern of schema validation and apply it correctly to filter a list of users based on the predefined schema. The test ensures that the LLM grasps the business logic of validating user data against a schema and can use a helper function to achieve this.", "assertions": "assert.strictEqual(validUsers.length, 2, 'There should be exactly 2 valid users');\nassert.strictEqual(validUsers[0].name, 'John Doe', 'First valid user should be John Doe');\nassert.strictEqual(validUsers[1].name, 'Jane Smith', 'Second valid user should be Jane Smith');", "o3-mini": "const validUsers = filterValidUsers(users, userSchema);"}
{"id": "14", "testsource": "devbench-code-purpose-understanding", "language": "typescript", "prefix": "import * as fs from 'fs';\n\ninterface User {\n  id: number;\n  name: string;\n  email: string;\n  password: string;\n}\n\ninterface ValidationResult {\n  valid: boolean;\n  errors: string[];\n}\n\nconst users: User[] = [\n  { id: 1, name: 'Alice', email: 'alice@example.com', password: 'password123' },\n  { id: 2, name: 'Bob', email: 'bob@example.com', password: 'securepass' },\n];\n\nfunction validateEmail(email: string): boolean {\n  const emailRegex = /^[\\w-\\.]+@([\\w-]+\\.)+[\\w-]{2,4}$/;\n  return emailRegex.test(email);\n}\n\nfunction validatePassword(password: string): boolean {\n  const minLength = 8;\n  return password.length >= minLength;\n}\n\nfunction validateUser(user: User): ValidationResult {\n  const errors: string[] = [];\n  if (!validateEmail(user.email)) {\n    errors.push('Invalid email format');\n  }\n  if (!validatePassword(user.password)) {\n    errors.push('Password must be at least 8 characters long');\n  }\n  return {\n    valid: errors.length === 0,\n    errors,\n  };\n}\n\nfunction saveUsersToFile(filename: string, users: User[]): void {\n  const data = JSON.stringify(users, null, 2);\n  fs.writeFileSync(filename, data, 'utf-8');\n}\n\nfunction loadUsersFromFile(filename: string): User[] {\n  const data = fs.readFileSync(filename, 'utf-8');\n  return JSON.parse(data);\n}\n\nfunction sanitizeUser(user: User): User {\n  return {\n    ...user,\n    password: '', // Remove password for security reasons\n  };\n}\n\nfunction sanitizeUsers(users: User[]): User[] {\n  return users.map(sanitizeUser);\n}\n\nconst filename = 'users.json';\n\n// Save initial users to file\nsaveUsersToFile(filename, users);\n\n// Load users from file\nconst loadedUsers = loadUsersFromFile(filename);\n\n// Validate loaded users\nconst validationResults = loadedUsers.map(validateUser);\n// Print validation errors\n", "suffix": "\n// Sanitize users for display\nconst sanitizedUsers = sanitizeUsers(loadedUsers);\n\n// Display sanitized users\nconsole.log(sanitizedUsers);\n\n// Clean up the file after tests\nfs.unlinkSync(filename);\n", "golden_completion": "\nfor (const result of validationResults) {\n  if (!result.valid) {\n    console.error('Validation errors:', result.errors);\n  }\n}\n", "LLM_justification": "This test case is a good example because it combines data validation and file operations, which are common tasks in many applications. The prefix sets up a scenario where user data is validated and saved to a file, then loaded and validated again. The golden completion involves iterating over the validation results and logging any errors, demonstrating understanding of the business logic and validation requirements. The suffix sanitizes the user data for display and performs file cleanup, ensuring proper resource management. This scenario tests the LLM's ability to understand and correctly complete the validation and error handling logic in a realistic context.", "assertions": "import { strict as assert } from 'assert';\n\n// Ensure the loaded users match the initial users\nassert.deepEqual(loadedUsers, users);\n\n// Ensure validation results are as expected\nconst expectedValidationResults = [\n  { valid: true, errors: [] },\n  { valid: true, errors: [] }\n];\nassert.deepEqual(validationResults, expectedValidationResults);\n\n// Ensure sanitized users do not contain passwords\nconst expectedSanitizedUsers = [\n  { id: 1, name: 'Alice', email: 'alice@example.com', password: '' },\n  { id: 2, name: 'Bob', email: 'bob@example.com', password: '' }\n];\nassert.deepEqual(sanitizedUsers, expectedSanitizedUsers);\n\n// Ensure the file no longer exists\nassert.throws(() => fs.readFileSync(filename), /ENOENT/);\n", "o3-mini": "validationResults.forEach((result, i) => {\n  if (!result.valid) {\n    console.log(`User ${loadedUsers[i].name} validation errors: ${result.errors.join(', ')}`);\n  }\n});"}
{"id": "15", "testsource": "devbench-code-purpose-understanding", "language": "typescript", "prefix": "import * as assert from 'assert';\n\ninterface Dataset {\n    id: number;\n    value: number;\n}\n\nclass DataAnalyzer {\n    private data: Dataset[];\n\n    constructor(data: Dataset[]) {\n        this.data = data;\n    }\n\n    public findMaxValue(): number {\n        if (this.data.length === 0) {\n            throw new Error('Dataset is empty');\n        }\n        return Math.max(...this.data.map(d => d.value));\n    }\n\n    public findMinValue(): number {\n        if (this.data.length === 0) {\n            throw new Error('Dataset is empty');\n        }\n        return Math.min(...this.data.map(d => d.value));\n    }\n\n    public calculateAverage(): number {\n        if (this.data.length === 0) {\n            throw new Error('Dataset is empty');\n        }\n        const sum = this.data.reduce((acc, d) => acc + d.value, 0);\n        return sum / this.data.length;\n    }\n\n    public findMedian(): number {\n        if (this.data.length === 0) {\n            throw new Error('Dataset is empty');\n        }\n        const sorted = [...this.data].sort((a, b) => a.value - b.value);\n        const mid = Math.floor(sorted.length / 2);\n        return sorted.length % 2 !== 0 ? sorted[mid].value : (sorted[mid - 1].value + sorted[mid].value) / 2;\n    }\n\n    // Next, we want to implement a method to normalize the dataset values\n", "suffix": "\n    // Method to remove any outliers from the dataset\n    public removeOutliers(): Dataset[] {\n        const q1 = this.calculateQuantile(0.25);\n        const q3 = this.calculateQuantile(0.75);\n        const iqr = q3 - q1;\n        const lowerBound = q1 - 1.5 * iqr;\n        const upperBound = q3 + 1.5 * iqr;\n        return this.data.filter(d => d.value >= lowerBound && d.value <= upperBound);\n    }\n\n    private calculateQuantile(quantile: number): number {\n        if (this.data.length === 0) {\n            throw new Error('Dataset is empty');\n        }\n        const sorted = [...this.data].sort((a, b) => a.value - b.value);\n        const pos = (sorted.length - 1) * quantile;\n        const base = Math.floor(pos);\n        const rest = pos - base;\n        if ((sorted[base + 1] !== undefined)) {\n            return sorted[base].value + rest * (sorted[base + 1].value - sorted[base].value);\n        } else {\n            return sorted[base].value;\n        }\n    }\n}\n\nconst sampleData: Dataset[] = [\n    { id: 1, value: 10 },\n    { id: 2, value: 20 },\n    { id: 3, value: 30 },\n    { id: 4, value: 40 },\n    { id: 5, value: 50 }\n];\nconst analyzer = new DataAnalyzer(sampleData);\n\nassert.strictEqual(analyzer.findMaxValue(), 50);\nassert.strictEqual(analyzer.findMinValue(), 10);\nassert.strictEqual(analyzer.calculateAverage(), 30);\nassert.strictEqual(analyzer.findMedian(), 30);\nassert.deepStrictEqual(analyzer.removeOutliers(), sampleData);\n", "golden_completion": "    public normalizeData(): Dataset[] {\n        if (this.data.length === 0) {\n            throw new Error('Dataset is empty');\n        }\n        const min = this.findMinValue();\n        const max = this.findMaxValue();\n        return this.data.map(d => ({\n            ...d,\n            value: (d.value - min) / (max - min)\n        }));\n    }\n", "LLM_justification": "This test case examines the LLM's ability to understand the purpose of implementing a method to normalize dataset values within a class designed for data analysis. The scenario involves typical data analysis functions such as finding the max, min, average, and median values. The completion requires the model to implement a method that normalizes the dataset values based on the minimum and maximum values. This tests the model's comprehension of data normalization in a statistical context, and its ability to continue a pattern of methods for analyzing datasets. The assertions confirm that the normalization function works correctly and integrates well with other methods in the class.", "assertions": "assert.deepStrictEqual(analyzer.normalizeData(), [\n    { id: 1, value: 0 },\n    { id: 2, value: 0.25 },\n    { id: 3, value: 0.5 },\n    { id: 4, value: 0.75 },\n    { id: 5, value: 1 }\n]);\n", "o3-mini": "    public normalizeData(): Dataset[] {\n        const min = this.findMinValue();\n        const max = this.findMaxValue();\n        if (max === min) {\n            return this.data.map(d => ({ ...d, value: 0 }));\n        }\n        return this.data.map(d => ({ ...d, value: (d.value - min) / (max - min) }));\n    }"}
{"id": "16", "testsource": "devbench-code-purpose-understanding", "language": "typescript", "prefix": "import * as fs from 'fs';\nimport * as path from 'path';\n\ninterface LogEntry {\n    timestamp: string;\n    level: 'INFO' | 'WARN' | 'ERROR';\n    message: string;\n}\n\nclass Logger {\n    private logFilePath: string;\n    private logEntries: LogEntry[] = [];\n\n    constructor(logFilePath: string) {\n        this.logFilePath = logFilePath;\n    }\n\n    private formatLogEntry(level: 'INFO' | 'WARN' | 'ERROR', message: string): LogEntry {\n        return {\n            timestamp: new Date().toISOString(),\n            level,\n            message\n        };\n    }\n\n    public logInfo(message: string) {\n        const logEntry = this.formatLogEntry('INFO', message);\n        this.logEntries.push(logEntry);\n        this.writeLogToFile(logEntry);\n    }\n\n    public logWarn(message: string) {\n        const logEntry = this.formatLogEntry('WARN', message);\n        this.logEntries.push(logEntry);\n        this.writeLogToFile(logEntry);\n    }\n\n    public logError(message: string) {\n        const logEntry = this.formatLogEntry('ERROR', message);\n        this.logEntries.push(logEntry);\n        this.writeLogToFile(logEntry);\n    }\n\n    private writeLogToFile(logEntry: LogEntry) {\n        const logMessage = `${logEntry.timestamp} [${logEntry.level}] ${logEntry.message}\\n`;\n        fs.appendFileSync(this.logFilePath, logMessage);\n    }\n\n    public getLogs(): LogEntry[] {\n        return this.logEntries;\n    }\n}\n\n// Usage example\nconst logger = new Logger(path.join(__dirname, 'app.log'));\nlogger.logInfo('Application started');\nlogger.logWarn('Low disk space');\nlogger.logError('Unhandled exception occurred');\n\nconsole.log('Current logs:', logger.getLogs());\n\n// Function to rotate logs\nfunction rotateLogs(logger: Logger, newLogFilePath: string) {", "suffix": "}\n\n// Test assertions\nimport * as assert from 'assert';\n\nconst testLogger = new Logger(path.join(__dirname, 'test.log'));\ntestLogger.logInfo('Test log entry');\nassert.strictEqual(testLogger.getLogs().length, 1);\nassert.strictEqual(testLogger.getLogs()[0].level, 'INFO');\nassert.strictEqual(testLogger.getLogs()[0].message, 'Test log entry');\n\nrotateLogs(testLogger, path.join(__dirname, 'new_test.log'));\nassert.strictEqual(testLogger.getLogs().length, 0);\n\nconsole.log('All tests passed');\n\n// Clean up\nfs.unlinkSync(path.join(__dirname, 'test.log'));\nfs.unlinkSync(path.join(__dirname, 'new_test.log'));\nfs.unlinkSync(path.join(__dirname, 'app.log'));\n", "golden_completion": "    const oldLogEntries = logger.getLogs();\n    logger = new Logger(newLogFilePath);\n    for (const entry of oldLogEntries) {\n        switch (entry.level) {\n            case 'INFO':\n                logger.logInfo(entry.message);\n                break;\n            case 'WARN':\n                logger.logWarn(entry.message);\n                break;\n            case 'ERROR':\n                logger.logError(entry.message);\n                break;\n        }\n    }\n", "LLM_justification": "This scenario tests the LLM's ability to understand the purpose of rotating logs in a logging system, a common operation in system operations and monitoring. The Logger class manages log entries and writes them to a file, while the rotateLogs function is intended to transfer log entries to a new log file, simulating log rotation. The golden completion demonstrates the correct logic for transferring log entries from the old logger to a new logger, ensuring continuity of log data. The assertions verify that the logs are accurately transferred and the old log file is cleared, which are critical business rules in log management.", "assertions": "import * as assert from 'assert';\n\nconst testLogger = new Logger(path.join(__dirname, 'test.log'));\ntestLogger.logInfo('Test log entry');\nassert.strictEqual(testLogger.getLogs().length, 1);\nassert.strictEqual(testLogger.getLogs()[0].level, 'INFO');\nassert.strictEqual(testLogger.getLogs()[0].message, 'Test log entry');\n\nrotateLogs(testLogger, path.join(__dirname, 'new_test.log'));\nassert.strictEqual(testLogger.getLogs().length, 0);\n\nconsole.log('All tests passed');\n\n// Clean up\nfs.unlinkSync(path.join(__dirname, 'test.log'));\nfs.unlinkSync(path.join(__dirname, 'new_test.log'));\nfs.unlinkSync(path.join(__dirname, 'app.log'));\n", "o3-mini": "logger['logEntries'] = [];\nlogger['logFilePath'] = newLogFilePath;"}
{"id": "17", "testsource": "devbench-code-purpose-understanding", "language": "typescript", "prefix": "import * as fs from 'fs';\nimport * as path from 'path';\n\n// Utility function to check if a path is a directory\nfunction isDirectory(filePath: string): boolean {\n    return fs.statSync(filePath).isDirectory();\n}\n\n// Utility function to read files in a directory\nfunction readDirectory(dirPath: string): string[] {\n    return fs.readdirSync(dirPath);\n}\n\n// Function to filter and return only .txt files from a directory\nfunction getTxtFiles(directory: string): string[] {\n    return readDirectory(directory).filter(file => path.extname(file) === '.txt');\n}\n\n// Function to read the content of a file\nfunction readFileContent(filePath: string): string {\n    return fs.readFileSync(filePath, 'utf8');\n}\n\n// Function to process the content of a text file\nfunction processFileContent(content: string): string {\n    // Example processing: Convert to uppercase\n    return content.toUpperCase();\n}\n\n// Function to write content to a file\nfunction writeFileContent(filePath: string, content: string): void {\n    fs.writeFileSync(filePath, content);\n}\n\n// Function to process all .txt files in a directory\nfunction processTxtFilesInDirectory(directory: string): void {\n    if (!isDirectory(directory)) {\n        throw new Error(`${directory} is not a directory`);\n    }\n\n    const txtFiles = getTxtFiles(directory);\n    for (const file of txtFiles) {\n        const filePath = path.join(directory, file);\n        const content = readFileContent(filePath);\n        const processedContent = processFileContent(content);\n        writeFileContent(filePath, processedContent);\n    }\n}\n\n// Mock directory and files for testing\nconst testDir = './testDir';\nconst testFiles = ['test1.txt', 'test2.txt'];\n\nif (!fs.existsSync(testDir)) {\n    fs.mkdirSync(testDir);\n}\nfor (const file of testFiles) {\n    fs.writeFileSync(path.join(testDir, file), `Content of ${file}`);\n}\n\ntry {\n    processTxtFilesInDirectory(testDir);\n", "suffix": "    // Cleanup\n    for (const file of testFiles) {\n        fs.unlinkSync(path.join(testDir, file));\n    }\n    fs.rmdirSync(testDir);\n} catch (error) {\n    console.error(error);\n}\n", "golden_completion": "    const processedFiles = getTxtFiles(testDir);\n    for (const file of processedFiles) {\n        const content = readFileContent(path.join(testDir, file));\n        console.log(`Processed content of ${file}:`, content);\n    }\n", "LLM_justification": "This test case is a realistic example of a file processing system that reads, processes, and writes text files in a directory. It tests the LLM's ability to understand and continue code that handles string/text manipulation within a system operations context. The completion focuses on verifying that the text files have been processed correctly by reading and logging the processed content. This ensures the model comprehends the entire workflow and maintains the business logic of processing text files.", "assertions": "const processedContent1 = fs.readFileSync(path.join(testDir, 'test1.txt'), 'utf8');\nconst processedContent2 = fs.readFileSync(path.join(testDir, 'test2.txt'), 'utf8');\nconsole.assert(processedContent1 === 'CONTENT OF TEST1.TXT', 'test1.txt content mismatch');\nconsole.assert(processedContent2 === 'CONTENT OF TEST2.TXT', 'test2.txt content mismatch');\n", "o3-mini": "    console.log(\"Processed .txt files successfully.\");"}
{"id": "18", "testsource": "devbench-code-purpose-understanding", "language": "typescript", "prefix": "import fs from 'fs';\nimport { promisify } from 'util';\n\nconst readFileAsync = promisify(fs.readFile);\nconst writeFileAsync = promisify(fs.writeFile);\n\ninterface VideoMetadata {\n    filename: string;\n    duration: number;\n    resolution: string;\n    format: string;\n}\n\n// Helper function to simulate video processing\nasync function processVideo(file: string): Promise<VideoMetadata> {\n    // Simulate processing time\n    await new Promise(resolve => setTimeout(resolve, 1000));\n    // Return mock metadata\n    return {\n        filename: file,\n        duration: 3600,\n        resolution: '1920x1080',\n        format: 'mp4'\n    };\n}\n\n// Function to handle video processing and saving metadata\nasync function handleVideoProcessing(inputFile: string, outputMetadataFile: string): Promise<void> {\n    try {\n        console.log(`Processing video: ${inputFile}`);\n        const metadata = await processVideo(inputFile);\n        console.log('Video processed successfully. Metadata:', metadata);\n", "suffix": "        const metadataJson = JSON.stringify(metadata, null, 2);\n        await writeFileAsync(outputMetadataFile, metadataJson);\n        console.log(`Metadata saved to ${outputMetadataFile}`);\n    } catch (error) {\n        console.error('Error processing video:', error);\n    }\n}\n\n// Test the video processing function\n(async () => {\n    const inputFile = 'example_video.mp4';\n    const outputMetadataFile = 'video_metadata.json';\n    await handleVideoProcessing(inputFile, outputMetadataFile);\n})();\n", "golden_completion": "        if (!metadata.filename || !metadata.duration || !metadata.resolution || !metadata.format) {\n            throw new Error('Invalid metadata');\n        }\n", "LLM_justification": "This test case checks the LLM's ability to understand the business logic of video processing and validation of metadata. The completion ensures that the metadata generated from video processing is valid before proceeding to save it. This involves checking that all required fields in the metadata are present and correctly populated. The scenario is practical and reflects real-world requirements where data integrity is crucial before performing any file operations.", "assertions": "import { strict as assert } from 'assert';\n\n(async () => {\n    try {\n        const inputFile = 'test_video.mp4';\n        const outputMetadataFile = 'test_video_metadata.json';\n        await handleVideoProcessing(inputFile, outputMetadataFile);\n        const savedMetadata = await readFileAsync(outputMetadataFile, 'utf-8');\n        const parsedMetadata = JSON.parse(savedMetadata);\n        assert.strictEqual(parsedMetadata.filename, 'test_video.mp4', 'Filename should match the input video file');\n        assert.strictEqual(parsedMetadata.duration, 3600, 'Duration should be 3600 seconds');\n        assert.strictEqual(parsedMetadata.resolution, '1920x1080', 'Resolution should be 1920x1080');\n        assert.strictEqual(parsedMetadata.format, 'mp4', 'Format should be mp4');\n    } catch (error) {\n        console.error('Assertion failed:', error);\n        process.exit(1);\n    }\n    console.log('All assertions passed.');\n})();", "o3-mini": "        metadata.processedAt = new Date().toISOString();"}
{"id": "19", "testsource": "devbench-code-purpose-understanding", "language": "typescript", "prefix": "import * as fs from 'fs';\nimport * as path from 'path';\n\n// Utility function to read a file asynchronously\nfunction readFileAsync(filePath: string): Promise<string> {\n    return new Promise((resolve, reject) => {\n        fs.readFile(filePath, 'utf8', (err, data) => {\n            if (err) {\n                reject(err);\n            } else {\n                resolve(data);\n            }\n        });\n    });\n}\n\n// Utility function to write data to a file asynchronously\nfunction writeFileAsync(filePath: string, data: string): Promise<void> {\n    return new Promise((resolve, reject) => {\n        fs.writeFile(filePath, data, 'utf8', (err) => {\n            if (err) {\n                reject(err);\n            } else {\n                resolve();\n            }\n        });\n    });\n}\n\n// Class to handle file operations for a media processing application\nclass MediaFileHandler {\n    private directory: string;\n\n    constructor(directory: string) {\n        this.directory = directory;\n    }\n\n    // Method to process a media file\n    async processFile(fileName: string): Promise<void> {\n        const filePath = path.join(this.directory, fileName);\n        try {\n            const fileData = await readFileAsync(filePath);\n            const processedData = this.modifyMediaContent(fileData);\n            await writeFileAsync(filePath, processedData);\n        } catch (error) {\n            console.error(`Error processing file ${fileName}:`, error);\n        }\n    }\n\n    // Placeholder method to modify media content\n    private modifyMediaContent(data: string): string {\n        // Simulate media content modification\n        return data.toUpperCase();\n    }\n}\n\n// Example usage\n(async () => {\n    const mediaHandler = new MediaFileHandler('./media');\n    await mediaHandler.processFile('example.txt');\n})();\n\n// Test cases\nasync function testMediaFileHandler() {\n    const testDirectory = './testMedia';\n    const testFileName = 'test.txt';\n    const testFilePath = path.join(testDirectory, testFileName);\n    const originalContent = 'Hello, world!';\n    const expectedContent = 'HELLO, WORLD!';\n\n    // Ensure the test directory exists\n    if (!fs.existsSync(testDirectory)) {\n        fs.mkdirSync(testDirectory);\n    }\n\n    // Write the original content to the test file\n    await writeFileAsync(testFilePath, originalContent);\n", "suffix": "console.log('Test completed');\n}\n\ntestMediaFileHandler().then(() => {\n    // Clean up test file\n    fs.unlinkSync(path.join('./testMedia', 'test.txt'));\n    fs.rmdirSync('./testMedia');\n}).catch((error) => {\n    console.error('Test failed:', error);\n});", "golden_completion": "    const mediaHandler = new MediaFileHandler(testDirectory);\n    await mediaHandler.processFile(testFileName);\n\n    // Read the processed file content\n    const processedContent = await readFileAsync(testFilePath);\n\n    // Assertions\n    console.assert(processedContent === expectedContent, 'Processed content does not match expected content');", "LLM_justification": "This test case effectively evaluates the LLM's understanding of promises and async/await in the context of a media processing application. The prefix establishes a comprehensive setup, including utility functions for file operations and a class designed to process media files asynchronously. The golden completion involves correctly using the MediaFileHandler class to process a test file, followed by reading the file and asserting that its content matches the expected outcome. This scenario tests the LLM's ability to comprehend the asynchronous flow and maintain business logic consistency, ensuring that the file processing and content modification are correctly implemented. The suffix ensures cleanup of resources after assertions, adhering to best practices.", "assertions": "console.assert(fs.existsSync('./testMedia/test.txt'), 'Test file should exist');\nconsole.assert(fs.readFileSync('./testMedia/test.txt', 'utf8') === 'HELLO, WORLD!', 'Test file content should be processed correctly');", "o3-mini": "    await new MediaFileHandler(testDirectory).processFile(testFileName);\n    const processedContent = await readFileAsync(testFilePath);\n    if (processedContent !== expectedContent) {\n        throw new Error('Test failed: Content does not match expected');\n    }"}
{"id": "20", "testsource": "devbench-code-purpose-understanding", "language": "typescript", "prefix": "import * as assert from 'assert';\n\n// This module simulates a media processing pipeline where frames of a video are processed asynchronously.\n// The main classes and functions are defined below:\n\n// Represents a single frame of video\nclass VideoFrame {\n    constructor(public id: number, public data: Uint8Array) {}\n}\n\n// A mock function to simulate asynchronous frame processing\nasync function processFrame(frame: VideoFrame): Promise<VideoFrame> {\n    return new Promise((resolve) => {\n        setTimeout(() => {\n            // Simulate processing by modifying the frame data\n            frame.data = frame.data.map((byte) => byte ^ 0xff); // Invert all bits\n            resolve(frame);\n        }, 100);\n    });\n}\n\n// A class to handle the media processing pipeline\nclass MediaProcessor {\n    private frames: VideoFrame[] = [];\n\n    // Add a frame to the processing queue\n    addFrame(frame: VideoFrame) {\n        this.frames.push(frame);\n    }\n\n    // Process all frames asynchronously\n    async processAllFrames(): Promise<VideoFrame[]> {\n        const processedFrames: VideoFrame[] = [];\n        for (const frame of this.frames) {\n            const processedFrame = await processFrame(frame);\n            processedFrames.push(processedFrame);\n        }\n        return processedFrames;\n    }\n}\n\n// Helper function to create a random frame\nfunction createRandomFrame(id: number): VideoFrame {\n    const data = new Uint8Array(10);\n    for (let i = 0; i < data.length; i++) {\n        data[i] = Math.floor(Math.random() * 256);\n    }\n    return new VideoFrame(id, data);\n}\n\n// Create a media processor instance\nconst mediaProcessor = new MediaProcessor();\n\n// Add some random frames to the processor\nfor (let i = 0; i < 5; i++) {\n    mediaProcessor.addFrame(createRandomFrame(i));\n}\n", "suffix": ".finally(() => {\n    // Clean up resources if any\n    console.log('Processing complete');\n});\n", "golden_completion": "mediaProcessor.processAllFrames().then((processedFrames) => {\n    assert.strictEqual(processedFrames.length, 5, 'All frames should be processed');\n    for (let i = 0; i < processedFrames.length; i++) {\n        const originalFrame = mediaProcessor.frames[i];\n        const processedFrame = processedFrames[i];\n        // Ensure that the frame ID remains the same\n        assert.strictEqual(originalFrame.id, processedFrame.id, 'Frame ID should not change');\n        // Verify that the frame data has been processed (inverted)\n        for (let j = 0; j < originalFrame.data.length; j++) {\n            assert.strictEqual(originalFrame.data[j] ^ 0xff, processedFrame.data[j], 'Frame data should be inverted');\n        }\n    }\n})\n", "LLM_justification": "This test case effectively evaluates the LLM's ability to understand and continue TypeScript code that involves asynchronous processing of media frames. The prefix sets up a comprehensive media processing pipeline, including helper functions and classes. The golden completion and suffix focus on verifying that the asynchronous processing logic is correctly implemented and the processed frames meet the expected business rules, such as maintaining frame IDs and correctly inverting frame data. This scenario tests both the technical pattern of promises/async-await and the domain context of media processing, making it a robust benchmark for semantic code understanding.", "assertions": "mediaProcessor.processAllFrames().then((processedFrames) => {\n    assert.strictEqual(processedFrames.length, 5, 'All frames should be processed');\n    for (let i = 0; i < processedFrames.length; i++) {\n        const originalFrame = mediaProcessor.frames[i];\n        const processedFrame = processedFrames[i];\n        // Ensure that the frame ID remains the same\n        assert.strictEqual(originalFrame.id, processedFrame.id, 'Frame ID should not change');\n        // Verify that the frame data has been processed (inverted)\n        for (let j = 0; j < originalFrame.data.length; j++) {\n            assert.strictEqual(originalFrame.data[j] ^ 0xff, processedFrame.data[j], 'Frame data should be inverted');\n        }\n    }\n});\n", "o3-mini": "mediaProcessor.processAllFrames().then((frames) => {\n    console.log('Processed frames:', frames);\n})"}
{"id": "21", "testsource": "devbench-code-purpose-understanding", "language": "typescript", "prefix": "import * as fs from 'fs';\nimport * as path from 'path';\n\ninterface MediaFile {\n    name: string;\n    path: string;\n    size: number;\n    type: 'image' | 'video' | 'audio';\n}\n\nclass MediaProcessor {\n    private mediaFiles: MediaFile[] = [];\n\n    constructor(private directory: string) {}\n\n    private async readDirectory(): Promise<void> {\n        return new Promise((resolve, reject) => {\n            fs.readdir(this.directory, (err, files) => {\n                if (err) {\n                    reject(err);\n                } else {\n                    files.forEach(file => {\n                        const filePath = path.join(this.directory, file);\n                        const stats = fs.statSync(filePath);\n                        if (stats.isFile()) {\n                            const fileType = this.getFileType(file);\n                            if (fileType) {\n                                this.mediaFiles.push({\n                                    name: file,\n                                    path: filePath,\n                                    size: stats.size,\n                                    type: fileType\n                                });\n                            }\n                        }\n                    });\n                    resolve();\n                }\n            });\n        });\n    }\n\n    private getFileType(fileName: string): 'image' | 'video' | 'audio' | null {\n        const ext = path.extname(fileName).toLowerCase();\n        switch (ext) {\n            case '.jpg':\n            case '.jpeg':\n            case '.png':\n            case '.gif':\n                return 'image';\n            case '.mp4':\n            case '.avi':\n            case '.mov':\n                return 'video';\n            case '.mp3':\n            case '.wav':\n            case '.flac':\n                return 'audio';\n            default:\n                return null;\n        }\n    }\n\n    public async processMediaFiles(): Promise<void> {\n        await this.readDirectory();\n        for (const mediaFile of this.mediaFiles) {\n            try {\n                await this.processFile(mediaFile);\n            } catch (error) {\n                console.error(`Failed to process file: ${mediaFile.name}`, error);\n            }\n        }\n    }\n\n    private async processFile(mediaFile: MediaFile): Promise<void> {\n        // Placeholder for processing logic\n        console.log(`Processing ${mediaFile.type} file: ${mediaFile.name}`);\n    }\n}\n\nconst mediaProcessor = new MediaProcessor('./media');\n", "suffix": "\n", "golden_completion": "mediaProcessor.processMediaFiles().then(() => {\n    console.log('All media files processed successfully.');\n}).catch(error => {\n    console.error('Error processing media files:', error);\n});\n", "LLM_justification": "This scenario tests the model's ability to understand and continue TypeScript code involving async/await and error handling within a media processing context. The completion involves handling the promise returned by the processMediaFiles method and logging the appropriate messages based on success or failure. This requires understanding the purpose of the method and the business context of processing media files.", "assertions": "import * as assert from 'assert';\n\nconst logMessages: string[] = [];\nconst originalConsoleLog = console.log;\nconst originalConsoleError = console.error;\n\nconsole.log = (message: string) => { logMessages.push(message); };\nconsole.error = (message: string) => { logMessages.push(message); };\n\nconst mediaProcessor = new MediaProcessor('./media');\nmediaProcessor.processMediaFiles().then(() => {\n    assert.strictEqual(logMessages.includes('All media files processed successfully.'), true, 'Success message should be logged');\n    assert.strictEqual(logMessages.some(msg => msg.includes('Error processing media files:')), false, 'Error message should not be logged');\n}).catch(error => {\n    assert.fail('Should not reach here');\n}).finally(() => {\n    console.log = originalConsoleLog;\n    console.error = originalConsoleError;\n});\n", "o3-mini": "mediaProcessor.processMediaFiles();"}
{"id": "22", "testsource": "devbench-code-purpose-understanding", "language": "typescript", "prefix": "import fs from 'fs';\nimport path from 'path';\n\n// Configuration for the build process\nconst config = {\n\tbuildDir: 'dist',\n\tsrcDir: 'src',\n\tentryFile: 'index.ts',\n\toutputFile: 'bundle.js'\n};\n\n// Utility function to create directory if it doesn't exist\nfunction ensureDirExists(dir: string): void {\n\tif (!fs.existsSync(dir)) {\n\t\tfs.mkdirSync(dir);\n\t}\n}\n\n// Function to clean the build directory\nfunction cleanBuildDir(): void {\n\tif (fs.existsSync(config.buildDir)) {\n\t\tfs.readdirSync(config.buildDir).forEach((file) => {\n\t\t\tfs.unlinkSync(path.join(config.buildDir, file));\n\t\t});\n\t}\n}\n\n// Function to transpile TypeScript files to JavaScript\nfunction transpile(srcFile: string, outFile: string): Promise<void> {\n\treturn new Promise((resolve, reject) => {\n\t\t// Simulate transpilation process\n\t\tsetTimeout(() => {\n\t\t\ttry {\n\t\t\t\tconst content = fs.readFileSync(srcFile, 'utf-8');\n\t\t\t\tconst transpiledContent = content.replace(/console\\.log/g, 'console.info'); // Simple transpilation mock\n\t\t\t\tfs.writeFileSync(outFile, transpiledContent);\n\t\t\t\tresolve();\n\t\t\t} catch (error) {\n\t\t\t\treject(error);\n\t\t\t}\n\t\t}, 1000);\n\t});\n}\n\n// Main build function\nasync function buildProject(): Promise<void> {\n\ttry {\n\t\t// Ensure build directory exists\n\t\tensureDirExists(config.buildDir);\n\t\t\n\t\t// Clean build directory\n\t\tcleanBuildDir();\n\t\t\n\t\t// Transpile the entry file\n\t\tawait transpile(path.join(config.srcDir, config.entryFile), path.join(config.buildDir, config.outputFile));\n\t\t\n\t\tconsole.info('Build completed successfully.');\n\t} catch (error) {\n\t\tconsole.error('Build failed:', error);\n\t}\n}\n\n// Run the build process\nbuildProject().then(() => {\n\tconsole.info('Build script finished.');\n});\n", "suffix": "\n\nconst projectWatcher = createWatcher(config.srcDir);\nprojectWatcher.startWatching();\n\n// Stop watching after some time\nsetTimeout(() => {\n\tprojectWatcher.stopWatching();\n\tconsole.info('Stopped watching for changes.');\n}, 60000);\n", "golden_completion": "\n// Additional functionality to watch for file changes and rebuild\ntype Watcher = {\n\twatchDir: string;\n\tstartWatching: () => void;\n\tstopWatching: () => void;\n};\n\nconst createWatcher = (watchDir: string): Watcher => {\n\tlet watcher: fs.FSWatcher | null = null;\n\n\tconst startWatching = () => {\n\t\tif (!watcher) {\n\t\t\twatcher = fs.watch(watchDir, (eventType, filename) => {\n\t\t\t\tif (filename && eventType === 'change') {\n\t\t\t\t\tconsole.log(`File changed: ${filename}`);\n\t\t\t\t\tbuildProject();\n\t\t\t\t}\n\t\t\t});\n\t\t}\n\t};\n\n\tconst stopWatching = () => {\n\t\tif (watcher) {\n\t\t\twatcher.close();\n\t\t\twatcher = null;\n\t\t}\n\t};\n\n\treturn { watchDir, startWatching, stopWatching };\n};\n\n", "LLM_justification": "This test case evaluates the LLM's understanding of tool automation in the context of a build process. The completion involves creating a file watcher that triggers the build process upon changes in the source directory. This scenario tests the LLM's ability to comprehend asynchronous operations, event handling, and the integration of these concepts into a build automation context. The assertions verify that the watch functionality correctly triggers the build process and manages resources appropriately.", "assertions": "import assert from 'assert';\nimport sinon from 'sinon';\n\n(async () => {\n\tconst readFileSyncStub = sinon.stub(fs, 'readFileSync').returns('console.log(\"Hello, World!\");');\n\tconst writeFileSyncStub = sinon.stub(fs, 'writeFileSync');\n\tconst watchStub = sinon.stub(fs, 'watch').callsFake((dir, callback) => {\n\t\tsetTimeout(() => callback('change', 'index.ts'), 100);\n\t\treturn { close: () => {} };\n\t});\n\n\tawait buildProject();\n\tassert.ok(readFileSyncStub.calledOnce, 'readFileSync should be called once');\n\tassert.ok(writeFileSyncStub.calledOnce, 'writeFileSync should be called once');\n\tassert.strictEqual(writeFileSyncStub.firstCall.args[1], 'console.info(\"Hello, World!\");', 'Transpilation should replace console.log with console.info');\n\n\tconst projectWatcher = createWatcher(config.srcDir);\n\tprojectWatcher.startWatching();\n\n\tsetTimeout(() => {\n\t\tassert.ok(watchStub.calledOnce, 'fs.watch should be called once to start watching');\n\t\tassert.ok(readFileSyncStub.calledTwice, 'readFileSync should be called twice after file change');\n\t\tassert.ok(writeFileSyncStub.calledTwice, 'writeFileSync should be called twice after file change');\n\t\tprojectWatcher.stopWatching();\n\t\treadFileSyncStub.restore();\n\t\twriteFileSyncStub.restore();\n\t\twatchStub.restore();\n\t}, 500);\n})();\n", "o3-mini": "function createWatcher(directory: string) {\n    let watcher: fs.FSWatcher;\n    return {\n        startWatching() {\n            watcher = fs.watch(directory, (event, filename) => {\n                console.info(`File ${filename} changed: ${event}`);\n            });\n        },\n        stopWatching() {\n            if (watcher) watcher.close();\n        }\n    }\n}"}
{"id": "23", "testsource": "devbench-code-purpose-understanding", "language": "typescript", "prefix": "import fs from 'fs';\nimport path from 'path';\n\n// Tool automation for builds: A utility to track build durations and log to a file\n\n// A class to manage build metrics\nclass BuildMetrics {\n    private buildStartTimes: Map<string, number>;\n    private buildDurations: Map<string, number>;\n    private logFilePath: string;\n\n    constructor(logFilePath: string) {\n        this.buildStartTimes = new Map();\n        this.buildDurations = new Map();\n        this.logFilePath = logFilePath;\n    }\n\n    // Method to start tracking a build\n    startBuild(buildName: string): void {\n        const startTime = Date.now();\n        this.buildStartTimes.set(buildName, startTime);\n    }\n\n    // Method to stop tracking a build\n    stopBuild(buildName: string): void {\n        const endTime = Date.now();\n        const startTime = this.buildStartTimes.get(buildName);\n        if (startTime !== undefined) {\n            const duration = endTime - startTime;\n            this.buildDurations.set(buildName, duration);\n        } else {\n            throw new Error(`Build ${buildName} was not started.`);\n        }\n    }\n\n    // Method to log build durations to a file\n    logBuildDurations(): void {\n        const logEntries = [];\n        this.buildDurations.forEach((duration, buildName) => {\n            logEntries.push(`${buildName}: ${duration}ms`);\n        });\n        const logData = logEntries.join('\\n');\n        fs.writeFileSync(this.logFilePath, logData);\n    }\n}\n\n// Example usage of the BuildMetrics class\nconst metrics = new BuildMetrics(path.join(__dirname, 'build.log'));\nmetrics.startBuild('build-1');\nsetTimeout(() => {\n    metrics.stopBuild('build-1');\n", "suffix": "    console.log('Build 1 duration logged.');\n}, 1000);\n\n// Assertions\nconst logFilePath = path.join(__dirname, 'build.log');\n\nsetTimeout(() => {\n    const logContent = fs.readFileSync(logFilePath, 'utf-8');\n    console.assert(logContent.includes('build-1: '), 'Build duration should be logged.');\n}, 1500);\n", "golden_completion": "    metrics.logBuildDurations();\n", "LLM_justification": "This test case evaluates an LLM's understanding of tool automation in a build process context, specifically focusing on logging build durations. The provided prefix sets up a class to track and log build metrics, and the completion requires the LLM to correctly identify where to invoke the logging method to maintain the business logic of recording build durations. The assertions check that the build duration is correctly logged, ensuring the LLM comprehends the purpose and flow of the code.", "assertions": "const logFilePath = path.join(__dirname, 'build.log');\n\nsetTimeout(() => {\n    const logContent = fs.readFileSync(logFilePath, 'utf-8');\n    console.assert(logContent.includes('build-1: '), 'Build duration should be logged.');\n}, 1500);\n", "o3-mini": "    metrics.logBuildDurations();"}
{"id": "24", "testsource": "devbench-code-purpose-understanding", "language": "typescript", "prefix": "import { readFileSync, writeFileSync } from 'fs';\nimport { join } from 'path';\n\n// Utility function to read JSON data from a file\nfunction readJsonFile(filePath: string): any {\n    const data = readFileSync(filePath, 'utf-8');\n    return JSON.parse(data);\n}\n\n// Utility function to write JSON data to a file\nfunction writeJsonFile(filePath: string, data: any): void {\n    const jsonData = JSON.stringify(data, null, 2);\n    writeFileSync(filePath, jsonData, 'utf-8');\n}\n\n// Function to generate a report based on metrics\nfunction generateReport(metrics: any[]): any {\n    let total = 0;\n    let count = 0;\n    for (const metric of metrics) {\n        total += metric.value;\n        count++;\n    }\n    const average = total / count;\n    return { total, average, count };\n}\n\n// Mock data for metrics\nconst metrics = [\n    { id: 1, value: 10 },\n    { id: 2, value: 20 },\n    { id: 3, value: 30 }\n];\n\n// Path to the report file\nconst reportFilePath = join(__dirname, 'report.json');\n\n// Read existing report\nlet report;\ntry {\n    report = readJsonFile(reportFilePath);\n} catch (error) {\n    report = null;\n}\n\n// Generate new report\nconst newReport = generateReport(metrics);\n\n// Save the new report\nwriteJsonFile(reportFilePath, newReport);\n", "suffix": "// Assertions to verify the correctness of the report\nimport { strict as assert } from 'assert';\n\nconst expectedReport = { total: 60, average: 20, count: 3 };\nassert.deepStrictEqual(newReport, expectedReport, 'The generated report does not match the expected report.');\n\n// Cleanup: delete the report file\nimport { unlinkSync } from 'fs';\nunlinkSync(reportFilePath);\n", "golden_completion": "const updatedReport = { ...report, ...newReport };\nwriteJsonFile(reportFilePath, updatedReport);\n", "LLM_justification": "This test case is designed to evaluate the LLM's ability to understand the semantic pattern of generating and updating a report based on metrics data. The scenario involves reading and writing JSON files, generating a new report, and updating an existing report. The golden completion demonstrates the correct merging of new report data with existing report data, which is a common business logic requirement in analytics contexts. The assertions verify the correctness of the generated report, ensuring that the business rules are maintained.", "assertions": "import { strict as assert } from 'assert';\nconst expectedUpdatedReport = { total: 60, average: 20, count: 3 };\nconst finalReport = readJsonFile(reportFilePath);\nassert.deepStrictEqual(finalReport, expectedUpdatedReport, 'The final report does not match the expected updated report.');", "o3-mini": "const savedReport = readJsonFile(reportFilePath);\nif (JSON.stringify(savedReport) !== JSON.stringify(newReport)) {\n    throw new Error('The saved report does not match the generated report.');\n}"}
{"id": "25", "testsource": "devbench-code-purpose-understanding", "language": "typescript", "prefix": "import { readFileSync } from 'fs';\nimport { createHash } from 'crypto';\n\n// Utility function to read a file and return its content as string\nfunction readFileContent(filePath: string): string {\n    try {\n        return readFileSync(filePath, 'utf8');\n    } catch (error) {\n        console.error(`Error reading file: ${filePath}`, error);\n        throw new Error('File read failed');\n    }\n}\n\n// Utility function to hash content using SHA-256\nfunction hashContent(content: string): string {\n    const hash = createHash('sha256');\n    hash.update(content);\n    return hash.digest('hex');\n}\n\n// Higher-order function to create an auditing mechanism\nfunction createAuditor(logFunction: (message: string) => void) {\n    return function (action: string, content: string) {\n        const timestamp = new Date().toISOString();\n        const hashedContent = hashContent(content);\n        logFunction(`[${timestamp}] Action: ${action}, Hash: ${hashedContent}`);\n    };\n}\n\n// Example log function\nfunction logToConsole(message: string) {\n    console.log(message);\n}\n\n// Create an auditor instance\nconst audit = createAuditor(logToConsole);\n\n// Example content and action\nconst exampleContent = 'Sensitive data that needs auditing';\nconst exampleAction = 'DATA_ACCESS';\n\n// Perform the audit\n", "suffix": "audit('DATA_MODIFICATION', exampleContent);\n\n// Assertions\nimport assert from 'assert';\n\nconst logMessages: string[] = [];\nfunction mockLogFunction(message: string) {\n    logMessages.push(message);\n}\n\nconst mockAudit = createAuditor(mockLogFunction);\nmockAudit('DATA_ACCESS', exampleContent);\n\nassert.strictEqual(logMessages.length, 1, 'Log message should be recorded');\nassert.ok(logMessages[0].includes('DATA_ACCESS'), 'Log message should contain the action');\nassert.ok(logMessages[0].includes(hashContent(exampleContent)), 'Log message should contain the hashed content');\n\n// Cleanup\nlogMessages.length = 0;", "golden_completion": "audit(exampleAction, exampleContent);", "LLM_justification": "This scenario tests the LLM's ability to understand higher-order functions and their use in a security context, specifically auditing. The prefix sets up utility functions for reading file content and hashing it, and it defines a higher-order function `createAuditor` that logs actions and hashed content. The completion involves using this auditor to log a specific action, demonstrating the LLM's comprehension of the business logic and correct usage of the provided functions. The assertions verify the correct logging behavior, ensuring that the action and hashed content are properly recorded. This makes it a good test case for understanding the semantic purpose and business rules.", "assertions": "import assert from 'assert';\n\nconst logMessages: string[] = [];\nfunction mockLogFunction(message: string) {\n    logMessages.push(message);\n}\n\nconst mockAudit = createAuditor(mockLogFunction);\nmockAudit('DATA_ACCESS', exampleContent);\n\nassert.strictEqual(logMessages.length, 1, 'Log message should be recorded');\nassert.ok(logMessages[0].includes('DATA_ACCESS'), 'Log message should contain the action');\nassert.ok(logMessages[0].includes(hashContent(exampleContent)), 'Log message should contain the hashed content');\n\n// Cleanup\nlogMessages.length = 0;", "o3-mini": "audit('DATA_MODIFICATION', exampleContent);"}
{"id": "26", "testsource": "devbench-code-purpose-understanding", "language": "typescript", "prefix": "import fs from 'fs';\nimport path from 'path';\n\ninterface Report {\n    id: number;\n    name: string;\n    data: any[];\n}\n\nclass ReportGenerator {\n    private reports: Report[] = [];\n\n    public addReport(report: Report) {\n        this.reports.push(report);\n    }\n\n    public async saveReports(directory: string): Promise<void> {\n        if (!fs.existsSync(directory)) {\n            fs.mkdirSync(directory);\n        }\n        for (const report of this.reports) {\n            const filePath = path.join(directory, `${report.name}.json`);\n            await this.saveReport(filePath, report.data);\n        }\n    }\n\n    private async saveReport(filePath: string, data: any[]): Promise<void> {\n        return new Promise((resolve, reject) => {\n            fs.writeFile(filePath, JSON.stringify(data, null, 2), (err) => {\n                if (err) {\n                    reject(err);\n                } else {\n                    resolve();\n                }\n            });\n        });\n    }\n}\n\n// Example usage\n(async () => {\n    const reportGenerator = new ReportGenerator();\n    reportGenerator.addReport({ id: 1, name: 'report1', data: [{ key: 'value1' }] });\n    reportGenerator.addReport({ id: 2, name: 'report2', data: [{ key: 'value2' }] });\n", "suffix": "})();\nconsole.log('Reports saved successfully.');\n", "golden_completion": "    await reportGenerator.saveReports('./reports');\n", "LLM_justification": "This example tests the LLM's ability to understand and continue a TypeScript code block that involves asynchronous file operations and object-oriented programming patterns. The given context sets up a scenario where a ReportGenerator class is used to add and save reports to a directory. The completion requires understanding the purpose of saving reports and correctly using the async/await pattern to ensure proper execution. It also involves handling file system operations, which is crucial in tool automation contexts like builds, tests, and deployment.", "assertions": "import assert from 'assert';\nimport fs from 'fs';\n\n(async () => {\n    const reportGenerator = new ReportGenerator();\n    reportGenerator.addReport({ id: 1, name: 'report1', data: [{ key: 'value1' }] });\n    reportGenerator.addReport({ id: 2, name: 'report2', data: [{ key: 'value2' }] });\n    await reportGenerator.saveReports('./reports');\n    assert(fs.existsSync('./reports/report1.json'), 'Report1 should be saved');\n    assert(fs.existsSync('./reports/report2.json'), 'Report2 should be saved');\n    const report1Content = JSON.parse(fs.readFileSync('./reports/report1.json', 'utf-8'));\n    const report2Content = JSON.parse(fs.readFileSync('./reports/report2.json', 'utf-8'));\n    assert.deepStrictEqual(report1Content, [{ key: 'value1' }], 'Report1 content should match');\n    assert.deepStrictEqual(report2Content, [{ key: 'value2' }], 'Report2 content should match');\n    console.log('All assertions passed.');\n})();\n", "o3-mini": "    await reportGenerator.saveReports('./reports');"}
{"id": "27", "testsource": "devbench-code-purpose-understanding", "language": "typescript", "prefix": "import axios from 'axios';\n\ninterface Report {\n    id: number;\n    name: string;\n    data: any;\n}\n\ninterface AnalyticsService {\n    fetchReport(reportId: number): Promise<Report>;\n    processReport(report: Report): void;\n    saveProcessedReport(report: Report): Promise<void>;\n}\n\nclass AnalyticsServiceImpl implements AnalyticsService {\n    async fetchReport(reportId: number): Promise<Report> {\n        try {\n            const response = await axios.get<Report>(`/api/reports/${reportId}`);\n            return response.data;\n        } catch (error) {\n            throw new Error('Failed to fetch report');\n        }\n    }\n\n    processReport(report: Report): void {\n        // Simulate report processing\n        report.data = { processed: true, originalData: report.data };\n    }\n\n    async saveProcessedReport(report: Report): Promise<void> {\n        try {\n            await axios.post('/api/reports', report);\n        } catch (error) {\n            throw new Error('Failed to save processed report');\n        }\n    }\n}\n\nasync function generateAndSaveReport(analyticsService: AnalyticsService, reportId: number) {\n    try {\n        const report = await analyticsService.fetchReport(reportId);\n        analyticsService.processReport(report);\n", "suffix": "        console.log('Report processed and saved successfully');\n    } catch (error) {\n        console.error('Error during report generation and saving:', error);\n    }\n}\n\n// Example usage\n(async () => {\n    const analyticsService = new AnalyticsServiceImpl();\n    await generateAndSaveReport(analyticsService, 1);\n})();\n", "golden_completion": "        await analyticsService.saveProcessedReport(report);\n", "LLM_justification": "This example tests the LLM's understanding of promises and async-await patterns within the context of an analytics service. The task involves fetching a report, processing it, and then saving the processed report. The golden completion demonstrates the correct use of async-await to ensure the save operation completes successfully. The assertions check that the report is processed and saved as expected, verifying both functional correctness and adherence to business rules.", "assertions": "const mockReport = { id: 1, name: 'Test Report', data: {} };\nconst mockAxiosGet = jest.spyOn(axios, 'get').mockResolvedValue({ data: mockReport });\nconst mockAxiosPost = jest.spyOn(axios, 'post').mockResolvedValue({});\nconst analyticsService = new AnalyticsServiceImpl();\n\n(async () => {\n    await generateAndSaveReport(analyticsService, 1);\n\n    expect(mockAxiosGet).toHaveBeenCalledWith('/api/reports/1');\n    expect(mockAxiosPost).toHaveBeenCalledWith('/api/reports', { id: 1, name: 'Test Report', data: { processed: true, originalData: {} } });\n})();\n\nmockAxiosGet.mockRestore();\nmockAxiosPost.mockRestore();", "o3-mini": "        await analyticsService.saveProcessedReport(report);"}
{"id": "28", "testsource": "devbench-code-purpose-understanding", "language": "typescript", "prefix": "import { readFile } from 'fs/promises';\nimport { join } from 'path';\n\ninterface Metric {\n    timestamp: number;\n    value: number;\n}\n\nclass MetricsReporter {\n    private metrics: Metric[] = [];\n\n    constructor(private filePath: string) {}\n\n    async loadMetrics(): Promise<void> {\n        try {\n            const data = await readFile(this.filePath, 'utf-8');\n            this.metrics = JSON.parse(data);\n        } catch (error) {\n            console.error('Failed to load metrics:', error);\n        }\n    }\n\n    addMetric(value: number): void {\n        const metric: Metric = {\n            timestamp: Date.now(),\n            value\n        };\n        this.metrics.push(metric);\n    }\n\n    getMetrics(startTime: number, endTime: number): Metric[] {\n        return this.metrics.filter(metric => metric.timestamp >= startTime && metric.timestamp <= endTime);\n    }\n}\n\nasync function main() {\n    const reporter = new MetricsReporter(join(__dirname, 'metrics.json'));\n    await reporter.loadMetrics();\n    reporter.addMetric(42);\n", "suffix": "\n    const metrics = reporter.getMetrics(Date.now() - 1000 * 60 * 60, Date.now());\n    console.log(metrics);\n}\n\nmain().catch(console.error);\n", "golden_completion": "\n    await reporter.loadMetrics();\n", "LLM_justification": "This test case evaluates the LLM's ability to understand the context of loading metrics from a file, adding a new metric, and retrieving metrics within a specified time range. The prefix sets up a MetricsReporter class with methods to load metrics from a JSON file, add a new metric, and filter metrics by timestamp. The golden completion involves reloading the metrics after adding a new one, which ensures the updated metrics list is accurate when retrieved. This scenario tests comprehension of async/await patterns, error handling, and the business logic of metric reporting.", "assertions": "import { strict as assert } from 'assert';\n\n(async () => {\n    const testFilePath = join(__dirname, 'test_metrics.json');\n    const testData = JSON.stringify([{ timestamp: Date.now() - 1000 * 60, value: 10 }]);\n\n    await writeFile(testFilePath, testData);\n\n    const reporter = new MetricsReporter(testFilePath);\n    await reporter.loadMetrics();\n    reporter.addMetric(42);\n    await reporter.loadMetrics();\n\n    const metrics = reporter.getMetrics(Date.now() - 1000 * 60 * 60, Date.now());\n    assert(metrics.length === 2, 'Metrics count should be 2');\n    assert(metrics[1].value === 42, 'The second metric value should be 42');\n\n    await unlink(testFilePath);\n})();", "o3-mini": "const { writeFile } = await import('fs/promises');\nawait writeFile(reporter['filePath'], JSON.stringify(reporter['metrics']));"}
{"id": "29", "testsource": "devbench-code-purpose-understanding", "language": "typescript", "prefix": "import * as crypto from 'crypto';\n\ninterface User {\n\tid: string;\n\tusername: string;\n\tpasswordHash: string;\n}\n\nclass UserService {\n\tprivate users: Map<string, User> = new Map();\n\n\tconstructor() {}\n\n\tprivate hashPassword(password: string): string {\n\t\treturn crypto.createHash('sha256').update(password).digest('hex');\n\t}\n\n\tpublic addUser(username: string, password: string): User {\n\t\tconst id = crypto.randomUUID();\n\t\tconst passwordHash = this.hashPassword(password);\n\t\tconst newUser: User = { id, username, passwordHash };\n\t\tthis.users.set(id, newUser);\n\t\treturn newUser;\n\t}\n\n\tpublic authenticate(username: string, password: string): boolean {\n\t\tfor (const user of this.users.values()) {\n\t\t\tif (user.username === username && user.passwordHash === this.hashPassword(password)) {\n\t\t\t\treturn true;\n\t\t\t}\n\t\t}\n\t\treturn false;\n\t}\n}\n\n// Example usage\nconst userService = new UserService();\nconst user = userService.addUser('testUser', 'securePassword');\nconsole.log('User created:', user);\n", "suffix": "console.log('Authentication status:', isAuthenticated);\n\n// Clean up resources\nuserService['users'].clear();\n", "golden_completion": "const isAuthenticated = userService.authenticate('testUser', 'securePassword');\n", "LLM_justification": "This example tests the LLM's ability to understand authentication logic within a security context. The prefix sets up user creation and password hashing, while the golden completion requires correctly authenticating a user. The suffix tests incorrect authentication, ensuring the LLM comprehends the business logic of user authentication.", "assertions": "import * as assert from 'assert';\n\nconst isAuthenticated = userService.authenticate('testUser', 'securePassword');\nassert.strictEqual(isAuthenticated, true, 'User should be authenticated with correct password');\nconst isAuthenticatedWrongPassword = userService.authenticate('testUser', 'wrongPassword');\nassert.strictEqual(isAuthenticatedWrongPassword, false, 'User should not be authenticated with wrong password');\n\n// Clean up resources\nuserService['users'].clear();\n", "o3-mini": "const isAuthenticated = userService.authenticate('testUser', 'securePassword');"}
{"id": "30", "testsource": "devbench-code-purpose-understanding", "language": "typescript", "prefix": "import * as crypto from 'crypto';\n\n// A class to handle encryption and decryption of sensitive data\nclass SecurityManager {\n    private algorithm: string;\n    private key: string;\n    private iv: Buffer;\n\n    constructor() {\n        this.algorithm = 'aes-256-cbc';\n        this.key = crypto.randomBytes(32).toString('hex');\n        this.iv = crypto.randomBytes(16);\n    }\n\n    // Encrypts a given plaintext using the AES-256-CBC algorithm\n    encrypt(text: string): string {\n        const cipher = crypto.createCipheriv(this.algorithm, Buffer.from(this.key, 'hex'), this.iv);\n        let encrypted = cipher.update(text);\n        encrypted = Buffer.concat([encrypted, cipher.final()]);\n        return `${this.iv.toString('hex')}:${encrypted.toString('hex')}`;\n    }\n\n    // Decrypts a given ciphertext using the AES-256-CBC algorithm\n    decrypt(text: string): string {\n        const [iv, encryptedText] = text.split(':');\n        const decipher = crypto.createDecipheriv(this.algorithm, Buffer.from(this.key, 'hex'), Buffer.from(iv, 'hex'));\n        let decrypted = decipher.update(Buffer.from(encryptedText, 'hex'));\n        decrypted = Buffer.concat([decrypted, decipher.final()]);\n        return decrypted.toString();\n    }\n}\n\n// A function to simulate sensitive data processing\nfunction processSensitiveData(data: string, securityManager: SecurityManager): string {\n    // Encrypt the data\n    const encryptedData = securityManager.encrypt(data);\n    // Simulate some processing (e.g., storing or transmitting the data)\n    // ...\n    return encryptedData;\n}\n\nconst securityManager = new SecurityManager();\nconst sensitiveData = 'Secret Information';\nconst encryptedData = processSensitiveData(sensitiveData, securityManager);\n", "suffix": "\n", "golden_completion": "const decryptedData = securityManager.decrypt(encryptedData);\nif (decryptedData === sensitiveData) {\n    console.log('Decryption successful:', decryptedData);\n} else {\n    console.log('Decryption failed');\n}", "LLM_justification": "This test case is designed to evaluate the LLM's understanding of encryption and decryption processes within a security context. It requires the model to correctly use the provided SecurityManager class to decrypt data that was previously encrypted, and then compare the result with the original data to ensure the decryption process is accurate. The assertions verify that the decrypted data matches the original sensitive data, ensuring the integrity of the encryption-decryption cycle.", "assertions": "const decryptedData = securityManager.decrypt(encryptedData);\nconsole.assert(decryptedData === sensitiveData, 'Decryption did not return the original data');\n", "o3-mini": "const decryptedData = securityManager.decrypt(encryptedData);\nconsole.log(\"Encrypted Data:\", encryptedData);\nconsole.log(\"Decrypted Data:\", decryptedData);"}
{"id": "31", "testsource": "devbench-code-purpose-understanding", "language": "typescript", "prefix": "import { EventEmitter } from 'events';\n\ninterface BuildEvent {\n    timestamp: Date;\n    message: string;\n}\n\nclass BuildAutomation extends EventEmitter {\n    private buildSteps: string[];\n    private buildLogs: BuildEvent[];\n\n    constructor() {\n        super();\n        this.buildSteps = [];\n        this.buildLogs = [];\n    }\n\n    addStep(step: string) {\n        this.buildSteps.push(step);\n    }\n\n    startBuild() {\n        this.emit('buildStarted', { timestamp: new Date(), message: 'Build started.' });\n        for (const step of this.buildSteps) {\n            try {\n                this.emit('stepStarted', { timestamp: new Date(), message: `Step started: ${step}` });\n                // Simulate step execution\n                console.log(`Executing step: ${step}`);\n                this.emit('stepCompleted', { timestamp: new Date(), message: `Step completed: ${step}` });\n            } catch (error) {\n                this.emit('stepFailed', { timestamp: new Date(), message: `Step failed: ${step}` });\n            }\n        }\n        this.emit('buildCompleted', { timestamp: new Date(), message: 'Build completed.' });\n    }\n\n    onBuildStarted(listener: (event: BuildEvent) => void) {\n        this.on('buildStarted', listener);\n    }\n\n    onStepStarted(listener: (event: BuildEvent) => void) {\n        this.on('stepStarted', listener);\n    }\n\n    onStepCompleted(listener: (event: BuildEvent) => void) {\n        this.on('stepCompleted', listener);\n    }\n\n    onStepFailed(listener: (event: BuildEvent) => void) {\n        this.on('stepFailed', listener);\n    }\n\n    onBuildCompleted(listener: (event: BuildEvent) => void) {\n        this.on('buildCompleted', listener);\n    }\n\n    getBuildLogs(): BuildEvent[] {\n        return this.buildLogs;\n    }\n}\n\nconst buildAutomation = new BuildAutomation();\n\nbuildAutomation.onBuildStarted((event) => {\n    buildAutomation.getBuildLogs().push(event);\n    console.log(event.message);\n});\n\nbuildAutomation.onStepStarted((event) => {\n    buildAutomation.getBuildLogs().push(event);\n    console.log(event.message);\n});\n\nbuildAutomation.onStepCompleted((event) => {\n    buildAutomation.getBuildLogs().push(event);\n    console.log(event.message);\n});\n\nbuildAutomation.onStepFailed((event) => {\n    buildAutomation.getBuildLogs().push(event);\n    console.log(event.message);\n});\n\nbuildAutomation.onBuildCompleted((event) => {\n    buildAutomation.getBuildLogs().push(event);\n    console.log(event.message);\n});\n\nbuildAutomation.addStep('Compile');\nbuildAutomation.addStep('Test');\nbuildAutomation.addStep('Package');\n", "suffix": "\nconsole.log(`Total log entries: ${logs.length}`);\nconsole.log(logs);\n\n// Cleanup resources\nbuildAutomation.removeAllListeners();\n", "golden_completion": "buildAutomation.startBuild();\n\nconst logs = buildAutomation.getBuildLogs();\n", "LLM_justification": "This scenario tests the LLM's ability to understand and continue an event-driven build automation system. The context involves adding and executing build steps while emitting and handling events to log the process. The golden completion focuses on starting the build process and verifying the logs, demonstrating understanding of event handling and maintaining business logic consistency. The suffix includes cleanup code to ensure proper resource management, which is critical in real-world applications.", "assertions": "import assert from 'assert';\n\nconst buildAutomation = new BuildAutomation();\n\nbuildAutomation.onBuildStarted((event) => {\n    buildAutomation.getBuildLogs().push(event);\n    console.log(event.message);\n});\n\nbuildAutomation.onStepStarted((event) => {\n    buildAutomation.getBuildLogs().push(event);\n    console.log(event.message);\n});\n\nbuildAutomation.onStepCompleted((event) => {\n    buildAutomation.getBuildLogs().push(event);\n    console.log(event.message);\n});\n\nbuildAutomation.onStepFailed((event) => {\n    buildAutomation.getBuildLogs().push(event);\n    console.log(event.message);\n});\n\nbuildAutomation.onBuildCompleted((event) => {\n    buildAutomation.getBuildLogs().push(event);\n    console.log(event.message);\n});\n\nbuildAutomation.addStep('Compile');\nbuildAutomation.addStep('Test');\nbuildAutomation.addStep('Package');\n\nbuildAutomation.startBuild();\n\nconst logs = buildAutomation.getBuildLogs();\nassert.strictEqual(logs.length, 5, 'There should be 5 log entries in total.');\nassert.strictEqual(logs[0].message, 'Build started.', 'First log entry should indicate build started.');\nassert.strictEqual(logs[1].message, 'Step started: Compile', 'Second log entry should indicate first step started.');\nassert.strictEqual(logs[2].message, 'Step completed: Compile', 'Third log entry should indicate first step completed.');\nassert.strictEqual(logs[3].message, 'Step started: Test', 'Fourth log entry should indicate second step started.');\nassert.strictEqual(logs[4].message, 'Step completed: Test', 'Fifth log entry should indicate second step completed.');\n\n// Cleanup resources\nbuildAutomation.removeAllListeners();\n", "o3-mini": "buildAutomation.startBuild()\nlogs = buildAutomation.getBuildLogs()"}
{"id": "32", "testsource": "devbench-code-purpose-understanding", "language": "typescript", "prefix": "import * as crypto from 'crypto';\n\ninterface User {\n\tusername: string;\n\tpasswordHash: string;\n}\n\nclass UserAuth {\n\tprivate users: User[];\n\n\tconstructor() {\n\t\tthis.users = [];\n\t}\n\n\tprivate hashPassword(password: string): string {\n\t\treturn crypto.createHash('sha256').update(password).digest('hex');\n\t}\n\n\tpublic register(username: string, password: string): void {\n\t\tconst passwordHash = this.hashPassword(password);\n\t\tthis.users.push({ username, passwordHash });\n\t}\n\n\tpublic authenticate(username: string, password: string): boolean {\n\t\tconst passwordHash = this.hashPassword(password);\n\t\tconst user = this.users.find(user => user.username === username);\n\t\tif (user && user.passwordHash === passwordHash) {\n\t\t\treturn true;\n\t\t}\n\t\treturn false;\n\t}\n\n\tpublic changePassword(username: string, oldPassword: string, newPassword: string): boolean {\n\t\tif (this.authenticate(username, oldPassword)) {\n\t\t\tconst user = this.users.find(user => user.username === username);\n\t\t\tif (user) {\n\t\t\t\tuser.passwordHash = this.hashPassword(newPassword);\n\t\t\t\treturn true;\n\t\t\t}\n\t\t}\n\t\treturn false;\n\t}\n}\n\nconst auth = new UserAuth();\n\nauth.register('testUser', 'initialPassword');\n\n// Successfully authenticate with the initial password\nconst isAuthenticatedInitially = auth.authenticate('testUser', 'initialPassword');\nconsole.assert(isAuthenticatedInitially, 'User should be authenticated with the initial password');\n\n// Change the password\nconst isPasswordChanged = auth.changePassword('testUser', 'initialPassword', 'newPassword');\nconsole.assert(isPasswordChanged, 'Password should be changed successfully');\n\n// Ensure old password no longer works\nconst isAuthenticatedWithOldPassword = auth.authenticate('testUser', 'initialPassword');\nconsole.assert(!isAuthenticatedWithOldPassword, 'User should not be authenticated with the old password');\n", "suffix": "// Some other logic that follows after password change\nconst authResult = auth.authenticate('testUser', 'newPassword');\nconsole.assert(authResult, 'User should be authenticated with the new password');\n\n// Clean up resources if any\n// In this case, there are no resources to clean up, but in a real-world scenario, this is where you would do it.\n", "golden_completion": "// Authenticate with the new password\nconst isAuthenticatedWithNewPassword = auth.authenticate('testUser', 'newPassword');\nconsole.assert(isAuthenticatedWithNewPassword, 'User should be authenticated with the new password');\n", "LLM_justification": "This example is a good test case because it demonstrates a clear business logic scenario involving user authentication and password management, which is critical in security contexts. The provided prefix sets up a comprehensive context with user registration, authentication, and password change functionality. The golden completion is focused on verifying that the authentication works with the new password after a password change, ensuring business rule compliance. The suffix contains different logic to verify the new password functionality, ensuring clear distinction between the completion and suffix. Assertions are used to validate the correctness of the implementation, testing both positive and negative scenarios for authentication.", "assertions": "console.assert(isAuthenticatedWithNewPassword, 'User should be authenticated with the new password');", "o3-mini": "console.log('Password changed successfully.');"}
{"id": "33", "testsource": "devbench-code-purpose-understanding", "language": "typescript", "prefix": "import { readFileSync, writeFileSync } from 'fs';\nimport { promisify } from 'util';\n\n// A utility function to read a file asynchronously\nconst readFileAsync = promisify(readFileSync);\n\n// Define a type for the configuration settings\ninterface Config {\n    key: string;\n    value: string;\n}\n\n// A class representing a configuration manager for a tool automation scenario\nclass ConfigManager {\n    private configFilePath: string;\n    private config: Config[] = [];\n\n    constructor(configFilePath: string) {\n        this.configFilePath = configFilePath;\n    }\n\n    // Method to load configuration from the file\n    async loadConfig(): Promise<void> {\n        try {\n            const data = await readFileAsync(this.configFilePath, 'utf-8');\n            this.config = JSON.parse(data);\n        } catch (error) {\n            console.error('Failed to load config:', error);\n            throw new Error('Failed to load config');\n        }\n    }\n\n    // Method to get a config value by key\n    getConfigValue(key: string): string | undefined {\n        const configItem = this.config.find(item => item.key === key);\n        return configItem ? configItem.value : undefined;\n    }\n\n    // Method to set a config value by key\n    setConfigValue(key: string, value: string): void {\n        const configItem = this.config.find(item => item.key === key);\n        if (configItem) {\n            configItem.value = value;\n        } else {\n            this.config.push({ key, value });\n        }\n    }\n\n    // Method to save the current configuration to the file\n    async saveConfig(): Promise<void> {\n        try {\n            const data = JSON.stringify(this.config, null, 2);\n            await writeFileSync(this.configFilePath, data, 'utf-8');\n        } catch (error) {\n            console.error('Failed to save config:', error);\n            throw new Error('Failed to save config');\n        }\n    }\n}\n\n// The main function to demonstrate the ConfigManager usage\nasync function main() {\n    const configManager = new ConfigManager('config.json');\n\n    // Load the configuration\n    await configManager.loadConfig();\n\n    // Retrieve a specific config value\n    const apiKey = configManager.getConfigValue('apiKey');\n    console.log('API Key:', apiKey);\n\n    // Set a new config value\n    configManager.setConfigValue('newKey', 'newValue');\n\n    // Save the updated configuration\n    await configManager.saveConfig();\n}\n\nmain().catch(error => console.error(error));\n", "suffix": "\n\n// Test that config value is properly set\nconst testConfigManager = new ConfigManager('test_config.json');\ntestConfigManager.setConfigValue('testKey', 'testValue');\nconst testValue = testConfigManager.getConfigValue('testKey');\nconsole.assert(testValue === 'testValue', 'Expected testValue to be set correctly');\n\n// Test error handling for loading config\ntry {\n    await testConfigManager.loadConfig();\n} catch (error) {\n    console.assert(error.message === 'Failed to load config', 'Expected error message to be \"Failed to load config\"');\n}\n\n// Clean up\nwriteFileSync('test_config.json', '{}');\n", "golden_completion": "await testConfigManager.saveConfig();\n", "LLM_justification": "This example tests the LLM's ability to understand the purpose of a configuration manager in a tool automation context, where it involves reading, modifying, and saving configuration settings. The LLM needs to comprehend asynchronous file operations, error handling, and ensuring the consistency of the configuration state. The assertions check the correct setting and retrieval of configuration values and proper error handling during the load operation. This scenario combines async/await patterns with a practical tool automation context, providing a robust test for code purpose comprehension.", "assertions": "const configManager = new ConfigManager('test_config.json');\nconfigManager.setConfigValue('testKey', 'testValue');\nconst value = configManager.getConfigValue('testKey');\nconsole.assert(value === 'testValue', 'Expected testValue to be set correctly');\n\ntry {\n    await configManager.loadConfig();\n} catch (error) {\n    console.assert(error.message === 'Failed to load config', 'Expected error message to be \"Failed to load config\"');\n}\n\n// Clean up\nwriteFileSync('test_config.json', '{}');", "o3-mini": "try {\n    require('fs').unlinkSync('test_config.json');\n} catch (err) {}"}
{"id": "34", "testsource": "devbench-code-purpose-understanding", "language": "typescript", "prefix": "import fs from 'fs';\nimport path from 'path';\n\ninterface DeploymentConfig {\n    environment: string;\n    version: string;\n    services: string[];\n}\n\nfunction readConfig(filePath: string): DeploymentConfig {\n    const configContent = fs.readFileSync(filePath, 'utf-8');\n    return JSON.parse(configContent) as DeploymentConfig;\n}\n\nclass DeploymentManager {\n    private config: DeploymentConfig;\n\n    constructor(configFilePath: string) {\n        this.config = readConfig(configFilePath);\n    }\n\n    public async deploy(): Promise<void> {\n        console.log(`Deploying version ${this.config.version} to ${this.config.environment} environment.`);\n        for (const service of this.config.services) {\n            await this.deployService(service);\n        }\n    }\n\n    private async deployService(service: string): Promise<void> {\n        console.log(`Deploying service: ${service}`);\n        // Simulate an asynchronous deployment task\n        await new Promise(resolve => setTimeout(resolve, 1000));\n    }\n}\n\n// Helper function to create a temporary deployment config file\nfunction createTempConfig(): string {\n    const tempFilePath = path.join(__dirname, 'temp_config.json');\n    const config: DeploymentConfig = {\n        environment: 'staging',\n        version: '1.0.0',\n        services: ['auth', 'api', 'frontend']\n    };\n    fs.writeFileSync(tempFilePath, JSON.stringify(config, null, 2));\n    return tempFilePath;\n}\n\nconst tempConfigPath = createTempConfig();\nconst deploymentManager = new DeploymentManager(tempConfigPath);\n\n(async () => {\n", "suffix": "    console.log('Deployment process finished.');\n})();\n\n// Clean up temporary config file\nfs.unlinkSync(tempConfigPath);\n\n", "golden_completion": "    await deploymentManager.deploy();\n", "LLM_justification": "This scenario tests the LLM's ability to understand the purpose of a deployment process in a tool automation context. The code involves reading a configuration file, initializing a deployment manager, and performing asynchronous deployment tasks using Promises and async-await. The golden completion requires inserting a call to the deploy method, which is critical for the deployment process to function correctly. The assertions will verify that the deployment steps are executed as expected and that the configuration file is cleaned up afterward.", "assertions": "import assert from 'assert';\n\n(async () => {\n    const consoleOutput: string[] = [];\n    const originalConsoleLog = console.log;\n    console.log = (message: string) => consoleOutput.push(message);\n\n    await deploymentManager.deploy();\n\n    console.log = originalConsoleLog;\n\n    assert(consoleOutput.includes('Deploying version 1.0.0 to staging environment.'), 'Deployment version and environment log missing.');\n    assert(consoleOutput.includes('Deploying service: auth'), 'Auth service deployment log missing.');\n    assert(consoleOutput.includes('Deploying service: api'), 'API service deployment log missing.');\n    assert(consoleOutput.includes('Deploying service: frontend'), 'Frontend service deployment log missing.');\n\n    // Clean up temporary config file\n    fs.unlinkSync(tempConfigPath);\n})();\n", "o3-mini": "    await deploymentManager.deploy();"}
{"id": "35", "testsource": "devbench-code-purpose-understanding", "language": "typescript", "prefix": "import * as fs from 'fs';\nimport * as path from 'path';\n\ninterface BuildStep {\n    execute(): Promise<void>;\n}\n\nclass CleanStep implements BuildStep {\n    private targetDir: string;\n    constructor(targetDir: string) {\n        this.targetDir = targetDir;\n    }\n    async execute(): Promise<void> {\n        return new Promise((resolve, reject) => {\n            fs.rmdir(this.targetDir, { recursive: true }, (err) => {\n                if (err) reject(err);\n                else resolve();\n            });\n        });\n    }\n}\n\nclass CompileStep implements BuildStep {\n    private sourceDir: string;\n    private outDir: string;\n    constructor(sourceDir: string, outDir: string) {\n        this.sourceDir = sourceDir;\n        this.outDir = outDir;\n    }\n    async execute(): Promise<void> {\n        // Simulate a compilation step\n        return new Promise((resolve) => {\n            setTimeout(() => {\n                console.log(`Compiled sources from ${this.sourceDir} to ${this.outDir}`);\n                resolve();\n            }, 1000);\n        });\n    }\n}\n\nclass BuildProcess {\n    private steps: BuildStep[] = [];\n\n    addStep(step: BuildStep): void {\n        this.steps.push(step);\n    }\n\n    async run(): Promise<void> {\n        for (const step of this.steps) {\n            try {\n                await step.execute();\n            } catch (error) {\n                console.error('Build step failed:', error);\n            }\n        }\n    }\n}\n\n// Example usage\nconst build = new BuildProcess();\nbuild.addStep(new CleanStep(path.join(__dirname, 'dist')));\nbuild.addStep(new CompileStep(path.join(__dirname, 'src'), path.join(__dirname, 'dist')));\n\n// This part is missing the deployment step\n", "suffix": "build.run().then(() => {\n    console.log('Build process completed successfully');\n}).catch((error) => {\n    console.error('Build process encountered an error:', error);\n});\n", "golden_completion": "class DeployStep implements BuildStep {\n    private targetDir: string;\n    constructor(targetDir: string) {\n        this.targetDir = targetDir;\n    }\n    async execute(): Promise<void> {\n        return new Promise((resolve, reject) => {\n            setTimeout(() => {\n                console.log(`Deployed to ${this.targetDir}`);\n                resolve();\n            }, 500);\n        });\n    }\n}\n\nbuild.addStep(new DeployStep(path.join(__dirname, 'dist')));\n", "LLM_justification": "This example is a good test case because it involves a realistic scenario in tool automation (builds, tests, deployment) using OOP patterns. The prefix sets up a build process with different steps (cleaning, compiling) and demonstrates how these steps are added and executed sequentially. The golden completion involves adding a deployment step, which is crucial for understanding the business logic of the build process. The suffix then runs the build process and logs the outcome. This tests the LLM's understanding of the build process and the importance of each step.", "assertions": "import * as assert from 'assert';\n\n(async () => {\n    const logs: string[] = [];\n    const originalLog = console.log;\n    console.log = (message: string) => { logs.push(message); };\n    try {\n        await build.run();\n        assert.strictEqual(logs[0], 'Compiled sources from src to dist');\n        assert.strictEqual(logs[1], 'Deployed to dist');\n        assert.strictEqual(logs[2], 'Build process completed successfully');\n    } catch (error) {\n        assert.fail('Build process should not fail');\n    } finally {\n        console.log = originalLog;\n    }\n})();\n", "o3-mini": "class DeployStep implements BuildStep {\n    async execute(): Promise<void> {\n        return new Promise((resolve) => {\n            setTimeout(() => {\n                console.log('Deployed build artifacts');\n                resolve();\n            }, 500);\n        });\n    }\n}\nbuild.addStep(new DeployStep());"}
{"id": "36", "testsource": "devbench-code-purpose-understanding", "language": "typescript", "prefix": "import * as crypto from 'crypto';\n\n// Type Definitions\ninterface AuditLog {\n\tid: string;\n\tuser: string;\n\taction: string;\n\ttimestamp: Date;\n}\n\n// Utility Function to Generate Unique IDs\nfunction generateUniqueId(): string {\n\treturn crypto.randomBytes(16).toString('hex');\n}\n\n// Class to Handle Audit Logging\nclass AuditService {\n\tprivate logs: AuditLog[] = [];\n\n\t// Method to Log an Action\n\tlogAction(user: string, action: string): void {\n\t\tconst log: AuditLog = {\n\t\t\tid: generateUniqueId(),\n\t\t\tuser,\n\t\t\taction,\n\t\t\ttimestamp: new Date()\n\t\t};\n\t\tthis.logs.push(log);\n\t}\n\n\t// Method to Retrieve Logs\n\tgetLogs(): AuditLog[] {\n\t\treturn this.logs;\n\t}\n}\n\n// AuditService Instance\nconst auditService = new AuditService();\n\n// Sample Actions to Log\nconst actions = [\n\t{ user: 'alice', action: 'login' },\n\t{ user: 'bob', action: 'logout' },\n\t{ user: 'charlie', action: 'view' }\n];\n\n// Logging Actions\nfor (const action of actions) {\n\tauditService.logAction(action.user, action.action);\n}\n\n// Function to Retrieve and Display Logs\nfunction displayLogs(service: AuditService): void {\n\tconst logs = service.getLogs();\n\tfor (const log of logs) {\n\t\tconsole.log(`User: ${log.user}, Action: ${log.action}, Timestamp: ${log.timestamp}`);\n\t}\n}\n\n// Displaying the Logs\n", "suffix": "\n\n// Assertions to Verify Correctness\nconst logs = auditService.getLogs();\nconsole.assert(logs.length === 3, 'There should be exactly 3 logs');\nconsole.assert(logs[0].user === 'alice', 'First log should be for user alice');\nconsole.assert(logs[1].user === 'bob', 'Second log should be for user bob');\nconsole.assert(logs[2].user === 'charlie', 'Third log should be for user charlie');\n\n// Cleanup (if needed)\n// No external resources to clean up in this example\n", "golden_completion": "displayLogs(auditService);\n\n", "LLM_justification": "This test case is designed to evaluate the LLM's ability to understand TypeScript code within the context of security auditing. The example involves logging user actions and retrieving these logs, which is a common practice in security-related applications. The golden completion requires the LLM to correctly integrate the displayLogs function call and validate the audit logs through assertions. This tests the model's understanding of both the business logic (audit logging) and the technical pattern (error handling and assertions).", "assertions": "const logs = auditService.getLogs();\nconsole.assert(logs.length === 3, 'There should be exactly 3 logs');\nconsole.assert(logs[0].user === 'alice', 'First log should be for user alice');\nconsole.assert(logs[1].user === 'bob', 'Second log should be for user bob');\nconsole.assert(logs[2].user === 'charlie', 'Third log should be for user charlie');\n", "o3-mini": "displayLogs(auditService);"}
{"id": "37", "testsource": "devbench-code-purpose-understanding", "language": "typescript", "prefix": "import { assert } from 'chai';\n\ninterface Metric {\n    timestamp: Date;\n    value: number;\n}\n\nclass MetricsReporter {\n    private metrics: Metric[] = [];\n\n    addMetric(value: number): void {\n        this.metrics.push({ timestamp: new Date(), value });\n    }\n\n    generateReport(): string {\n        return this.metrics.map(metric => `Time: ${metric.timestamp}, Value: ${metric.value}`).join('\\n');\n    }\n\n    async logMetricsToServer(): Promise<void> {\n        try {\n            const response = await fetch('https://example.com/metrics', {\n                method: 'POST',\n                headers: { 'Content-Type': 'application/json' },\n                body: JSON.stringify(this.metrics)\n            });\n            if (!response.ok) {\n                throw new Error('Failed to log metrics');\n            }\n        } catch (error) {\n            console.error('Error logging metrics:', error);\n        }\n    }\n}\n\nconst reporter = new MetricsReporter();\nreporter.addMetric(100);\nreporter.addMetric(200);\n", "suffix": "reporter.addMetric(300);\nconst report = reporter.generateReport();\nconsole.log(report);\n\nassert.include(report, 'Value: 100');\nassert.include(report, 'Value: 200');\nassert.include(report, 'Value: 300');\n\n// Clean up resources if needed\n", "golden_completion": "await reporter.logMetricsToServer();\n", "LLM_justification": "This test case is a good example of using async-await for handling asynchronous operations in the context of an analytics domain. The prefix sets up a MetricsReporter class that collects metrics and provides methods for reporting and logging them to a server. The golden completion involves the logMetricsToServer method, which is crucial for ensuring that the metrics are sent to the server correctly. This tests the LLM's understanding of how to properly handle asynchronous operations and the importance of logging metrics in an analytics context. The assertions verify that the metrics are correctly reported, ensuring the business logic is maintained.", "assertions": "assert.isDefined(reporter);\nassert.isFunction(reporter.addMetric);\nassert.isFunction(reporter.generateReport);\nassert.isFunction(reporter.logMetricsToServer);\nassert.include(reporter.generateReport(), 'Value: 100');\nassert.include(reporter.generateReport(), 'Value: 200');\nawait reporter.logMetricsToServer();\nassert.include(reporter.generateReport(), 'Value: 100');\nassert.include(reporter.generateReport(), 'Value: 200');\nassert.include(reporter.generateReport(), 'Value: 300');\n", "o3-mini": "reporter.addMetric(300);"}
{"id": "38", "testsource": "devbench-code-purpose-understanding", "language": "typescript", "prefix": "import * as crypto from 'crypto';\n\ninterface User {\n  id: number;\n  username: string;\n  passwordHash: string;\n}\n\ninterface AuditLog {\n  timestamp: Date;\n  userId: number;\n  action: string;\n  status: string;\n}\n\nconst users: User[] = [\n  { id: 1, username: 'alice', passwordHash: '5f4dcc3b5aa765d61d8327deb882cf99' },\n  { id: 2, username: 'bob', passwordHash: 'b2e98ad6f6eb8508dd6a14cfa704bad7' }\n];\n\nconst auditLogs: AuditLog[] = [];\n\nfunction hashPassword(password: string): string {\n  return crypto.createHash('md5').update(password).digest('hex');\n}\n\nfunction authenticate(username: string, password: string): boolean {\n  const user = users.find(u => u.username === username);\n  if (!user) return false;\n  return user.passwordHash === hashPassword(password);\n}\n\nfunction logAudit(userId: number, action: string, status: string): void {\n  auditLogs.push({ timestamp: new Date(), userId, action, status });\n}\n\nfunction login(username: string, password: string): boolean {\n  const user = users.find(u => u.username === username);\n  if (!user) {\n    console.log('User not found');\n    return false;\n  }\n  const isAuthenticated = authenticate(username, password);\n  if (isAuthenticated) {\n    console.log('User authenticated');\n    logAudit(user.id, 'login', 'success');\n    return true;\n  } else {\n    console.log('Authentication failed');\n    logAudit(user.id, 'login', 'failure');\n    return false;\n  }\n}\n\n// Example usage\nconst username = 'alice';\nconst password = 'password';\nconst loginSuccess = login(username, password);\n", "suffix": "\n\n// Verify audit log\nconst aliceLog = auditLogs.find(log => log.userId === 1 && log.action === 'login');\nconsole.assert(aliceLog !== undefined, 'Audit log for Alice should exist');\nconsole.assert(aliceLog?.status === 'success', 'Alice login status should be success');\n\n// Clean up\nusers.length = 0;\nauditLogs.length = 0;\n", "golden_completion": "if (loginSuccess) {\n  console.log('Login successful for user:', username);\n} else {\n  console.log('Login failed for user:', username);\n}\n", "LLM_justification": "This test case is a good example because it involves both error handling and security domain context, specifically user authentication and audit logging. The code tests the LLM's ability to understand the logic behind authenticating a user and logging the result of the authentication attempt. The assertions verify that the audit log is correctly updated based on the authentication outcome. This scenario is realistic and common in applications requiring secure user access and auditing capabilities.", "assertions": "console.assert(loginSuccess === true, 'Login should be successful for correct credentials');\nconsole.assert(auditLogs.length === 1, 'There should be one audit log entry');\nconsole.assert(auditLogs[0].status === 'success', 'Audit log status should be success');\n", "o3-mini": "console.log(`Login success: ${loginSuccess}`);"}
{"id": "39", "testsource": "devbench-code-purpose-understanding", "language": "typescript", "prefix": "import * as fs from 'fs';\nimport * as crypto from 'crypto';\n\n// Helper function to generate a random string\nfunction generateRandomString(length: number): string {\n    return crypto.randomBytes(length).toString('hex');\n}\n\n// Helper function to simulate writing to a log file\nfunction writeLog(message: string): void {\n    fs.appendFileSync('audit.log', message + '\\n');\n}\n\n// Class representing a user session\nclass UserSession {\n    private sessionId: string;\n    private userId: string;\n    private startTime: Date;\n    private endTime: Date | null;\n    private actions: string[];\n\n    constructor(userId: string) {\n        this.sessionId = generateRandomString(16);\n        this.userId = userId;\n        this.startTime = new Date();\n        this.endTime = null;\n        this.actions = [];\n    }\n\n    public addAction(action: string): void {\n        this.actions.push(action);\n    }\n\n    public endSession(): void {\n        this.endTime = new Date();\n        this.logSession();\n    }\n\n    private logSession(): void {\n        const sessionDuration = this.endTime ? (this.endTime.getTime() - this.startTime.getTime()) : 0;\n        const logMessage = `SessionID: ${this.sessionId}, UserID: ${this.userId}, Duration: ${sessionDuration}ms, Actions: ${this.actions.join(', ')}`;\n        writeLog(logMessage);\n    }\n}\n\n// Function to simulate user actions\nfunction simulateUserActions(userId: string, actions: string[]): void {\n    const session = new UserSession(userId);\n    actions.forEach(action => session.addAction(action));\n    // Missing code to end the session\n", "suffix": "\n}\n\n// Test the simulateUserActions function\nsimulateUserActions('user123', ['login', 'view_dashboard', 'logout']);\n\n// Read the log file to assert the correct entries\nconst logData = fs.readFileSync('audit.log', 'utf8');\nconsole.assert(logData.includes('SessionID: '), 'Log must contain a SessionID');\nconsole.assert(logData.includes('UserID: user123'), 'Log must contain the correct UserID');\nconsole.assert(logData.includes('Actions: login, view_dashboard, logout'), 'Log must contain the correct actions');\n\n// Cleanup log file\nfs.unlinkSync('audit.log');", "golden_completion": "session.endSession();", "LLM_justification": "This example tests the LLM's ability to comprehend the business logic of an auditing system where user sessions are logged, including the actions taken by the user. The completion involves correctly ending the user session and logging it. This scenario uses OOP patterns and fits into the domain of security (auditing). The assertions verify that the log contains the expected session details, ensuring the completion maintains business logic consistency.", "assertions": "console.assert(logData.includes('SessionID: '), 'Log must contain a SessionID');\nconsole.assert(logData.includes('UserID: user123'), 'Log must contain the correct UserID');\nconsole.assert(logData.includes('Actions: login, view_dashboard, logout'), 'Log must contain the correct actions');", "o3-mini": "    session.endSession();"}
{"id": "40", "testsource": "devbench-code-purpose-understanding", "language": "typescript", "prefix": "import { randomBytes, createCipheriv, createDecipheriv } from 'crypto';\n\nclass EncryptionService {\n    private algorithm: string;\n    private key: Buffer;\n    private ivLength: number;\n\n    constructor(algorithm: string, key: Buffer, ivLength: number = 16) {\n        this.algorithm = algorithm;\n        this.key = key;\n        this.ivLength = ivLength;\n    }\n\n    encrypt(text: string): string {\n        const iv = randomBytes(this.ivLength);\n        const cipher = createCipheriv(this.algorithm, this.key, iv);\n        let encrypted = cipher.update(text, 'utf8', 'hex');\n        encrypted += cipher.final('hex');\n        return iv.toString('hex') + ':' + encrypted;\n    }\n\n    decrypt(encryptedText: string): string {\n        const [ivHex, encrypted] = encryptedText.split(':');\n        const iv = Buffer.from(ivHex, 'hex');\n        const decipher = createDecipheriv(this.algorithm, this.key, iv);\n        let decrypted = decipher.update(encrypted, 'hex', 'utf8');\n        decrypted += decipher.final('utf8');\n        return decrypted;\n    }\n}\n\nconst key = randomBytes(32);\nconst service = new EncryptionService('aes-256-cbc', key);\n\n// Encrypt a text\nconst originalText = 'Hello, World!';\nconst encryptedText = service.encrypt(originalText);\nconsole.log('Encrypted:', encryptedText);\n\n// Decrypt the text back\nconst decryptedText = service.decrypt(encryptedText);\nconsole.log('Decrypted:', decryptedText);\n\n// Assertions\nimport * as assert from 'assert';\n", "suffix": "assert.strictEqual(service.decrypt('invalid:encrypted'), ''); // Should throw an error or return an empty string\nconsole.log('Invalid decryption handled correctly.');\n", "golden_completion": "assert.strictEqual(decryptedText, originalText);\n", "LLM_justification": "This scenario demonstrates an encryption service using Node.js crypto module, a common pattern in security-related contexts. The focus is on the ability to understand encryption and decryption processes, and the assertions test the consistency of these operations. This tests the LLM's ability to comprehend and complete a sequence where the integrity of encrypted and decrypted data must be maintained, a crucial aspect in many real-world applications involving secure data handling.", "assertions": "assert.strictEqual(decryptedText, originalText);\n", "o3-mini": "try {\n    const result = service.decrypt('invalid:encrypted');\n    assert.strictEqual(result, '');\n} catch {\n    assert.ok(true);\n}"}
{"id": "41", "testsource": "devbench-code-purpose-understanding", "language": "typescript", "prefix": "import * as crypto from 'crypto';\n\n// User data type definition\ninterface User {\n  id: number;\n  username: string;\n  password: string;\n  salt: string;\n}\n\n// Function to generate a salt\nfunction generateSalt(length: number): string {\n  return crypto.randomBytes(length).toString('hex');\n}\n\n// Function to hash a password with a given salt\nfunction hashPassword(password: string, salt: string): string {\n  const hash = crypto.createHmac('sha256', salt);\n  hash.update(password);\n  return hash.digest('hex');\n}\n\n// Class responsible for user authentication\nclass AuthService {\n  private users: User[] = [];\n\n  // Register a new user\n  register(username: string, password: string): User {\n    const salt = generateSalt(16);\n    const hashedPassword = hashPassword(password, salt);\n    const newUser: User = { id: this.users.length + 1, username, password: hashedPassword, salt };\n    this.users.push(newUser);\n    return newUser;\n  }\n\n  // Authenticate a user with username and password\n  authenticate(username: string, password: string): boolean {\n    const user = this.users.find(u => u.username === username);\n    if (!user) return false;\n    const hashedPassword = hashPassword(password, user.salt);\n    return user.password === hashedPassword;\n  }\n\n  // Fetch user by ID\n  getUserById(id: number): User | undefined {\n    return this.users.find(u => u.id === id);\n  }\n}\n\n// Utility function to log user login attempts\nfunction logLoginAttempt(username: string, success: boolean): void {\n  console.log(`Login attempt for user: ${username} was ${success ? 'successful' : 'unsuccessful'}`);\n}\n\n// Initialize AuthService\nconst authService = new AuthService();\n\n// Register a test user\nconst testUser = authService.register('testUser', 'securePassword123');\nconsole.log('Test user registered:', testUser);\n\n// Attempt to authenticate with the correct password\nconst authSuccess = authService.authenticate('testUser', 'securePassword123');\nlogLoginAttempt('testUser', authSuccess);\n\n", "suffix": "// Attempt to authenticate with an incorrect password\nconst authFailure = authService.authenticate('testUser', 'wrongPassword');\nlogLoginAttempt('testUser', authFailure);\n\n// Assertions to verify business logic\nimport { strict as assert } from 'assert';\n\nassert.strictEqual(authFailure, false, 'Authentication should fail with wrong password');\n\n// Clean up resources (not needed in this example, but placeholder for real scenarios)\n// e.g., close database connections\n", "golden_completion": "// Assertions to verify business logic\nimport { strict as assert } from 'assert';\n\nassert.strictEqual(authSuccess, true, 'Authentication should succeed with correct password');\n\n", "LLM_justification": "This scenario tests the LLM's understanding of user authentication logic within a security context, using TypeScript. The prefix provides comprehensive setup including user registration, password hashing, and authentication functions. The golden_completion involves assertions that check the correctness of the authentication process, verifying the business rule that the correct password should authenticate successfully. This scenario is a good test case because it requires the LLM to understand the security domain, proper use of cryptographic functions, and the business logic of user authentication.", "assertions": "assert.strictEqual(authSuccess, true, 'Authentication should succeed with correct password');\nassert.strictEqual(authFailure, false, 'Authentication should fail with wrong password');", "o3-mini": "const authFailure = authService.authenticate('testUser', 'wrongPassword');\nlogLoginAttempt('testUser', authFailure);"}
{"id": "42", "testsource": "devbench-code-purpose-understanding", "language": "typescript", "prefix": "import * as crypto from 'crypto';\n\n// Encryption Utility\nclass EncryptionUtility {\n\tprivate algorithm: string;\n\tprivate key: Buffer;\n\tprivate iv: Buffer;\n\n\tconstructor() {\n\t\tthis.algorithm = 'aes-256-cbc';\n\t\tthis.key = crypto.randomBytes(32);\n\t\tthis.iv = crypto.randomBytes(16);\n\t}\n\n\t// Encrypt a text\n\tencrypt(text: string): string {\n\t\tconst cipher = crypto.createCipheriv(this.algorithm, this.key, this.iv);\n\t\tlet encrypted = cipher.update(text, 'utf8', 'hex');\n\t\tencrypted += cipher.final('hex');\n\t\treturn encrypted;\n\t}\n\n\t// Decrypt a text\n\tdecrypt(encryptedText: string): string {\n\t\tconst decipher = crypto.createDecipheriv(this.algorithm, this.key, this.iv);\n\t\tlet decrypted = decipher.update(encryptedText, 'hex', 'utf8');\n\t\tdecrypted += decipher.final('utf8');\n\t\treturn decrypted;\n\t}\n}\n\n// Mock data for testing\nconst sampleText = \"Sensitive data to encrypt\";\nconst encryptionUtility = new EncryptionUtility();\n\n// Encrypting the sample text\nconst encryptedText = encryptionUtility.encrypt(sampleText);\n", "suffix": "const decryptedText = \"\";\n\n// Assertions\nimport { strict as assert } from 'assert';\nassert.strictEqual(encryptedText, \"\");\nassert.strictEqual(decryptedText, sampleText);\n\n// Cleanup\n// No resources to cleanup in this scenario\n", "golden_completion": "const decryptedText = encryptionUtility.decrypt(encryptedText);\n\n// Assertions\nimport { strict as assert } from 'assert';\nassert.strictEqual(encryptedText.length > 0, true);\nassert.strictEqual(decryptedText, sampleText);\n\n// Cleanup\n// No resources to cleanup in this scenario\n", "LLM_justification": "This example tests the LLM's ability to understand encryption and decryption logic in the context of security. The pattern includes encrypting a sample text and then decrypting it back to verify the correctness. The completion requires the model to correctly implement the decryption step and verify that the decrypted text matches the original. The assertions ensure the encrypted text is non-empty and the decrypted text matches the original, demonstrating understanding of the security domain and the correct use of crypto library functions.", "assertions": "import { strict as assert } from 'assert';\nassert.strictEqual(encryptedText.length > 0, true);\nassert.strictEqual(decryptedText, sampleText);\n", "o3-mini": "const decryptedText = encryptionUtility.decrypt(encryptedText);"}
{"id": "43", "testsource": "devbench-code-purpose-understanding", "language": "typescript", "prefix": "import * as assert from 'assert';\n\ninterface Metrics {\n    pageViews: number;\n    clicks: number;\n    purchases: number;\n}\n\nclass AnalyticsTracker {\n    private metrics: Metrics;\n    constructor() {\n        this.metrics = { pageViews: 0, clicks: 0, purchases: 0 };\n    }\n\n    public incrementPageViews() {\n        this.metrics.pageViews += 1;\n    }\n\n    public incrementClicks() {\n        this.metrics.clicks += 1;\n    }\n\n    public incrementPurchases() {\n        this.metrics.purchases += 1;\n    }\n\n    public getMetrics(): Metrics {\n        return this.metrics;\n    }\n}\n\n// Helper function to simulate user actions\nfunction simulateUserActions(tracker: AnalyticsTracker) {\n    tracker.incrementPageViews();\n    tracker.incrementClicks();\n    tracker.incrementPurchases();\n}\n\n// Initialize tracker\nconst tracker = new AnalyticsTracker();\n\n// Simulate some user actions\nsimulateUserActions(tracker);\n\n// Assertions to verify the correctness of the metrics\nassert.strictEqual(tracker.getMetrics().pageViews, 1);\nassert.strictEqual(tracker.getMetrics().clicks, 1);\nassert.strictEqual(tracker.getMetrics().purchases, 1);\n\n// Simulate more user actions\nsimulateUserActions(tracker);\n\n// More assertions\nassert.strictEqual(tracker.getMetrics().pageViews, 2);\nassert.strictEqual(tracker.getMetrics().clicks, 2);\nassert.strictEqual(tracker.getMetrics().purchases, 2);\n\n// Simulate a custom number of actions\nfunction simulateCustomUserActions(tracker: AnalyticsTracker, actions: { pageViews: number, clicks: number, purchases: number }) {\n", "suffix": "}\n\n// Simulate custom actions\nsimulateCustomUserActions(tracker, { pageViews: 3, clicks: 2, purchases: 1 });\n\n// Assertions for custom actions\nassert.strictEqual(tracker.getMetrics().pageViews, 5);\nassert.strictEqual(tracker.getMetrics().clicks, 4);\nassert.strictEqual(tracker.getMetrics().purchases, 3);\n\nconsole.log('All assertions passed.');\n", "golden_completion": "    for (let i = 0; i < actions.pageViews; i++) {\n        tracker.incrementPageViews();\n    }\n    for (let i = 0; i < actions.clicks; i++) {\n        tracker.incrementClicks();\n    }\n    for (let i = 0; i < actions.purchases; i++) {\n        tracker.incrementPurchases();\n    }\n", "LLM_justification": "This test case evaluates the LLM's ability to understand and continue a code pattern that involves tracking and updating metrics. The scenario is relevant to the domain of analytics, which requires understanding of increment operations and maintaining state consistency. The golden completion demonstrates how to properly iterate over specified actions to update metrics, ensuring business logic is followed. Assertions are placed to verify that the metrics are correctly updated after each simulation, testing the functional correctness and business rule compliance of the provided code.", "assertions": "assert.strictEqual(tracker.getMetrics().pageViews, 5);\nassert.strictEqual(tracker.getMetrics().clicks, 4);\nassert.strictEqual(tracker.getMetrics().purchases, 3);\n\nconsole.log('All assertions passed.');", "o3-mini": "    for (let i = 0; i < actions.pageViews; i++) {\n        tracker.incrementPageViews();\n    }\n    for (let i = 0; i < actions.clicks; i++) {\n        tracker.incrementClicks();\n    }\n    for (let i = 0; i < actions.purchases; i++) {\n        tracker.incrementPurchases();\n    }"}
{"id": "44", "testsource": "devbench-code-purpose-understanding", "language": "typescript", "prefix": "import { readFileSync, writeFileSync } from 'fs';\nimport { join } from 'path';\n\n// Define a type for our metrics\ninterface Metric {\n    timestamp: number;\n    value: number;\n}\n\n// Utility function to read metrics from a JSON file\nfunction readMetrics(filePath: string): Metric[] {\n    const data = readFileSync(filePath, 'utf-8');\n    return JSON.parse(data);\n}\n\n// Utility function to write metrics to a JSON file\nfunction writeMetrics(filePath: string, metrics: Metric[]): void {\n    const data = JSON.stringify(metrics, null, 2);\n    writeFileSync(filePath, data);\n}\n\n// Function to calculate the average value of metrics\nfunction calculateAverage(metrics: Metric[]): number {\n    const total = metrics.reduce((sum, metric) => sum + metric.value, 0);\n    return total / metrics.length;\n}\n\n// Function to calculate the maximum value of metrics\nfunction calculateMax(metrics: Metric[]): number {\n    return Math.max(...metrics.map(metric => metric.value));\n}\n\n// Function to calculate the minimum value of metrics\nfunction calculateMin(metrics: Metric[]): number {\n    return Math.min(...metrics.map(metric => metric.value));\n}\n\n// Example file paths\nconst inputFilePath = join(__dirname, 'metrics.json');\nconst outputFilePath = join(__dirname, 'output_metrics.json');\n\n// Read the metrics from the input file\nconst metrics = readMetrics(inputFilePath);\n\n// Calculate the average, max, and min values\nconst average = calculateAverage(metrics);\nconst max = calculateMax(metrics);\nconst min = calculateMin(metrics);\n\n// Create a summary object\nconst summary = {\n    average,\n    max,\n    min,\n    count: metrics.length,\n    timestamp: Date.now()\n};\n\n// Write the summary to the output file\nwriteMetrics(outputFilePath, metrics);", "suffix": "\n// Print the summary to the console\nconsole.log('Metrics summary:', summary);\n\n// Clean up: Remove the output file (if needed)\nimport { unlinkSync } from 'fs';\nunlinkSync(outputFilePath);", "golden_completion": "\n// Add the summary to the metrics array\nmetrics.push({ timestamp: summary.timestamp, value: summary.average });\n\n// Write the updated metrics back to the output file\nwriteMetrics(outputFilePath, metrics);", "LLM_justification": "This test case is an excellent example because it involves the use of data structures and analytics within a real-world scenario of processing and summarizing metrics from a file. It tests the LLM's ability to understand the context of calculating and summarizing metrics, as well as updating the dataset with new information. The assertions will verify that the new summary is correctly added to the metrics and the file is properly updated.", "assertions": "import { strict as assert } from 'assert';\n\n// Read the updated metrics from the output file\nconst updatedMetrics = readMetrics(outputFilePath);\n\n// Check that the updated metrics contain the new summary\nconst lastMetric = updatedMetrics[updatedMetrics.length - 1];\nassert.equal(lastMetric.value, summary.average, 'The last metric value should be the average');\nassert.equal(lastMetric.timestamp, summary.timestamp, 'The last metric timestamp should match the summary timestamp');\n\n// Ensure the count of metrics is correct\nassert.equal(updatedMetrics.length, metrics.length, 'The length of updated metrics should be incremented by one');", "o3-mini": "writeFileSync(outputFilePath, JSON.stringify(summary, null, 2));"}
{"id": "45", "testsource": "devbench-code-purpose-understanding", "language": "typescript", "prefix": "import { EventEmitter } from 'events';\n\n// Define a simple interface for an event payload\ntype EventPayload = {\n  eventType: string;\n  eventData: any;\n};\n\n// Custom EventEmitter class for handling game events\nclass GameEventEmitter extends EventEmitter {\n  // Emit an event with the specified payload\n  emitEvent(payload: EventPayload): void {\n    this.emit(payload.eventType, payload.eventData);\n  }\n\n  // Add a listener for a specific event type\n  addEventListener(eventType: string, listener: (data: any) => void): void {\n    this.on(eventType, listener);\n  }\n\n  // Remove a listener for a specific event type\n  removeEventListener(eventType: string, listener: (data: any) => void): void {\n    this.off(eventType, listener);\n  }\n}\n\n// Create an instance of the GameEventEmitter\nconst gameEvents = new GameEventEmitter();\n\n// Define a function to log event data\ntype EventLog = { timestamp: Date; eventType: string; eventData: any };\nconst eventLog: EventLog[] = [];\nfunction logEvent(eventType: string, eventData: any) {\n  eventLog.push({ timestamp: new Date(), eventType, eventData });\n}\n\n// Define some game-specific event handlers\nfunction onPlayerScored(data: any) {\n  console.log('Player scored:', data);\n  logEvent('playerScored', data);\n}\nfunction onEnemyDefeated(data: any) {\n  console.log('Enemy defeated:', data);\n  logEvent('enemyDefeated', data);\n}\n\n// Add event listeners to gameEvents\n", "suffix": "gameEvents.addEventListener('enemyDefeated', onEnemyDefeated);\n\n// Emit some test events\ngameEvents.emitEvent({ eventType: 'playerScored', eventData: { playerId: 1, score: 10 } });\ngameEvents.emitEvent({ eventType: 'enemyDefeated', eventData: { enemyId: 42 } });\n\n// Assertions\nimport { strict as assert } from 'assert';\nassert.equal(eventLog.length, 2, 'Event log should contain 2 entries');\nassert.equal(eventLog[0].eventType, 'playerScored', 'First event should be playerScored');\nassert.equal(eventLog[0].eventData.playerId, 1, 'First event data should match');\nassert.equal(eventLog[0].eventData.score, 10, 'First event score should match');\nassert.equal(eventLog[1].eventType, 'enemyDefeated', 'Second event should be enemyDefeated');\nassert.equal(eventLog[1].eventData.enemyId, 42, 'Second event data should match');\n\n// Clean up event listeners\ngameEvents.removeEventListener('playerScored', onPlayerScored);\ngameEvents.removeEventListener('enemyDefeated', onEnemyDefeated);", "golden_completion": "gameEvents.addEventListener('playerScored', onPlayerScored);", "LLM_justification": "This test case is designed to evaluate the LLM's ability to understand and correctly continue code based on its semantic meaning and business context. The scenario involves event handling in a game mechanics context, where events such as 'playerScored' and 'enemyDefeated' are logged and handled using an EventEmitter pattern. The golden completion requires adding an event listener for the 'playerScored' event, which is crucial for the subsequent assertions to pass. This completion demonstrates understanding of the event handling mechanism and its importance in the game's business logic.", "assertions": "import { strict as assert } from 'assert';\nassert.equal(eventLog.length, 2, 'Event log should contain 2 entries');\nassert.equal(eventLog[0].eventType, 'playerScored', 'First event should be playerScored');\nassert.equal(eventLog[0].eventData.playerId, 1, 'First event data should match');\nassert.equal(eventLog[0].eventData.score, 10, 'First event score should match');\nassert.equal(eventLog[1].eventType, 'enemyDefeated', 'Second event should be enemyDefeated');\nassert.equal(eventLog[1].eventData.enemyId, 42, 'Second event data should match');", "o3-mini": "gameEvents.addEventListener('enemyDefeated', onEnemyDefeated);"}
{"id": "46", "testsource": "devbench-code-purpose-understanding", "language": "typescript", "prefix": "import fs from 'fs';\nimport path from 'path';\n\ninterface TestResult {\n    testName: string;\n    passed: boolean;\n    duration: number;\n}\n\nclass TestRunner {\n    private results: TestResult[] = [];\n\n    public async runTests(testFiles: string[]): Promise<void> {\n        for (const file of testFiles) {\n            try {\n                const testModule = await import(path.resolve(file));\n                const testNames = Object.keys(testModule).filter(key => key.startsWith('test'));\n                for (const testName of testNames) {\n                    const start = Date.now();\n                    await testModule[testName]();\n                    const duration = Date.now() - start;\n                    this.results.push({ testName, passed: true, duration });\n                }\n            } catch (error) {\n                this.results.push({ testName: file, passed: false, duration: 0 });\n            }\n        }\n    }\n\n    public getResults(): TestResult[] {\n        return this.results;\n    }\n}\n\n// Utility function to write results to a file\nfunction writeResultsToFile(results: TestResult[], filePath: string): void {\n    const fileContent = JSON.stringify(results, null, 2);\n    fs.writeFileSync(filePath, fileContent);\n}\n\n// Helper function to read test files from a directory\nfunction getTestFilesFromDirectory(directory: string): string[] {\n    const files = fs.readdirSync(directory);\n    return files.filter(file => file.endsWith('.test.js')).map(file => path.join(directory, file));\n}\n\n// Main function to orchestrate test running and reporting\nasync function main() {\n    const testDirectory = './tests';\n    const testFiles = getTestFilesFromDirectory(testDirectory);\n    const testRunner = new TestRunner();\n    await testRunner.runTests(testFiles);\n    const results = testRunner.getResults();\n    writeResultsToFile(results, './test-results.json');\n}\n\n// Run the main function and handle errors\n", "suffix": "\n// Cleanup: remove the test results file after verification\nfs.unlinkSync('./test-results.json');\n", "golden_completion": "main().catch(error => console.error('Error running tests:', error));\n", "LLM_justification": "This test case evaluates the LLM's ability to understand and correctly implement the async-await pattern within the context of a tool automation scenario. The code involves running automated tests, capturing results, and handling errors appropriately. The prefix sets up the context with a test runner class, utility functions, and a main orchestrating function. The LLM must comprehend the business logic and ensure proper error handling and async-await usage in the golden completion. Assertions verify that the tests are run, results are captured, and errors are logged if they occur.", "assertions": "import { strict as assert } from 'assert';\nimport fs from 'fs';\nimport path from 'path';\n\n// Check if the test results file exists\nassert(fs.existsSync('./test-results.json'));\n\n// Read the results file\nconst resultsContent = fs.readFileSync('./test-results.json', 'utf8');\nconst results = JSON.parse(resultsContent) as TestResult[];\n\n// Verify the results structure\nassert(Array.isArray(results), 'Results should be an array');\nresults.forEach(result => {\n    assert(typeof result.testName === 'string', 'Test name should be a string');\n    assert(typeof result.passed === 'boolean', 'Passed flag should be a boolean');\n    assert(typeof result.duration === 'number', 'Duration should be a number');\n});\n\n// Ensure at least one test result is present\nassert(results.length > 0, 'There should be at least one test result');", "o3-mini": "main().catch(error => {\n    console.error(error);\n});"}
{"id": "47", "testsource": "devbench-code-purpose-understanding", "language": "typescript", "prefix": "import fs from 'fs';\nimport path from 'path';\n\n// Utility function to read a JSON file\nconst readJsonFile = (filePath: string): any => {\n  const rawData = fs.readFileSync(filePath);\n  return JSON.parse(rawData.toString());\n};\n\n// Utility function to write to a JSON file\nconst writeJsonFile = (filePath: string, data: any): void => {\n  const jsonData = JSON.stringify(data, null, 2);\n  fs.writeFileSync(filePath, jsonData);\n};\n\n// Report generation utility\nclass ReportGenerator {\n  private data: any;\n\n  constructor(dataFilePath: string) {\n    this.data = readJsonFile(dataFilePath);\n  }\n\n  public generateSummaryReport(outputFilePath: string): void {\n    const summary = this.createSummary();\n    writeJsonFile(outputFilePath, summary);\n  }\n\n  private createSummary(): any {\n    const summary = {\n      totalUsers: this.data.users.length,\n      totalSales: this.data.sales.reduce((acc: number, sale: any) => acc + sale.amount, 0),\n      averageSaleValue: this.calculateAverageSaleValue()\n    };\n    return summary;\n  }\n\n  private calculateAverageSaleValue(): number {\n    return this.data.sales.reduce((acc: number, sale: any) => acc + sale.amount, 0) / this.data.sales.length;\n  }\n}\n\n// Error handling example\nfunction generateReport(dataFilePath: string, outputFilePath: string): void {\n  try {\n    const reportGenerator = new ReportGenerator(dataFilePath);\n    reportGenerator.generateSummaryReport(outputFilePath);\n  } catch (error) {\n    console.error('Failed to generate report:', error);\n  }\n}\n\n// Mock data for testing\nconst mockData = {\n  users: [\n    { id: 1, name: 'Alice' },\n    { id: 2, name: 'Bob' }\n  ],\n  sales: [\n    { id: 1, userId: 1, amount: 100 },\n    { id: 2, userId: 2, amount: 150 }\n  ]\n};\n\nconst mockDataFilePath = path.join(__dirname, 'mockData.json');\nconst mockOutputFilePath = path.join(__dirname, 'reportSummary.json');\n\n// Write mock data to file for testing\nwriteJsonFile(mockDataFilePath, mockData);\n\n// Test function to generate report\nfunction testGenerateReport() {\n  generateReport(mockDataFilePath, mockOutputFilePath);\n  const result = readJsonFile(mockOutputFilePath);\n  return result;\n}\n", "suffix": "\n// Clean up mock files\nfs.unlinkSync(mockDataFilePath);\nfs.unlinkSync(mockOutputFilePath);\n", "golden_completion": "\nconst result = testGenerateReport();\n", "LLM_justification": "This test case is designed to evaluate an LLM's understanding of error handling and analytics within a TypeScript application. The scenario involves reading and writing JSON files, generating a summary report, and handling potential errors. The assertions verify that the generated report is accurate based on the provided mock data, ensuring that the business logic is correctly implemented. This example is a good test case because it demonstrates real-world tasks such as file I/O, data processing, and error management, all of which are common in many business applications.", "assertions": "const result = testGenerateReport();\nconsole.assert(result.totalUsers === 2, 'Total users should be 2');\nconsole.assert(result.totalSales === 250, 'Total sales should be 250');\nconsole.assert(result.averageSaleValue === 125, 'Average sale value should be 125');", "o3-mini": "console.log(testGenerateReport());"}
{"id": "48", "testsource": "devbench-code-purpose-understanding", "language": "typescript", "prefix": "import fs from 'fs';\nimport { promisify } from 'util';\n\nconst readFileAsync = promisify(fs.readFile);\nconst writeFileAsync = promisify(fs.writeFile);\n\ninterface Metric {\n  name: string;\n  value: number;\n  timestamp: Date;\n}\n\nclass MetricsCollector {\n  private metrics: Metric[] = [];\n\n  collect(metric: Metric) {\n    this.metrics.push(metric);\n  }\n\n  async saveToFile(filename: string): Promise<void> {\n    try {\n      const data = JSON.stringify(this.metrics, null, 2);\n      await writeFileAsync(filename, data);\n    } catch (error) {\n      console.error('Error saving metrics to file:', error);\n    }\n  }\n\n  async loadFromFile(filename: string): Promise<void> {\n    try {\n      const data = await readFileAsync(filename, 'utf-8');\n      this.metrics = JSON.parse(data);\n    } catch (error) {\n      console.error('Error loading metrics from file:', error);\n    }\n  }\n\n  getMetrics(): Metric[] {\n    return this.metrics;\n  }\n}\n\nconst collector = new MetricsCollector();\ncollector.collect({ name: 'CPU Usage', value: 75, timestamp: new Date() });\ncollector.collect({ name: 'Memory Usage', value: 60, timestamp: new Date() });\nconst FILENAME = 'metrics.json';\n\nasync function main() {\n  await collector.saveToFile(FILENAME);\n  // Clear current metrics\n  collector['metrics'] = [];\n  await collector.loadFromFile(FILENAME);\n", "suffix": "\n  console.log('Loaded Metrics:', loadedMetrics);\n  await writeFileAsync(FILENAME, ''); // Clean up the file\n}\n\nmain().catch(console.error);", "golden_completion": "  const loadedMetrics = collector.getMetrics();\n", "LLM_justification": "This example tests the LLM's ability to understand and continue a TypeScript code scenario involving Promises/async-await in the context of analytics (metrics collection and reporting). The prefix establishes a comprehensive setup for collecting and saving metrics to a file, while the golden completion requires the LLM to correctly implement assertions verifying the loaded metrics. This demonstrates the LLM's understanding of async operations, file handling, and business logic validation.", "assertions": "const loadedMetrics = collector.getMetrics();\nconsole.assert(loadedMetrics.length === 2, 'Metrics count should be 2');\nconsole.assert(loadedMetrics[0].name === 'CPU Usage', 'First metric should be CPU Usage');\nconsole.assert(loadedMetrics[1].name === 'Memory Usage', 'Second metric should be Memory Usage');", "o3-mini": "  const loadedMetrics = collector.getMetrics();"}
{"id": "49", "testsource": "devbench-code-purpose-understanding", "language": "typescript", "prefix": "import { readFile } from 'fs/promises';\nimport { join } from 'path';\n\ninterface Report {\n  date: string;\n  metric: string;\n  value: number;\n}\n\nasync function loadReport(filePath: string): Promise<Report[]> {\n  const data = await readFile(filePath, 'utf8');\n  const lines = data.split('\\n');\n  return lines.map(line => {\n    const [date, metric, value] = line.split(',');\n    return { date, metric, value: parseFloat(value) };\n  });\n}\n\nfunction filterReportsByMetric(reports: Report[], metric: string): Report[] {\n  return reports.filter(report => report.metric === metric);\n}\n\nfunction calculateAverageValue(reports: Report[]): number {\n  const total = reports.reduce((sum, report) => sum + report.value, 0);\n  return total / reports.length;\n}\n\nasync function generateMetricReport(filePath: string, metric: string): Promise<string> {\n  try {\n    const reports = await loadReport(filePath);\n    const filteredReports = filterReportsByMetric(reports, metric);\n    if (filteredReports.length === 0) {\n      throw new Error(`No reports found for metric: ${metric}`);\n    }\n    const averageValue = calculateAverageValue(filteredReports);\n", "suffix": "\n  } catch (error) {\n    return `Error generating report: ${error.message}`;\n  }\n}\n\n(async () => {\n  const filePath = join(__dirname, 'sample_report.csv');\n  const metric = 'temperature';\n  const report = await generateMetricReport(filePath, metric);\n  console.log(report);\n})();\n", "golden_completion": "    return `The average value for the metric ${metric} is: ${averageValue.toFixed(2)}`;\n", "LLM_justification": "This example tests the LLM's ability to understand and continue a function that processes and generates a metric report. The prefix provides a comprehensive setup, including loading data from a file, filtering reports by a metric, and calculating the average value. The completion must correctly format the report string, maintaining consistency with the context and domain-specific logic of analytics reporting. The suffix provides an alternative return statement, ensuring clear distinction.", "assertions": "import { strict as assert } from 'assert';\n\n(async () => {\n  const filePath = join(__dirname, 'sample_report.csv');\n  const metric = 'temperature';\n  const report = await generateMetricReport(filePath, metric);\n  assert(report.startsWith('The average value for the metric temperature is:'));\n  console.log('All assertions passed.');\n})();\n", "o3-mini": "return `Metric: ${metric}, Average Value: ${averageValue}`;"}
{"id": "50", "testsource": "devbench-code-purpose-understanding", "language": "typescript", "prefix": "import fetch from 'node-fetch';\nimport { assert } from 'chai';\n\n// Type definitions for the analytics data structure\ninterface Metric {\n\tname: string;\n\tvalue: number;\n\ttimestamp: Date;\n}\n\n// Utility function to simulate fetching metrics\nasync function fetchMetrics(): Promise<Metric[]> {\n\treturn [\n\t\t{name: 'metric1', value: 10, timestamp: new Date()},\n\t\t{name: 'metric2', value: 20, timestamp: new Date()},\n\t\t{name: 'metric3', value: 30, timestamp: new Date()}\n\t];\n}\n\n// Class to handle metrics processing\nclass MetricsProcessor {\n\tprivate metrics: Metric[] = [];\n\n\tasync loadMetrics() {\n\t\tthis.metrics = await fetchMetrics();\n\t}\n\n\tprocessMetrics() {\n\t\t// Placeholder for metrics processing logic\n\t}\n\n\tgenerateReport() {\n\t\t// Placeholder for report generation logic\n\t}\n}\n\n// Helper function to format metrics for reporting\nfunction formatMetric(metric: Metric): string {\n\treturn `${metric.name}: ${metric.value} at ${metric.timestamp.toISOString()}`;\n}\n\n// Example usage\nasync function runAnalytics() {\n\tconst processor = new MetricsProcessor();\n\tawait processor.loadMetrics();\n\tprocessor.processMetrics();\n", "suffix": "\tconsole.log('Metrics processed.');\n\tprocessor.generateReport();\n}\n\nrunAnalytics();", "golden_completion": "\tconst formattedMetrics = processor.metrics.map(formatMetric);\n\tconsole.log('Formatted Metrics:', formattedMetrics);\n", "LLM_justification": "This test case demonstrates the use of Promises and async-await in the context of an analytics system. The code involves fetching metrics asynchronously, processing them, and formatting them for reporting. This scenario tests the LLM's understanding of asynchronous operations, data transformation, and the business logic of generating reports. It ensures that the LLM can correctly continue the code by adding the logic to format and log the metrics after processing, maintaining consistency with the prefix and suffix.", "assertions": "const processor = new MetricsProcessor();\n(async () => {\n\tawait processor.loadMetrics();\n\tprocessor.processMetrics();\n\tconst formattedMetrics = processor.metrics.map(formatMetric);\n\tassert.isArray(formattedMetrics);\n\tassert.lengthOf(formattedMetrics, 3);\n\tassert.match(formattedMetrics[0], /metric1: 10/);\n\tassert.match(formattedMetrics[1], /metric2: 20/);\n\tassert.match(formattedMetrics[2], /metric3: 30/);\n\tconsole.log('All assertions passed.');\n})();", "o3-mini": "\tprocessor['metrics'].forEach(metric => console.log(formatMetric(metric)));"}
