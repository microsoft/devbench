{"id": "1", "testsource": "devbench-pattern-matching", "language": "python", "prefix": "import statistics\nimport logging\n\nclass DataAnalyzer:\n    def __init__(self, data):\n        self.data = data\n        self.logger = logging.getLogger(__name__)\n        self.logger.setLevel(logging.DEBUG)\n        handler = logging.StreamHandler()\n        handler.setFormatter(logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s'))\n        self.logger.addHandler(handler)\n\n    def analyze_mean(self):\n        try:\n            mean_value = statistics.mean(self.data)\n", "suffix": "        except statistics.StatisticsError as e:\n            self.logger.error(f'Error calculating mean: {e}')\n            raise\n        return mean_value\n\n    def analyze_median(self):\n        try:\n            median_value = statistics.median(self.data)\n            self.logger.info(f'Median value calculated: {median_value}')\n        except statistics.StatisticsError as e:\n            self.logger.error(f'Error calculating median: {e}')\n            raise\n        return median_value\n\n# Example usage\nanalyzer = DataAnalyzer([1, 2, 3, 4, 5])\nmean = analyzer.analyze_mean()\nmedian = analyzer.analyze_median()\n\nassert mean == 3\nassert median == 3", "golden_completion": "            self.logger.info(f'Mean value calculated: {mean_value}')\n", "LLM_justification": "This test case demonstrates logging and error handling in a scientific computing context. The pattern involves calculating statistical measures (mean and median) while logging the results and handling potential exceptions. The golden completion requires the LLM to recognize the pattern of returning the calculated value after logging it, which is established in the analyze_mean method and should be mirrored in analyze_median. This pattern is realistic and common in data analysis tasks where logging and error handling are crucial.", "assertions": "assert mean == 3\nassert median == 3\n", "DeepSeek-V3-0324_completion_0": "            self.logger.info(f'Mean value calculated: {mean_value}')", "DeepSeek-V3-0324_completion_1": "            self.logger.info(f'Mean value calculated: {mean_value}')", "DeepSeek-V3-0324_completion_2": "            self.logger.info(f'Mean value calculated: {mean_value}')", "DeepSeek-V3-0324_completion_3": "            self.logger.info(f'Mean value calculated: {mean_value}')", "DeepSeek-V3-0324_completion_4": "            self.logger.info(f'Mean value calculated: {mean_value}')", "DeepSeek-V3-0324_completions": ["            self.logger.info(f'Mean value calculated: {mean_value}')", "            self.logger.info(f'Mean value calculated: {mean_value}')", "            self.logger.info(f'Mean value calculated: {mean_value}')", "            self.logger.info(f'Mean value calculated: {mean_value}')", "            self.logger.info(f'Mean value calculated: {mean_value}')"]}
{"id": "2", "testsource": "devbench-pattern-matching", "language": "python", "prefix": "import os\n\nclass DataValidator:\n    def __init__(self, schema):\n        self.schema = schema\n\n    def validate(self, data):\n        for key, value in self.schema.items():\n            if key not in data:\n                raise ValueError(f\"Missing key: {key}\")\n            if not isinstance(data[key], value):\n                raise TypeError(f\"Incorrect type for key: {key}\")\n\n# Example usage\nschema = {\n    'name': str,\n    'age': int,\n    'email': str\n}\n\nvalidator = DataValidator(schema)\ndata = {\n    'name': 'John Doe',\n    'age': 30,\n    'email': 'john.doe@example.com'\n}\n\n# Validate the data\ntry:", "suffix": "    print(\"Data is valid\")\nexcept (ValueError, TypeError) as e:\n    print(f\"Data validation error: {e}\")\n\n# Assertions\nassert validator.validate({'name': 'Jane Doe', 'age': 25, 'email': 'jane.doe@example.com'}) is None\n\n# Cleanup\ntry:\n    os.remove('tempfile.txt')\nexcept FileNotFoundError:\n    pass", "golden_completion": "\n    validator.validate(data)\n", "LLM_justification": "This test case effectively demonstrates error handling within the context of data validation. The pattern involves raising exceptions for missing keys or incorrect types, which is common in data validation scenarios. The completion involves calling the validate method within a try-except block, a standard practice for handling potential errors. The assertions verify that the validation works correctly for valid data and that exceptions are raised appropriately for invalid data.", "assertions": "assert validator.validate({'name': 'Jane Doe', 'age': 25, 'email': 'jane.doe@example.com'}) is None\ntry:\n    validator.validate({'name': 'Jane Doe', 'age': 'twenty-five', 'email': 'jane.doe@example.com'})\nexcept TypeError as e:\n    assert str(e) == 'Incorrect type for key: age'\ntry:\n    validator.validate({'name': 'Jane Doe', 'email': 'jane.doe@example.com'})\nexcept ValueError as e:\n    assert str(e) == 'Missing key: age'\n", "DeepSeek-V3-0324_completion_0": "    validator.validate(data)", "DeepSeek-V3-0324_completion_1": "    validator.validate(data)", "DeepSeek-V3-0324_completion_2": "    validator.validate(data)", "DeepSeek-V3-0324_completion_3": "    validator.validate(data)", "DeepSeek-V3-0324_completion_4": "    validator.validate(data)", "DeepSeek-V3-0324_completions": ["    validator.validate(data)", "    validator.validate(data)", "    validator.validate(data)", "    validator.validate(data)", "    validator.validate(data)"]}
{"id": "3", "testsource": "devbench-pattern-matching", "language": "python", "prefix": "import numpy as np\n\nclass DataProcessor:\n    def __init__(self, data):\n        self.data = data\n\n    def normalize(self):\n        mean = np.mean(self.data)\n        std = np.std(self.data)\n        self.data = (self.data - mean) / std\n\n    def clean(self):\n        self.data = self.data[~np.isnan(self.data)]\n\n    def compute_statistics(self):\n", "suffix": "        return median, variance\n\ndata = np.array([1, 2, 3, np.nan, 4, 5, 6, np.nan, 7])\nprocessor = DataProcessor(data)\nprocessor.clean()\nprocessor.normalize()\nmedian, variance = processor.compute_statistics()\n\nassert median == 0.0, 'Expected median to be 0.0 after normalization'\nassert variance == 1.0, 'Expected variance to be 1.0 after normalization'\nprint('All assertions passed!')", "golden_completion": "        median = np.median(self.data)\n        variance = np.var(self.data)", "LLM_justification": "This example tests the LLM's ability to recognize and continue patterns in object-oriented programming (OOP) within the context of data validation and normalization. The completion must adhere to the pattern established in the class methods, ensuring the calculations for median and variance follow the same style and use of numpy functions as the previous methods. Assertions verify the correctness of the statistical computations after cleaning and normalization.", "assertions": "assert isinstance(processor.data, np.ndarray), 'Data should be a numpy array'\nassert not np.isnan(processor.data).any(), 'Data should not contain NaN values after cleaning'\nassert np.isclose(np.mean(processor.data), 0.0), 'Data mean should be close to 0 after normalization'\nassert np.isclose(np.std(processor.data), 1.0), 'Data std should be close to 1 after normalization'\nassert median == 0.0, 'Expected median to be 0.0 after normalization'\nassert variance == 1.0, 'Expected variance to be 1.0 after normalization'", "DeepSeek-V3-0324_completion_0": "        median = np.median(self.data)\n        variance = np.var(self.data)", "DeepSeek-V3-0324_completion_1": "        median = np.median(self.data)\n        variance = np.var(self.data)", "DeepSeek-V3-0324_completion_2": "        median = np.median(self.data)\n        variance = np.var(self.data)", "DeepSeek-V3-0324_completion_3": "        median = np.median(self.data)\n        variance = np.var(self.data)", "DeepSeek-V3-0324_completion_4": "        median = np.median(self.data)\n        variance = np.var(self.data)", "DeepSeek-V3-0324_completions": ["        median = np.median(self.data)\n        variance = np.var(self.data)", "        median = np.median(self.data)\n        variance = np.var(self.data)", "        median = np.median(self.data)\n        variance = np.var(self.data)", "        median = np.median(self.data)\n        variance = np.var(self.data)", "        median = np.median(self.data)\n        variance = np.var(self.data)"]}
{"id": "4", "testsource": "devbench-pattern-matching", "language": "python", "prefix": "class DataValidator:\n    def __init__(self, schema):\n        self.schema = schema\n\n    def validate(self, data):\n        \"\"\"Validate data against the schema.\"\"\"\n        errors = []\n        for field, field_type in self.schema.items():\n            if field not in data:\n                errors.append(f\"Missing field: {field}\")\n            elif not isinstance(data[field], field_type):\n                errors.append(f\"Incorrect type for field: {field}\")\n", "suffix": "\n        return errors\n\nschema = {\n    \"name\": str,\n    \"age\": int,\n    \"email\": str\n}\n\nvalidator = DataValidator(schema)\ndata = {\n    \"name\": \"John Doe\",\n    \"age\": 30,\n    \"email\": \"john.doe@example.com\"\n}\n\nerrors = validator.validate(data)\nassert errors == [], f\"Unexpected errors: {errors}\"\n\ninvalid_data = {\n    \"name\": \"John Doe\",\n    \"age\": \"thirty\",\n    \"email\": \"john.doe@example.com\"\n}\n\nerrors = validator.validate(invalid_data)\nassert \"Incorrect type for field: age\" in errors, f\"Expected type error for age, got: {errors}\"\nassert len(errors) == 1, f\"Expected one error, got: {len(errors)}\"\n\ninvalid_data = {\n    \"age\": 30,\n    \"email\": \"john.doe@example.com\"\n}\n\nerrors = validator.validate(invalid_data)\nassert \"Missing field: name\" in errors, f\"Expected missing field error for name, got: {errors}\"\nassert len(errors) == 1, f\"Expected one error, got: {len(errors)}\"\n", "golden_completion": "            else:\n                if isinstance(data[field], str) and not data[field].strip():\n                    errors.append(f\"Empty field: {field}\")", "LLM_justification": "This test case involves data validation, which is a common task in many applications. The pattern here is validating data against a predefined schema, checking for missing fields and incorrect types. The golden completion adds an additional validation step for empty string values, which is a realistic and practical extension of the pattern. This tests the LLM's ability to recognize and extend validation logic appropriately.", "assertions": "schema = {\n    \"name\": str,\n    \"age\": int,\n    \"email\": str\n}\n\nvalidator = DataValidator(schema)\ndata = {\n    \"name\": \"\",\n    \"age\": 30,\n    \"email\": \"john.doe@example.com\"\n}\n\nerrors = validator.validate(data)\nassert \"Empty field: name\" in errors, f\"Expected empty field error for name, got: {errors}\"\nassert len(errors) == 1, f\"Expected one error, got: {len(errors)}\"\n", "DeepSeek-V3-0324_completion_0": "            elif not isinstance(data[field], field_type):\n                errors.append(f\"Incorrect type for field: {field}\")", "DeepSeek-V3-0324_completion_1": "            elif not isinstance(data[field], field_type):\n                errors.append(f\"Incorrect type for field: {field}\")", "DeepSeek-V3-0324_completion_2": "            elif not isinstance(data[field], field_type):\n                errors.append(f\"Incorrect type for field: {field}\")", "DeepSeek-V3-0324_completion_3": "\n            elif not isinstance(data[field], field_type):\n                errors.append(f\"Incorrect type for field: {field}\")", "DeepSeek-V3-0324_completion_4": "\n            elif not isinstance(data[field], field_type):\n                errors.append(f\"Incorrect type for field: {field}\")", "DeepSeek-V3-0324_completions": ["            elif not isinstance(data[field], field_type):\n                errors.append(f\"Incorrect type for field: {field}\")", "            elif not isinstance(data[field], field_type):\n                errors.append(f\"Incorrect type for field: {field}\")", "            elif not isinstance(data[field], field_type):\n                errors.append(f\"Incorrect type for field: {field}\")", "\n            elif not isinstance(data[field], field_type):\n                errors.append(f\"Incorrect type for field: {field}\")", "\n            elif not isinstance(data[field], field_type):\n                errors.append(f\"Incorrect type for field: {field}\")"]}
{"id": "5", "testsource": "devbench-pattern-matching", "language": "python", "prefix": "import numpy as np\n\nclass DataAnalyzer:\n    def __init__(self, data):\n        self.data = data\n\n    def mean(self):\n        return np.mean(self.data)\n\n    def variance(self):\n", "suffix": "    def standard_deviation(self):\n        return np.std(self.data)\n\n# Creating a sample data set\nsample_data = np.array([1, 2, 3, 4, 5])\nanalyzer = DataAnalyzer(sample_data)\n\n# Assertions to verify the correctness of the implemented methods\nassert analyzer.mean() == 3.0\nassert analyzer.standard_deviation() == np.sqrt(2.0)\nassert analyzer.variance() == 2.0\n\n# No resources to clean up in this example\n", "golden_completion": "        return np.var(self.data)\n", "LLM_justification": "This is a good test case for pattern matching in Python because it involves defining a class with methods that perform statistical computations on a dataset. The pattern of using numpy functions for statistical measures is clear and the completion requires recognizing the pattern of defining methods that wrap numpy functions. The assertions verify that the methods are correctly implemented and return expected values, ensuring both functional and semantic correctness.", "assertions": "assert analyzer.mean() == 3.0\nassert analyzer.standard_deviation() == np.sqrt(2.0)\nassert analyzer.variance() == 2.0\n", "DeepSeek-V3-0324_completion_0": "        return np.var(self.data)", "DeepSeek-V3-0324_completion_1": "        return np.var(self.data)\n    def standard_deviation(self):", "DeepSeek-V3-0324_completion_2": "        return np.var(self.data)\n    def standard_deviation(self):", "DeepSeek-V3-0324_completion_3": "        return np.var(self.data)", "DeepSeek-V3-0324_completion_4": "        return np.var(self.data)", "DeepSeek-V3-0324_completions": ["        return np.var(self.data)", "        return np.var(self.data)\n    def standard_deviation(self):", "        return np.var(self.data)\n    def standard_deviation(self):", "        return np.var(self.data)", "        return np.var(self.data)"]}
{"id": "6", "testsource": "devbench-pattern-matching", "language": "python", "prefix": "import logging\nimport os\n\nclass LogManager:\n    def __init__(self, log_file):\n        self.log_file = log_file\n        self.logger = logging.getLogger(__name__)\n        self.logger.setLevel(logging.DEBUG)\n        self.handler = logging.FileHandler(self.log_file)\n        self.handler.setLevel(logging.DEBUG)\n        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n        self.handler.setFormatter(formatter)\n        self.logger.addHandler(self.handler)\n\n    def log_info(self, message):\n        self.logger.info(message)\n\n    def log_error(self, message):\n        self.logger.error(message)\n\n    def log_warning(self, message):\n        self.logger.warning(message)\n\n", "suffix": "\n# Creating an instance of LogManager\nlog_manager = LogManager('test_log.log')\nlog_manager.log_info('This is an info message')\nlog_manager.log_error('This is an error message')\nlog_manager.log_warning('This is a warning message')\n\n# Verify log file content\nwith open('test_log.log', 'r') as f:\n    logs = f.read()\n\nassert 'This is an info message' in logs\nassert 'This is an error message' in logs\nassert 'This is a warning message' in logs\n\n# Close the log manager before removing the file\nlog_manager.close()\n\n# Clean up\nos.remove('test_log.log')\n", "golden_completion": "    def log_debug(self, message):\n        self.logger.debug(message)\n\n    def close(self):\n        # Close all handlers\n        handlers = self.logger.handlers[:]\n        for handler in handlers:\n            handler.close()\n            self.logger.removeHandler(handler)\n\n", "LLM_justification": "This example tests the LLM's ability to recognize and extend an established pattern of logging methods within a class. The class 'LogManager' includes methods for logging info, error, and warning messages. The completion requires adding a method for logging debug messages, following the same pattern. This is a realistic scenario in system operations where logging different levels of messages is common. The assertions verify that messages are correctly logged, ensuring functional correctness.", "assertions": "log_manager = LogManager('test_log.log')\nlog_manager.log_debug('This is a debug message')\n\nwith open('test_log.log', 'r') as f:\n    logs = f.read()\n\nassert 'This is a debug message' in logs\n\n# Close the log manager before removing the file\nlog_manager.close()\n\n# Clean up\nos.remove('test_log.log')\n", "DeepSeek-V3-0324_completion_0": "    def close(self):\n        self.handler.close()\n        self.logger.removeHandler(self.handler)", "DeepSeek-V3-0324_completion_1": "    def close(self):\n        self.handler.close()\n        self.logger.removeHandler(self.handler)", "DeepSeek-V3-0324_completion_2": "    def close(self):\n        self.handler.close()\n        self.logger.removeHandler(self.handler)", "DeepSeek-V3-0324_completion_3": "    def close(self):\n        self.handler.close()\n        self.logger.removeHandler(self.handler)", "DeepSeek-V3-0324_completion_4": "    def close(self):\n        self.handler.close()\n        self.logger.removeHandler(self.handler)", "DeepSeek-V3-0324_completions": ["    def close(self):\n        self.handler.close()\n        self.logger.removeHandler(self.handler)", "    def close(self):\n        self.handler.close()\n        self.logger.removeHandler(self.handler)", "    def close(self):\n        self.handler.close()\n        self.logger.removeHandler(self.handler)", "    def close(self):\n        self.handler.close()\n        self.logger.removeHandler(self.handler)", "    def close(self):\n        self.handler.close()\n        self.logger.removeHandler(self.handler)"]}
{"id": "7", "testsource": "devbench-pattern-matching", "language": "python", "prefix": "import requests\n\nclass APIClient:\n    def __init__(self, base_url):\n        self.base_url = base_url\n\n    def get(self, endpoint):\n        try:\n            response = requests.get(f\"{self.base_url}/{endpoint}\")\n            response.raise_for_status()\n            return response.json()\n        except requests.RequestException as e:\n            print(f\"GET request failed: {e}\")\n            return None\n\n    def post(self, endpoint, data):\n        try:\n", "suffix": "            response.raise_for_status()\n            return response.json()\n        except requests.RequestException as e:\n            print(f\"POST request failed: {e}\")\n            return None\n\nclient = APIClient(\"https://jsonplaceholder.typicode.com\")\n\n# Test GET request\nresponse = client.get(\"posts/1\")\nassert response is not None, \"GET request should return a response\"\n\n# Test POST request\nresponse = client.post(\"posts\", {\"title\": \"foo\", \"body\": \"bar\", \"userId\": 1})\nassert response is not None, \"POST request should return a response\"\n", "golden_completion": "            response = requests.post(f\"{self.base_url}/{endpoint}\", json=data)\n", "LLM_justification": "This test case is a good example for an LLM because it involves recognizing and completing a pattern in a common context: making HTTP requests in a client class. The established pattern in the `get` method involves making a request, checking the response status, and handling exceptions. The completion for the `post` method should follow the same pattern, ensuring consistency and proper error handling. The assertions test that the methods return valid responses, verifying both functionality and pattern adherence.", "assertions": "response = client.post(\"users\", {\"name\": \"Test User\", \"email\": \"test@example.com\"})\nassert response is not None, \"POST request should return a response\"\n\nresponse = client.get(\"users/1\")\nassert response is not None, \"GET request should return a response\"", "DeepSeek-V3-0324_completion_0": "            response = requests.post(f\"{self.base_url}/{endpoint}\", json=data)", "DeepSeek-V3-0324_completion_1": "            response = requests.post(f\"{self.base_url}/{endpoint}\", json=data)", "DeepSeek-V3-0324_completion_2": "            response = requests.post(f\"{self.base_url}/{endpoint}\", json=data)", "DeepSeek-V3-0324_completion_3": "            response = requests.post(f\"{self.base_url}/{endpoint}\", json=data)", "DeepSeek-V3-0324_completion_4": "            response = requests.post(f\"{self.base_url}/{endpoint}\", json=data)", "DeepSeek-V3-0324_completions": ["            response = requests.post(f\"{self.base_url}/{endpoint}\", json=data)", "            response = requests.post(f\"{self.base_url}/{endpoint}\", json=data)", "            response = requests.post(f\"{self.base_url}/{endpoint}\", json=data)", "            response = requests.post(f\"{self.base_url}/{endpoint}\", json=data)", "            response = requests.post(f\"{self.base_url}/{endpoint}\", json=data)"]}
{"id": "8", "testsource": "devbench-pattern-matching", "language": "python", "prefix": "import statistics\n\nclass DataAnalyzer:\n    def __init__(self, data):\n        self.data = data\n\n    def mean(self):\n        return statistics.mean(self.data)\n\n    def median(self):\n        return statistics.median(self.data)\n\n    def variance(self):\n        return statistics.variance(self.data)\n\n    # Add a method to compute the standard deviation\n    def stdev(self):\n", "suffix": "\n\n# Example usage\nanalyzer = DataAnalyzer([2, 4, 4, 4, 5, 5, 7, 9])\n\nassert analyzer.mean() == 5\nassert analyzer.median() == 4.5\nassert round(analyzer.variance(), 2) == 4.57\nassert round(analyzer.stdev(), 2) == 2.14\n\nprint(\"All assertions passed.\")", "golden_completion": "        return statistics.stdev(self.data)", "LLM_justification": "This test case is a good example of pattern matching in OOP patterns within the context of scientific computing. The pattern established is the use of the statistics module to perform various statistical calculations. The completion should demonstrate an understanding of how to continue this pattern by adding a method to compute the standard deviation using the statistics module. This not only tests the LLM's ability to recognize and complete the pattern but also ensures that it adheres to best practices by leveraging existing library functions. The assertions verify the correctness of the implementation by comparing computed values with expected results.", "assertions": "assert analyzer.mean() == 5\nassert analyzer.median() == 4.5\nassert round(analyzer.variance(), 2) == 4.57\nassert round(analyzer.stdev(), 2) == 2.14", "DeepSeek-V3-0324_completion_0": "        return statistics.stdev(self.data)", "DeepSeek-V3-0324_completion_1": "        return statistics.stdev(self.data)", "DeepSeek-V3-0324_completion_2": "        return statistics.stdev(self.data)", "DeepSeek-V3-0324_completion_3": "        return statistics.stdev(self.data)", "DeepSeek-V3-0324_completion_4": "        return statistics.stdev(self.data)", "DeepSeek-V3-0324_completions": ["        return statistics.stdev(self.data)", "        return statistics.stdev(self.data)", "        return statistics.stdev(self.data)", "        return statistics.stdev(self.data)", "        return statistics.stdev(self.data)"]}
{"id": "9", "testsource": "devbench-pattern-matching", "language": "python", "prefix": "import os\nimport logging\n\nclass FileHandler:\n    def __init__(self, filename):\n        self.filename = filename\n        self.file = None\n\n    def __enter__(self):\n        self.file = open(self.filename, 'w')\n        logging.info(f\"Opened file {self.filename}\")\n        return self.file\n\n    def __exit__(self, exc_type, exc_value, traceback):\n        if self.file:\n            self.file.close()\n            logging.info(f\"Closed file {self.filename}\")\n\n# Example usage of the context manager\nwith FileHandler('example.txt') as f:\n    f.write('Hello, world!')\n\nclass DatabaseConnection:\n    def __init__(self, dsn):\n        self.dsn = dsn\n        self.connection = None\n\n    def __enter__(self):", "suffix": "\n\n    def __exit__(self, exc_type, exc_value, traceback):\n        if self.connection:\n            logging.info(f\"Disconnecting from database {self.dsn}\")\n\n# Example usage of the context manager\nwith DatabaseConnection('my_database') as conn:\n    pass\n\n# Assertions to verify both pattern adherence and functionality\nassert os.path.exists('example.txt')\n\n", "golden_completion": "        self.connection = 'mock_connection'\n        logging.info(f\"Connecting to database {self.dsn}\")\n        return self.connection", "LLM_justification": "This example tests the LLM's ability to recognize and continue the pattern of implementing context managers in Python. The prompt provides a complete context manager (FileHandler) for handling file operations and starts another context manager (DatabaseConnection) for database operations. The completion involves correctly implementing the __enter__ method to match the pattern established by the FileHandler class. The example also includes proper logging, resource cleanup, and assertions to ensure the context manager's functionality and pattern adherence.", "assertions": "assert os.path.exists('example.txt')\n\n# Simulate the context manager's usage and check for expected log messages\nwith DatabaseConnection('my_database') as conn:\n    assert conn == 'mock_connection'\n\n# Cleanup resources\nos.remove('example.txt')", "DeepSeek-V3-0324_completion_0": "        self.connection = connect(self.dsn)\n        logging.info(f\"Connected to database {self.dsn}\")\n        return self.connection", "DeepSeek-V3-0324_completion_1": "        self.connection = connect(self.dsn)\n        logging.info(f\"Connected to database {self.dsn}\")\n        return self.connection", "DeepSeek-V3-0324_completion_2": "        self.connection = connect(self.dsn)\n        logging.info(f\"Connected to database {self.dsn}\")\n        return self.connection", "DeepSeek-V3-0324_completion_3": "        self.connection = connect(self.dsn)\n        logging.info(f\"Connected to database {self.dsn}\")\n        return self.connection\n            self.connection.close()", "DeepSeek-V3-0324_completion_4": "        self.connection = connect(self.dsn)\n        logging.info(f\"Connected to database {self.dsn}\")\n        return self.connection", "DeepSeek-V3-0324_completions": ["        self.connection = connect(self.dsn)\n        logging.info(f\"Connected to database {self.dsn}\")\n        return self.connection", "        self.connection = connect(self.dsn)\n        logging.info(f\"Connected to database {self.dsn}\")\n        return self.connection", "        self.connection = connect(self.dsn)\n        logging.info(f\"Connected to database {self.dsn}\")\n        return self.connection", "        self.connection = connect(self.dsn)\n        logging.info(f\"Connected to database {self.dsn}\")\n        return self.connection\n            self.connection.close()", "        self.connection = connect(self.dsn)\n        logging.info(f\"Connected to database {self.dsn}\")\n        return self.connection"]}
{"id": "10", "testsource": "devbench-pattern-matching", "language": "python", "prefix": "import sqlite3\n\nclass DatabaseHandler:\n    def __init__(self, db_name):\n        self.db_name = db_name\n\n    def __enter__(self):\n        self.conn = sqlite3.connect(self.db_name)\n        self.cursor = self.conn.cursor()\n        return self\n\n    def __exit__(self, exc_type, exc_val, exc_tb):\n        if exc_type is not None:\n            self.conn.rollback()\n        else:\n            self.conn.commit()\n        self.conn.close()\n\n# Using the context manager to insert data\nwith DatabaseHandler('test.db') as db:\n    db.cursor.execute('''CREATE TABLE IF NOT EXISTS users (id INTEGER PRIMARY KEY, name TEXT)''')\n    db.cursor.execute('''INSERT INTO users (name) VALUES ('Alice')''')\n    db.cursor.execute('''INSERT INTO users (name) VALUES ('Bob')''')\n\n# Verifying data insertion", "suffix": "    name = result[0]\n\nimport os\nos.remove('test.db')", "golden_completion": "with DatabaseHandler('test.db') as db:\n    db.cursor.execute('''SELECT name FROM users WHERE name = 'Alice' ''')\n    result = db.cursor.fetchone()\n", "LLM_justification": "This example tests the LLM's ability to recognize and complete the pattern of using a context manager for database operations. The context manager pattern is established in the prompt and followed in the golden completion. The completion requires the LLM to correctly use the context manager to query the database and validate the results. The assertions test the functional correctness of data insertion and retrieval.", "assertions": "\nassert name == 'Alice'", "DeepSeek-V3-0324_completion_0": "with DatabaseHandler('test.db') as db:\n    db.cursor.execute('''SELECT name FROM users WHERE id = 1''')\n    result = db.cursor.fetchone()\n    name = result[0]", "DeepSeek-V3-0324_completion_1": "with DatabaseHandler('test.db') as db:\n    db.cursor.execute('''SELECT name FROM users WHERE id = 1''')\n    result = db.cursor.fetchone()", "DeepSeek-V3-0324_completion_2": "with DatabaseHandler('test.db') as db:\n    db.cursor.execute('''SELECT name FROM users WHERE id = 1''')\n    result = db.cursor.fetchone()\n    name = result[0]", "DeepSeek-V3-0324_completion_3": "with DatabaseHandler('test.db') as db:\n    db.cursor.execute('''SELECT name FROM users WHERE id = 1''')\n    result = db.cursor.fetchone()\n    name = result[0]", "DeepSeek-V3-0324_completion_4": "with DatabaseHandler('test.db') as db:\n    db.cursor.execute('''SELECT name FROM users WHERE id = 1''')\n    result = db.cursor.fetchone()\n    name = result[0]", "DeepSeek-V3-0324_completions": ["with DatabaseHandler('test.db') as db:\n    db.cursor.execute('''SELECT name FROM users WHERE id = 1''')\n    result = db.cursor.fetchone()\n    name = result[0]", "with DatabaseHandler('test.db') as db:\n    db.cursor.execute('''SELECT name FROM users WHERE id = 1''')\n    result = db.cursor.fetchone()", "with DatabaseHandler('test.db') as db:\n    db.cursor.execute('''SELECT name FROM users WHERE id = 1''')\n    result = db.cursor.fetchone()\n    name = result[0]", "with DatabaseHandler('test.db') as db:\n    db.cursor.execute('''SELECT name FROM users WHERE id = 1''')\n    result = db.cursor.fetchone()\n    name = result[0]", "with DatabaseHandler('test.db') as db:\n    db.cursor.execute('''SELECT name FROM users WHERE id = 1''')\n    result = db.cursor.fetchone()\n    name = result[0]"]}
{"id": "11", "testsource": "devbench-pattern-matching", "language": "python", "prefix": "import logging\n\nclass NetworkMonitor:\n    def __init__(self, log_file):\n        self.log_file = log_file\n        self.setup_logger()\n\n    def setup_logger(self):\n        self.logger = logging.getLogger('network_monitor')\n        self.logger.setLevel(logging.INFO)\n        handler = logging.FileHandler(self.log_file)\n        handler.setFormatter(logging.Formatter('%(asctime)s - %(message)s'))\n        self.logger.addHandler(handler)\n\n    def log_event(self, event):\n        self.logger.info(event)\n\n    def monitor(self, events):\n        for event in events:\n", "suffix": "            if 'error' in event.lower():\n                self.log_event(f\"Error detected: {event}\")\n            else:\n                self.log_event(f\"Event: {event}\")\n\n    def close(self):\n        # Close all handlers\n        handlers = self.logger.handlers[:]\n        for handler in handlers:\n            handler.close()\n            self.logger.removeHandler(handler)\n\n# Example usage\nmonitor = NetworkMonitor('network.log')\nmonitor.monitor(['Connection established', 'Error: Connection lost', 'Data received'])\n\n# Assertions\nwith open('network.log', 'r') as log_file:\n    log_contents = log_file.read()\n    assert 'Connection established' in log_contents\n    assert 'Error detected: Error: Connection lost' in log_contents\n    assert 'Data received' in log_contents\n\n# Close the logger before removing the file\nmonitor.close()\n\n# Clean up\nimport os\nos.remove('network.log')\n", "golden_completion": "            if 'connection' in event.lower():\n                self.log_event(f\"Connection event: {event}\")\n", "LLM_justification": "This is a good test case as it involves a common pattern in system operations, specifically logging and monitoring network events. The code sets up a logger and processes events, categorizing them based on their content. The completion requires recognizing the pattern of logging different types of events and continuing it in a meaningful way. The assertions check that the log file contains the expected entries, validating both functionality and pattern adherence.", "assertions": "monitor = NetworkMonitor('network.log')\nmonitor.monitor(['Connection established', 'Error: Connection lost', 'Data received'])\n\nwith open('network.log', 'r') as log_file:\n    log_contents = log_file.read()\n    assert 'Connection event: Connection established' in log_contents\n    assert 'Error detected: Error: Connection lost' in log_contents\n    assert 'Event: Data received' in log_contents\n\n# Close the logger before removing the file\nmonitor.close()\n\nimport os\nos.remove('network.log')\n", "DeepSeek-V3-0324_completion_0": "            if 'error' in event.lower():\n                self.log_event(f\"Error detected: {event}\")\n            else:\n                self.log_event(f\"Event: {event}\")", "DeepSeek-V3-0324_completion_1": "            if 'error' in event.lower():\n                self.log_event(f\"Error detected: {event}\")\n            else:\n                self.log_event(f\"Event: {event}\")", "DeepSeek-V3-0324_completion_2": "            if 'error' in event.lower():\n                self.log_event(f\"Error detected: {event}\")\n            else:\n                self.log_event(f\"Event: {event}\")", "DeepSeek-V3-0324_completion_3": "            if 'error' in event.lower():\n                self.log_event(f\"Error detected: {event}\")\n            else:\n                self.log_event(f\"Event: {event}\")", "DeepSeek-V3-0324_completion_4": "\n            if 'error' in event.lower():\n                self.log_event(f\"Error detected: {event}\")\n            else:\n                self.log_event(f\"Event: {event}\")", "DeepSeek-V3-0324_completions": ["            if 'error' in event.lower():\n                self.log_event(f\"Error detected: {event}\")\n            else:\n                self.log_event(f\"Event: {event}\")", "            if 'error' in event.lower():\n                self.log_event(f\"Error detected: {event}\")\n            else:\n                self.log_event(f\"Event: {event}\")", "            if 'error' in event.lower():\n                self.log_event(f\"Error detected: {event}\")\n            else:\n                self.log_event(f\"Event: {event}\")", "            if 'error' in event.lower():\n                self.log_event(f\"Error detected: {event}\")\n            else:\n                self.log_event(f\"Event: {event}\")", "\n            if 'error' in event.lower():\n                self.log_event(f\"Error detected: {event}\")\n            else:\n                self.log_event(f\"Event: {event}\")"]}
{"id": "12", "testsource": "devbench-pattern-matching", "language": "python", "prefix": "import matplotlib.pyplot as plt\nimport numpy as np\n\nclass DataVisualizer:\n    def __init__(self, data):\n        self.data = data\n\n    def plot_histogram(self):\n        plt.hist(self.data)\n        plt.title('Histogram')\n        plt.xlabel('Value')\n        plt.ylabel('Frequency')\n        plt.show()\n\n    def plot_scatter(self, x, y):\n        plt.scatter(x, y)\n        plt.title('Scatter Plot')\n        plt.xlabel('X-axis')\n        plt.ylabel('Y-axis')\n        plt.show()\n\n    def plot_line(self, x, y):\n", "suffix": "        plt.title('Line Plot')\n        plt.xlabel('X-axis')\n        plt.ylabel('Y-axis')\n        plt.show()\n\n# Creating some sample data\ndata = np.random.randn(100)\nx = np.linspace(0, 10, 100)\ny = np.sin(x)\n\n# Creating an instance of DataVisualizer and plotting\nvisualizer = DataVisualizer(data)\nvisualizer.plot_histogram()\nvisualizer.plot_scatter(x, y)\nvisualizer.plot_line(x, y)\n", "golden_completion": "        plt.plot(x, y)\n", "LLM_justification": "This test case evaluates the LLM's ability to recognize and continue a pattern in object-oriented programming for plotting data using Matplotlib. The pattern involves creating methods within a class to plot different types of graphs and consistently using Matplotlib functions to do so. The golden completion demonstrates the correct continuation of this pattern by plotting a line graph with plt.plot(), matching the established pattern in the prefix and suffix.", "assertions": "assert isinstance(visualizer, DataVisualizer)\nassert hasattr(visualizer, 'plot_histogram')\nassert hasattr(visualizer, 'plot_scatter')\nassert hasattr(visualizer, 'plot_line')\nassert callable(visualizer.plot_histogram)\nassert callable(visualizer.plot_scatter)\nassert callable(visualizer.plot_line)\nvisualizer.plot_line(x, y) # This should generate a line plot without errors\n", "DeepSeek-V3-0324_completion_0": "        plt.plot(x, y)", "DeepSeek-V3-0324_completion_1": "        plt.plot(x, y)", "DeepSeek-V3-0324_completion_2": "        plt.plot(x, y)", "DeepSeek-V3-0324_completion_3": "        plt.plot(x, y)", "DeepSeek-V3-0324_completion_4": "        plt.plot(x, y)", "DeepSeek-V3-0324_completions": ["        plt.plot(x, y)", "        plt.plot(x, y)", "        plt.plot(x, y)", "        plt.plot(x, y)", "        plt.plot(x, y)"]}
{"id": "13", "testsource": "devbench-pattern-matching", "language": "python", "prefix": "class DataValidator:\n    def __init__(self, schema):\n        self.schema = schema\n\n    def validate(self, data):\n        errors = []\n        for key, value in data.items():\n            if key not in self.schema:\n                errors.append(f\"Unexpected key: {key}\")\n            elif not isinstance(value, self.schema[key]):\n                errors.append(f\"Invalid type for key: {key}\")\n", "suffix": "\n        return errors\n\ndata = {\"name\": \"John\", \"age\": 30, \"email\": \"john.doe@example.com\"}\nschema = {\"name\": str, \"age\": int}\n\nvalidator = DataValidator(schema)\nerrors = validator.validate(data)\n\nassert errors == [\"Unexpected key: email\"]\n\n# Cleanup resources if needed\n# No external resources to clean up in this example", "golden_completion": "        for key in self.schema:\n            if key not in data:\n                errors.append(f\"Missing key: {key}\")\n", "LLM_justification": "This test case involves data validation, a common scenario in data processing and API design. The prompt sets up a pattern for validating data against a schema, checking for unexpected keys and invalid types. The golden completion extends this pattern by adding a check for missing keys, which is a natural continuation of the validation logic. The assertions verify that the validator correctly identifies an unexpected key in the data. This scenario tests the LLM's ability to recognize and complete a data validation pattern while maintaining proper structure and functionality.", "assertions": "\nassert len(errors) == 1", "DeepSeek-V3-0324_completion_0": "        return errors", "DeepSeek-V3-0324_completion_1": "\n        elif not isinstance(value, self.schema[key]):\n            errors.append(f\"Invalid type for key: {key}\")", "DeepSeek-V3-0324_completion_2": "        return errors", "DeepSeek-V3-0324_completion_3": "        return errors", "DeepSeek-V3-0324_completion_4": "        return errors", "DeepSeek-V3-0324_completions": ["        return errors", "\n        elif not isinstance(value, self.schema[key]):\n            errors.append(f\"Invalid type for key: {key}\")", "        return errors", "        return errors", "        return errors"]}
{"id": "14", "testsource": "devbench-pattern-matching", "language": "python", "prefix": "import statistics\n\nclass DataAnalysis:\n    def __init__(self, data):\n        self.data = data\n\n    def mean(self):\n        return statistics.mean(self.data)\n\n    def median(self):\n        return statistics.median(self.data)\n\n    def mode(self):\n        return statistics.mode(self.data)\n\n    def variance(self):\n", "suffix": "\n\n# Test cases\nanalysis = DataAnalysis([1, 2, 3, 4, 4, 5, 5, 5])\nassert analysis.mean() == 3.625\nassert analysis.median() == 4\nassert analysis.mode() == 5\n", "golden_completion": "        return statistics.variance(self.data)\n", "LLM_justification": "This test case demonstrates a common pattern in scientific computing where statistical methods are implemented in a class to analyze data. The pattern of implementing statistical methods is established in the prefix with mean, median, and mode methods. The expected pattern continuation is to implement the variance method similarly. The provided assertions test the correctness of the methods and ensure the pattern is followed correctly. The suffix includes necessary cleanup code after the assertions.", "assertions": "assert analysis.mean() == 3.625\nassert analysis.median() == 4\nassert analysis.mode() == 5\nassert analysis.variance() == 2.267857142857143\n", "DeepSeek-V3-0324_completion_0": "        return statistics.variance(self.data)", "DeepSeek-V3-0324_completion_1": "        return statistics.variance(self.data)", "DeepSeek-V3-0324_completion_2": "        return statistics.variance(self.data)", "DeepSeek-V3-0324_completion_3": "        return statistics.variance(self.data)", "DeepSeek-V3-0324_completion_4": "        return statistics.variance(self.data)", "DeepSeek-V3-0324_completions": ["        return statistics.variance(self.data)", "        return statistics.variance(self.data)", "        return statistics.variance(self.data)", "        return statistics.variance(self.data)", "        return statistics.variance(self.data)"]}
{"id": "15", "testsource": "devbench-pattern-matching", "language": "python", "prefix": "import numpy as np\n\nclass MatrixOperations:\n    def __init__(self, matrix):\n        self.matrix = matrix\n\n    def transpose(self):\n        return np.transpose(self.matrix)\n\n    def invert(self):\n        return np.linalg.inv(self.matrix)\n\n    # Add a method to calculate the determinant of the matrix\n    def determinant(self):", "suffix": "\n\n# Testing the MatrixOperations class\nmatrix = np.array([[1, 2], [3, 4]])\noperations = MatrixOperations(matrix)\n\n# Transpose test\ntranspose_result = operations.transpose()\nassert np.array_equal(transpose_result, np.array([[1, 3], [2, 4]])), 'Transpose test failed'\n\n# Inversion test\ninvert_result = operations.invert()\nassert np.allclose(invert_result, np.array([[-2. ,  1. ], [ 1.5, -0.5]])), 'Inversion test failed'\n\n# Determinant test\ntry:\n    determinant_result = operations.determinant()\n    assert np.isclose(determinant_result, -2.0), 'Determinant test failed'\nexcept np.linalg.LinAlgError:\n    print(\"Determinant test failed: Matrix is not invertible\")", "golden_completion": "\n        return np.linalg.det(self.matrix)", "LLM_justification": "This test case is a good example of OOP patterns in the context of scientific computing. The MatrixOperations class encapsulates common matrix operations like transposition, inversion, and determinant calculation. This scenario tests the LLM's ability to recognize the pattern of adding a new method to an existing class and implementing it using numpy functions. The completion must adhere to the pattern established by the transpose and invert methods. The assertions check the correctness of the transpose, invert, and determinant methods, ensuring the implementation follows the expected pattern and produces correct results. Cleanup is handled after the assertions to maintain resource integrity.", "assertions": "assert np.array_equal(transpose_result, np.array([[1, 3], [2, 4]])), 'Transpose test failed'\nassert np.allclose(invert_result, np.array([[-2. ,  1. ], [ 1.5, -0.5]])), 'Inversion test failed'\nassert np.isclose(determinant_result, -2.0), 'Determinant test failed'", "DeepSeek-V3-0324_completion_0": "        return np.linalg.det(self.matrix)", "DeepSeek-V3-0324_completion_1": "        return np.linalg.det(self.matrix)", "DeepSeek-V3-0324_completion_2": "        return np.linalg.det(self.matrix)", "DeepSeek-V3-0324_completion_3": "        return np.linalg.det(self.matrix)", "DeepSeek-V3-0324_completion_4": "        return np.linalg.det(self.matrix)", "DeepSeek-V3-0324_completions": ["        return np.linalg.det(self.matrix)", "        return np.linalg.det(self.matrix)", "        return np.linalg.det(self.matrix)", "        return np.linalg.det(self.matrix)", "        return np.linalg.det(self.matrix)"]}
{"id": "16", "testsource": "devbench-pattern-matching", "language": "python", "prefix": "import re\n\nclass DataValidator:\n    def __init__(self, schema):\n        self.schema = schema\n\n    def validate(self, data):\n        errors = []\n        for field, rules in self.schema.items():\n            value = data.get(field)\n            if 'required' in rules and value is None:\n                errors.append(f\"{field} is required.\")\n            if 'type' in rules and value is not None and not isinstance(value, rules['type']):\n                errors.append(f\"{field} must be of type {rules['type'].__name__}.\")\n            if 'regex' in rules and value is not None and not re.match(rules['regex'], value):\n                errors.append(f\"{field} does not match the required pattern.\")\n", "suffix": "        return errors\n\nschema = {\n    'username': {'required': True, 'type': str, 'regex': r'^[a-zA-Z0-9_]{3,30}$'},\n    'age': {'required': True, 'type': int},\n    'email': {'required': False, 'type': str, 'regex': r'^[\\w\\.-]+@[\\w\\.-]+\\.\\w+$'}\n}\n\nvalidator = DataValidator(schema)\n\n# Example data to validate\nvalid_data = {'username': 'test_user', 'age': 25, 'email': 'test@example.com'}\ninvalid_data = {'username': 'tu', 'age': 'twenty', 'email': 'invalid-email'}\n\n# Assertions to verify the functionality\nassert validator.validate(valid_data) == [], \"Valid data should have no errors\"\nassert 'username is required.' in validator.validate({'age': 25}), \"Missing username should be flagged\"\nassert 'age must be of type int.' in validator.validate({'username': 'user', 'age': 'twenty'}), \"Invalid age type should be flagged\"\nassert 'email does not match the required pattern.' in validator.validate({'username': 'user', 'age': 25, 'email': 'invalid-email'}), \"Invalid email should be flagged\"\n", "golden_completion": "            if 'custom' in rules and value is not None and not rules['custom'](value):\n                errors.append(f\"{field} failed custom validation.\")\n", "LLM_justification": "This scenario tests the LLM's ability to recognize and complete a pattern related to data validation. The pattern involves checking various conditions in a schema-driven validation class. The completion involves adding support for custom validation rules, which is a common pattern in data validation frameworks. The assertions ensure that the validator correctly identifies valid and invalid data based on the schema, including the new custom validation rule.", "assertions": "assert validator.validate({'username': 'valid_user', 'age': 30, 'email': 'valid@example.com'}) == [], \"All fields valid\"\n\nschema_with_custom = {\n    'username': {\n        'required': True, \n        'type': str, \n        'regex': r'^[a-zA-Z0-9_]{3,30}$',\n        'custom': lambda x: x == 'valid_user'  # Custom validation rule\n    },\n    'age': {'required': True, 'type': int},\n    'email': {'required': False, 'type': str, 'regex': r'^[\\w\\.-]+@[\\w\\.-]+\\.\\w+$'}\n}\n\nvalidator_with_custom = DataValidator(schema_with_custom)\n\nassert 'username failed custom validation.' in validator_with_custom.validate(\n    {'username': 'invalid_user', 'age': 30, 'email': 'valid@example.com'}\n), \"Custom validation should be flagged\"", "DeepSeek-V3-0324_completion_0": "            if 'min' in rules and value is not None and value < rules['min']:\n                errors.append(f\"{field} must be at least {rules['min']}.\")\n            if 'max' in rules and value is not None and value > rules['max']:\n                errors.append(f\"{field} must be at most {rules['max']}.\")", "DeepSeek-V3-0324_completion_1": "            if 'min' in rules and value is not None and isinstance(value, (int, float)) and value < rules['min']:\n                errors.append(f\"{field} must be at least {rules['min']}.\")\n            if 'max' in rules and value is not None and isinstance(value, (int, float)) and value > rules['max']:\n                errors.append(f\"{field} must be at most {rules['max']}.\")", "DeepSeek-V3-0324_completion_2": "            if 'min' in rules and value is not None and value < rules['min']:\n                errors.append(f\"{field} must be at least {rules['min']}.\")\n            if 'max' in rules and value is not None and value > rules['max']:\n                errors.append(f\"{field} must be at most {rules['max']}.\")", "DeepSeek-V3-0324_completion_3": "            if 'min' in rules and value is not None and value < rules['min']:\n                errors.append(f\"{field} must be at least {rules['min']}.\")\n            if 'max' in rules and value is not None and value > rules['max']:\n                errors.append(f\"{field} must be at most {rules['max']}.\")", "DeepSeek-V3-0324_completion_4": "            if 'min' in rules and value is not None and value < rules['min']:\n                errors.append(f\"{field} must be at least {rules['min']}.\")\n            if 'max' in rules and value is not None and value > rules['max']:\n                errors.append(f\"{field} must be at most {rules['max']}.\")", "DeepSeek-V3-0324_completions": ["            if 'min' in rules and value is not None and value < rules['min']:\n                errors.append(f\"{field} must be at least {rules['min']}.\")\n            if 'max' in rules and value is not None and value > rules['max']:\n                errors.append(f\"{field} must be at most {rules['max']}.\")", "            if 'min' in rules and value is not None and isinstance(value, (int, float)) and value < rules['min']:\n                errors.append(f\"{field} must be at least {rules['min']}.\")\n            if 'max' in rules and value is not None and isinstance(value, (int, float)) and value > rules['max']:\n                errors.append(f\"{field} must be at most {rules['max']}.\")", "            if 'min' in rules and value is not None and value < rules['min']:\n                errors.append(f\"{field} must be at least {rules['min']}.\")\n            if 'max' in rules and value is not None and value > rules['max']:\n                errors.append(f\"{field} must be at most {rules['max']}.\")", "            if 'min' in rules and value is not None and value < rules['min']:\n                errors.append(f\"{field} must be at least {rules['min']}.\")\n            if 'max' in rules and value is not None and value > rules['max']:\n                errors.append(f\"{field} must be at most {rules['max']}.\")", "            if 'min' in rules and value is not None and value < rules['min']:\n                errors.append(f\"{field} must be at least {rules['min']}.\")\n            if 'max' in rules and value is not None and value > rules['max']:\n                errors.append(f\"{field} must be at most {rules['max']}.\")"]}
{"id": "17", "testsource": "devbench-pattern-matching", "language": "python", "prefix": "import re\n\nclass DataValidator:\n    def __init__(self, schema):\n        self.schema = schema\n\n    def validate(self, data):\n        errors = []\n        for field, constraints in self.schema.items():\n            value = data.get(field)\n            if 'type' in constraints and not isinstance(value, constraints['type']):\n                errors.append(f\"Field '{field}' should be of type {constraints['type'].__name__}\")\n            if 'regex' in constraints and not re.match(constraints['regex'], value):\n                errors.append(f\"Field '{field}' does not match pattern {constraints['regex']}\")\n", "suffix": "        if errors:\n            raise ValueError(f\"Validation errors: {', '.join(errors)}\")\n        return True\n\nschema = {\n    'name': {'type': str, 'regex': r'^[A-Za-z ]+$'},\n    'age': {'type': int, 'min': 0, 'max': 120}\n}\ndata = {'name': 'John Doe', 'age': 30}\nvalidator = DataValidator(schema)\nassert validator.validate(data) == True\n\ninvalid_data = {'name': 'John123', 'age': 150}\ntry:\n    validator.validate(invalid_data)\nexcept ValueError as e:\n    assert str(e) == \"Validation errors: Field 'name' does not match pattern ^[A-Za-z ]+$, Field 'age' should be at most 120\"\nfinally:\n    print('Validation test completed')", "golden_completion": "            if 'min' in constraints and value < constraints['min']:\n                errors.append(f\"Field '{field}' should be at least {constraints['min']}\")\n            if 'max' in constraints and value > constraints['max']:\n                errors.append(f\"Field '{field}' should be at most {constraints['max']}\")\n", "LLM_justification": "This example tests the LLM's ability to recognize and complete a pattern in the context of data validation within an OOP structure. The prompt sets up a class for validating data against a schema, and the completion requires the LLM to correctly add validation for minimum and maximum constraints. The pattern involves iterating over schema constraints and checking each one, which is a common real-world task in data validation. The assertions verify that the implementation correctly handles valid and invalid data cases, ensuring that both the pattern and functionality are correct.", "assertions": "assert validator.validate({'name': 'Alice', 'age': 25}) == True\ntry:\n    validator.validate({'name': 'Alice', 'age': -5})\nexcept ValueError as e:\n    assert str(e) == \"Validation errors: Field 'age' should be at least 0\"\ntry:\n    validator.validate({'name': 'Alice', 'age': 130})\nexcept ValueError as e:\n    assert str(e) == \"Validation errors: Field 'age' should be at most 120\"\n", "DeepSeek-V3-0324_completion_0": "            if 'min' in constraints and value < constraints['min']:\n                errors.append(f\"Field '{field}' should be at least {constraints['min']}\")\n            if 'max' in constraints and value > constraints['max']:\n                errors.append(f\"Field '{field}' should be at most {constraints['max']}\")", "DeepSeek-V3-0324_completion_1": "            if 'min' in constraints and value < constraints['min']:\n                errors.append(f\"Field '{field}' should be at least {constraints['min']}\")\n            if 'max' in constraints and value > constraints['max']:\n                errors.append(f\"Field '{field}' should be at most {constraints['max']}\")", "DeepSeek-V3-0324_completion_2": "            if 'min' in constraints and value < constraints['min']:\n                errors.append(f\"Field '{field}' should be at least {constraints['min']}\")\n            if 'max' in constraints and value > constraints['max']:\n                errors.append(f\"Field '{field}' should be at most {constraints['max']}\")", "DeepSeek-V3-0324_completion_3": "            if 'min' in constraints and value < constraints['min']:\n                errors.append(f\"Field '{field}' should be at least {constraints['min']}\")\n            if 'max' in constraints and value > constraints['max']:\n                errors.append(f\"Field '{field}' should be at most {constraints['max']}\")", "DeepSeek-V3-0324_completion_4": "            if 'min' in constraints and value < constraints['min']:\n                errors.append(f\"Field '{field}' should be at least {constraints['min']}\")\n            if 'max' in constraints and value > constraints['max']:\n                errors.append(f\"Field '{field}' should be at most {constraints['max']}\")", "DeepSeek-V3-0324_completions": ["            if 'min' in constraints and value < constraints['min']:\n                errors.append(f\"Field '{field}' should be at least {constraints['min']}\")\n            if 'max' in constraints and value > constraints['max']:\n                errors.append(f\"Field '{field}' should be at most {constraints['max']}\")", "            if 'min' in constraints and value < constraints['min']:\n                errors.append(f\"Field '{field}' should be at least {constraints['min']}\")\n            if 'max' in constraints and value > constraints['max']:\n                errors.append(f\"Field '{field}' should be at most {constraints['max']}\")", "            if 'min' in constraints and value < constraints['min']:\n                errors.append(f\"Field '{field}' should be at least {constraints['min']}\")\n            if 'max' in constraints and value > constraints['max']:\n                errors.append(f\"Field '{field}' should be at most {constraints['max']}\")", "            if 'min' in constraints and value < constraints['min']:\n                errors.append(f\"Field '{field}' should be at least {constraints['min']}\")\n            if 'max' in constraints and value > constraints['max']:\n                errors.append(f\"Field '{field}' should be at most {constraints['max']}\")", "            if 'min' in constraints and value < constraints['min']:\n                errors.append(f\"Field '{field}' should be at least {constraints['min']}\")\n            if 'max' in constraints and value > constraints['max']:\n                errors.append(f\"Field '{field}' should be at most {constraints['max']}\")"]}
{"id": "18", "testsource": "devbench-pattern-matching", "language": "python", "prefix": "class DataValidator:\n    def __init__(self, schema):\n        self.schema = schema\n\n    def validate(self, data):\n        errors = []\n        for field, rules in self.schema.items():\n            if field not in data:\n                errors.append(f'Missing field: {field}')\n            else:\n                value = data[field]\n                for rule, expected in rules.items():\n                    if rule == 'type' and not isinstance(value, expected):\n                        errors.append(f'Field {field} should be of type {expected.__name__}')\n                    elif rule == 'min_length' and len(value) < expected:\n                        errors.append(f'Field {field} should be at least {expected} characters long')\n", "suffix": "        return errors\n\nschema = {\n    'name': {'type': str, 'min_length': 3},\n    'age': {'type': int}\n}\n\nvalidator = DataValidator(schema)\ndata_valid = {'name': 'Alice', 'age': 30}\ndata_invalid = {'name': 'Al', 'age': 'thirty'}\n\nerrors_valid = validator.validate(data_valid)\nerrors_invalid = validator.validate(data_invalid)\n\nassert errors_valid == []\nassert errors_invalid == ['Field name should be at least 3 characters long', 'Field age should be of type int']\n\nprint('All assertions passed!')", "golden_completion": "                    elif rule == 'max_length' and len(value) > expected:\n                        errors.append(f'Field {field} should be at most {expected} characters long')\n", "LLM_justification": "This example tests the ability to recognize and continue a pattern within a data validation context. The pattern involves iterating over schema rules and applying them to the data fields. The golden completion correctly continues this pattern by adding a check for a new rule, 'max_length', which is consistent with the existing 'type' and 'min_length' rules. The assertions ensure that the validation logic works as expected, verifying both the pattern and functionality.", "assertions": "schema = {\n    'name': {'type': str, 'min_length': 3, 'max_length': 10},\n    'age': {'type': int}\n}\n\nvalidator = DataValidator(schema)\ndata_valid = {'name': 'Alice', 'age': 30}\ndata_invalid_length = {'name': 'Aliceeeeeeee', 'age': 30}\ndata_invalid_type = {'name': 'Alice', 'age': 'thirty'}\n\nerrors_valid = validator.validate(data_valid)\nerrors_invalid_length = validator.validate(data_invalid_length)\nerrors_invalid_type = validator.validate(data_invalid_type)\n\nassert errors_valid == []\nassert errors_invalid_length == ['Field name should be at most 10 characters long']\nassert errors_invalid_type == ['Field age should be of type int']", "DeepSeek-V3-0324_completion_0": "                    elif rule == 'max_length' and len(value) > expected':\n                        errors.append(f'Field {field} should be at most {expected} characters long')", "DeepSeek-V3-0324_completion_1": "                    elif rule == 'max_length' and len(value) > expected:\n                        errors.append(f'Field {field} should be at most {expected} characters long')\n                    elif rule == 'required' and not value:\n                        errors.append(f'Field {field} is required')", "DeepSeek-V3-0324_completion_2": "                    elif rule == 'max_length' and len(value) > expected:\n                        errors.append(f'Field {field} should be at most {expected} characters long')\n                    elif rule == 'required' and not value:\n                        errors.append(f'Field {field} is required')", "DeepSeek-V3-0324_completion_3": "                    elif rule == 'max_length' and len(value) > expected:\n                        errors.append(f'Field {field} should be at most {expected} characters long')\n                    elif rule == 'required' and not value:\n                        errors.append(f'Field {field} is required')", "DeepSeek-V3-0324_completion_4": "                    elif rule == 'max_length' and len(value) > expected:\n                        errors.append(f'Field {field} should be at most {expected} characters long')\n                    elif rule == 'required' and not value:\n                        errors.append(f'Field {field} is required')", "DeepSeek-V3-0324_completions": ["                    elif rule == 'max_length' and len(value) > expected':\n                        errors.append(f'Field {field} should be at most {expected} characters long')", "                    elif rule == 'max_length' and len(value) > expected:\n                        errors.append(f'Field {field} should be at most {expected} characters long')\n                    elif rule == 'required' and not value:\n                        errors.append(f'Field {field} is required')", "                    elif rule == 'max_length' and len(value) > expected:\n                        errors.append(f'Field {field} should be at most {expected} characters long')\n                    elif rule == 'required' and not value:\n                        errors.append(f'Field {field} is required')", "                    elif rule == 'max_length' and len(value) > expected:\n                        errors.append(f'Field {field} should be at most {expected} characters long')\n                    elif rule == 'required' and not value:\n                        errors.append(f'Field {field} is required')", "                    elif rule == 'max_length' and len(value) > expected:\n                        errors.append(f'Field {field} should be at most {expected} characters long')\n                    elif rule == 'required' and not value:\n                        errors.append(f'Field {field} is required')"]}
{"id": "19", "testsource": "devbench-pattern-matching", "language": "python", "prefix": "import requests\n\nclass APIClient:\n    def __init__(self, base_url):\n        self.base_url = base_url\n\n    def get_data(self, endpoint):\n        url = f\"{self.base_url}/{endpoint}\"\n        response = requests.get(url)\n        response.raise_for_status()\n        return response.json()\n\n    def post_data(self, endpoint, data):\n        url = f\"{self.base_url}/{endpoint}\"\n        response = requests.post(url, json=data)\n        response.raise_for_status()\n        return response.json()\n\n    def delete_data(self, endpoint):\n", "suffix": "        response = requests.delete(url)\n        response.raise_for_status()\n        return response.json()\n\nclient = APIClient(\"https://jsonplaceholder.typicode.com\")\n\nresponse = client.get_data(\"posts/1\")\nprint(f\"GET response: {response}\")\nassert \"id\" in response\nassert \"title\" in response\n\n# Test the post_data method\ndata = {\"title\": \"foo\", \"body\": \"bar\", \"userId\": 1}\nresponse = client.post_data(\"posts\", data)\nprint(f\"POST response: {response}\")\nassert response[\"title\"] == \"foo\"\nassert \"id\" in response\n\n# Test the delete_data method\nresponse = client.delete_data(\"posts/1\")\nprint(f\"DELETE response: {response}\")\nassert isinstance(response, dict)\n", "golden_completion": "        url = f\"{self.base_url}/{endpoint}\"\n", "LLM_justification": "This example tests the LLM's ability to recognize and complete a pattern involving API endpoint construction in an OOP context. The base URL is combined with the endpoint to form the full URL for the request, and the LLM needs to apply this pattern consistently across different HTTP methods. The completion should demonstrate understanding of this pattern by correctly forming the URL for the DELETE request, similar to GET and POST methods. The assertions verify that the pattern is applied correctly and that the methods function as expected.", "assertions": "assert client.base_url == \"https://jsonplaceholder.typicode.com\"\nassert \"name\" in client.get_data(\"users/1\")\nassert \"body\" in client.get_data(\"comments/1\")", "DeepSeek-V3-0324_completion_0": "        url = f\"{self.base_url}/{endpoint}\"", "DeepSeek-V3-0324_completion_1": "        url = f\"{self.base_url}/{endpoint}\"", "DeepSeek-V3-0324_completion_2": "        url = f\"{self.base_url}/{endpoint}\"", "DeepSeek-V3-0324_completion_3": "        url = f\"{self.base_url}/{endpoint}\"", "DeepSeek-V3-0324_completion_4": "        url = f\"{self.base_url}/{endpoint}\"", "DeepSeek-V3-0324_completions": ["        url = f\"{self.base_url}/{endpoint}\"", "        url = f\"{self.base_url}/{endpoint}\"", "        url = f\"{self.base_url}/{endpoint}\"", "        url = f\"{self.base_url}/{endpoint}\"", "        url = f\"{self.base_url}/{endpoint}\""]}
{"id": "20", "testsource": "devbench-pattern-matching", "language": "python", "prefix": "import requests\nfrom requests.exceptions import HTTPError\n\ndef fetch_data(url):\n    try:\n        response = requests.get(url)\n        response.raise_for_status()\n        data = response.json()\n", "suffix": "    except HTTPError as http_err:\n        print(f'HTTP error occurred: {http_err}')\n    except Exception as err:\n        print(f'Other error occurred: {err}')\n    else:\n        return data\n\n# Test cases\nurl = 'https://jsonplaceholder.typicode.com/todos/1'\ndata = fetch_data(url)\nassert isinstance(data, dict), 'Expected data to be a dictionary'\nassert 'userId' in data, 'Expected key userId in data'\nassert 'title' in data, 'Expected key title in data'\nassert data['id'] == 1, 'Expected id to be 1'\n\n# Cleanup\nprint('Finished testing')", "golden_completion": "    except ValueError as json_err:\n        print(f'JSON error occurred: {json_err}')\n", "LLM_justification": "This test case checks the LLM's ability to recognize and complete a common error handling pattern in network protocols. The provided prompt sets up a try block that handles potential errors from a network request. The golden completion adds an additional specific exception handling for JSON parsing errors, which is a realistic enhancement when fetching and processing data from an API. The test verifies functional correctness by making an actual request and checking the structure of the returned data. This scenario is practical and covers error handling, API interaction, and proper use of assertions.", "assertions": "url = 'https://jsonplaceholder.typicode.com/todos/1'\ndata = fetch_data(url)\nassert isinstance(data, dict), 'Expected data to be a dictionary'\nassert 'userId' in data, 'Expected key userId in data'\nassert 'title' in data, 'Expected key title in data'\nassert data['id'] == 1, 'Expected id to be 1'\n", "DeepSeek-V3-0324_completion_0": "        return data", "DeepSeek-V3-0324_completion_1": "        return data", "DeepSeek-V3-0324_completion_2": "        return data", "DeepSeek-V3-0324_completion_3": "        return data", "DeepSeek-V3-0324_completion_4": "        return data", "DeepSeek-V3-0324_completions": ["        return data", "        return data", "        return data", "        return data", "        return data"]}
{"id": "21", "testsource": "devbench-pattern-matching", "language": "python", "prefix": "import requests\nclass APIClient:\n    def __init__(self, base_url):\n        self.base_url = base_url\n\n    def get(self, endpoint):\n        response = requests.get(f\"{self.base_url}/{endpoint}\")\n        if response.status_code == 200:\n            return response.json()\n        else:\n            response.raise_for_status()\n\nclass AnalyticsClient(APIClient):\n    def __init__(self, base_url, api_key=None):\n        super().__init__(base_url)\n        self.api_key = api_key\n\n    def get_metrics(self, metric_type):\n        response = requests.get(f\"{self.base_url}/posts/{metric_type}\")\n        if response.status_code == 200:\n            return response.json()\n        else:\n            response.raise_for_status()\n\n    def get_report(self, report_id):\n", "suffix": "\n\n# Example usage:\nclient = AnalyticsClient(\"https://jsonplaceholder.typicode.com\")\n\ntry:\n    metrics = client.get_metrics(\"1\")\n    print(f\"Metrics result: {metrics}\")\n\n    report = client.get_report(\"1\")\n    print(f\"Report result: {report}\")\n\n    users = client.get(\"users/1\")\n    print(f\"User result: {users}\")\n\nexcept requests.exceptions.RequestException as e:\n    print(f\"API request failed: {e}\")\n\n# Assertions:\nimport unittest.mock as mock\n\nwith mock.patch('requests.get') as mock_get:\n    mock_response = mock.Mock()\n    mock_response.status_code = 200\n    mock_response.json.return_value = {'data': 'mocked'}\n    mock_get.return_value = mock_response\n\n    assert client.get_metrics(\"daily\") == {'data': 'mocked'}\n    assert client.get_report(\"12345\") == {'data': 'mocked'}\n\n", "golden_completion": "        response = requests.get(f\"{self.base_url}/comments/{report_id}\")\n        if response.status_code == 200:\n            return response.json()\n        else:\n            response.raise_for_status()\n", "LLM_justification": "This test case is a realistic example of API client patterns for an analytics context. The pattern involves making authenticated HTTP requests and handling responses based on status codes. The `golden_completion` follows the established pattern of making a request with headers, checking the status code, and returning JSON data or raising an error. The assertions verify that the pattern is correctly implemented and handles expected responses.", "assertions": "try:\n    post = client.get_metrics(\"1\")\n    assert \"title\" in post\n    assert \"body\" in post\n    assert \"userId\" in post\n\n    comment = client.get_report(\"1\")\n    assert \"name\" in comment\n    assert \"email\" in comment\n    assert \"body\" in comment\n\n    print(\"All tests passed!\")\nexcept Exception as e:\n    print(f\"Test failed: {e}\")", "DeepSeek-V3-0324_completion_0": "        response = requests.get(f\"{self.base_url}/reports/{report_id}\")\n        if response.status_code == 200:\n            return response.json()\n        else:\n            response.raise_for_status()", "DeepSeek-V3-0324_completion_1": "        response = requests.get(f\"{self.base_url}/reports/{report_id}\")\n        if response.status_code == 200:\n            return response.json()\n        else:\n            response.raise_for_status()", "DeepSeek-V3-0324_completion_2": "        response = requests.get(f\"{self.base_url}/reports/{report_id}\")\n        if response.status_code == 200:\n            return response.json()\n        else:\n            response.raise_for_status()", "DeepSeek-V3-0324_completion_3": "        response = requests.get(f\"{self.base_url}/reports/{report_id}\")\n        if response.status_code == 200:\n            return response.json()\n        else:\n            response.raise_for_status()", "DeepSeek-V3-0324_completion_4": "        response = requests.get(f\"{self.base_url}/reports/{report_id}\")\n        if response.status_code == 200:\n            return response.json()\n        else:\n            response.raise_for_status()", "DeepSeek-V3-0324_completions": ["        response = requests.get(f\"{self.base_url}/reports/{report_id}\")\n        if response.status_code == 200:\n            return response.json()\n        else:\n            response.raise_for_status()", "        response = requests.get(f\"{self.base_url}/reports/{report_id}\")\n        if response.status_code == 200:\n            return response.json()\n        else:\n            response.raise_for_status()", "        response = requests.get(f\"{self.base_url}/reports/{report_id}\")\n        if response.status_code == 200:\n            return response.json()\n        else:\n            response.raise_for_status()", "        response = requests.get(f\"{self.base_url}/reports/{report_id}\")\n        if response.status_code == 200:\n            return response.json()\n        else:\n            response.raise_for_status()", "        response = requests.get(f\"{self.base_url}/reports/{report_id}\")\n        if response.status_code == 200:\n            return response.json()\n        else:\n            response.raise_for_status()"]}
{"id": "22", "testsource": "devbench-pattern-matching", "language": "python", "prefix": "import socket\nimport unittest.mock as mock\n\nclass NetworkClient:\n    def __init__(self, host: str, port: int):\n        self.host = host\n        self.port = port\n        self.sock = None\n\n    def connect(self):\n        self.sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        self.sock.connect((self.host, self.port))\n\n    def send_message(self, message: str):\n        if not self.sock:\n            raise ConnectionError('Client is not connected')\n        self.sock.sendall(message.encode('utf-8'))\n\n    def receive_message(self):\n        if not self.sock:\n            raise ConnectionError('Client is not connected')\n", "suffix": "        return data.decode('utf-8')\n\n    def close(self):\n        if self.sock:\n            self.sock.close()\n            self.sock = None\n\n", "golden_completion": "        data = self.sock.recv(4096)\n", "LLM_justification": "This test case is a good example of pattern matching in the context of network protocols (APIs, messaging, sync/async) and error handling. The task is to complete the `receive_message` method by correctly implementing the pattern of receiving data from a socket connection. The pattern involves checking the connection, receiving data, and handling it appropriately. The assertions ensure that the client can connect, send, and receive messages correctly, adhering to the established pattern of socket communication.", "assertions": "with mock.patch('socket.socket') as mock_socket:\n    # Configure the mock socket\n    mock_socket_instance = mock.Mock()\n    mock_socket.return_value = mock_socket_instance\n\n    # Set up the receive method to return a predefined response\n    mock_socket_instance.recv.return_value = b'Hello, Server!'\n\n    client = NetworkClient('localhost', 8080)\n    client.connect()\n    client.send_message('Hello, Server!')\n\n    response = client.receive_message()\n    assert isinstance(response, str)\n    assert isinstance(response, str)\n    client.close()\n\n    # Verify the expected methods were called\n    mock_socket_instance.connect.assert_called_once_with(('localhost', 8080))\n    mock_socket_instance.sendall.assert_called_once()\n    mock_socket_instance.recv.assert_called_once_with(4096)\n    mock_socket_instance.close.assert_called_once()\n\n", "DeepSeek-V3-0324_completion_0": "        data = self.sock.recv(1024)", "DeepSeek-V3-0324_completion_1": "        data = self.sock.recv(1024)", "DeepSeek-V3-0324_completion_2": "        data = self.sock.recv(1024)", "DeepSeek-V3-0324_completion_3": "        data = self.sock.recv(1024)", "DeepSeek-V3-0324_completion_4": "        data = self.sock.recv(1024)", "DeepSeek-V3-0324_completions": ["        data = self.sock.recv(1024)", "        data = self.sock.recv(1024)", "        data = self.sock.recv(1024)", "        data = self.sock.recv(1024)", "        data = self.sock.recv(1024)"]}
{"id": "23", "testsource": "devbench-pattern-matching", "language": "python", "prefix": "import os\nimport json\n\nclass ConfigLoader:\n    def __init__(self, config_path):\n        self.config_path = config_path\n        self.config = None\n\n    def load_config(self):\n        try:\n            with open(self.config_path, 'r') as file:\n                self.config = json.load(file)\n            return True\n        except FileNotFoundError:\n            print('Config file not found.')\n            self.config = {}\n            return False\n        except json.JSONDecodeError:\n            print('Error decoding JSON from config file.')\n            self.config = {}\n            return False\n\n    def get_config_value(self, key):\n", "suffix": "        return self.config.get(key, None)\ntest_config = {\n    'some_key': None,\n    'some_other_key': None\n}\n\nwith open('config.json', 'w') as file:\n    json.dump(test_config, file)\n\nconfig_loader = ConfigLoader('config.json')\nconfig_loader.load_config()\n\n# Assertions to verify the functionality\nassert config_loader.get_config_value('some_key') == None\nassert config_loader.get_config_value('some_other_key') == None\n\n# Cleanup\nif os.path.exists('config.json'):\n    os.remove('config.json')", "golden_completion": "        if self.config is None:\n            raise ValueError('Config not loaded.')\n", "LLM_justification": "This test case evaluates the LLM's ability to recognize and complete an error handling pattern in an object-oriented context. The scenario involves reading a JSON configuration file, handling potential errors, and ensuring that the configuration is loaded before accessing its values. The completion requires adding a check to raise an error if the configuration is not loaded, demonstrating understanding of error handling and proper flow control.", "assertions": "unloaded_config = ConfigLoader('nonexistent.json')\ntry:\n    unloaded_config.get_config_value('missing_key')\nexcept ValueError as e:\n    assert str(e) == 'Config not loaded.'", "DeepSeek-V3-0324_completion_0": "        return self.config.get(key, None)", "DeepSeek-V3-0324_completion_1": "        return self.config.get(key, None)", "DeepSeek-V3-0324_completion_2": "        return self.config.get(key, None)", "DeepSeek-V3-0324_completion_3": "        return self.config.get(key, None)", "DeepSeek-V3-0324_completion_4": "        return self.config.get(key, None)", "DeepSeek-V3-0324_completions": ["        return self.config.get(key, None)", "        return self.config.get(key, None)", "        return self.config.get(key, None)", "        return self.config.get(key, None)", "        return self.config.get(key, None)"]}
{"id": "24", "testsource": "devbench-pattern-matching", "language": "python", "prefix": "import json\nimport os\n\nclass ConfigManager:\n    def __init__(self, config_path):\n        self.config_path = config_path\n        self.config = {}\n\n    def load_config(self):\n        if not os.path.exists(self.config_path):\n            raise FileNotFoundError(f\"Config file not found: {self.config_path}\")\n        with open(self.config_path, 'r') as config_file:\n            self.config = json.load(config_file)\n\n    def save_config(self):\n        with open(self.config_path, 'w') as config_file:\n            json.dump(self.config, config_file)\n\n    def get(self, key, default=None):\n        return self.config.get(key, default)\n\n    def set(self, key, value):\n        self.config[key] = value\n\n    def delete(self, key):\n", "suffix": "\n\n# Example usage:\nconfig_path = 'config.json'\nconfig_manager = ConfigManager(config_path)\nconfig_manager.set('username', 'test_user')\nassert config_manager.get('username') == 'test_user'\nconfig_manager.delete('username')\nassert config_manager.get('username') is None\n\n# Cleanup\nif os.path.exists(config_path):\n    os.remove(config_path)\n", "golden_completion": "        self.config.pop(key, None)\n", "LLM_justification": "This example tests the ability to recognize and complete a pattern in a class that manages configuration data. The pattern involves typical CRUD operations (Create, Read, Update, Delete) on a configuration dictionary. The completion should appropriately implement the deletion method using a common Python idiom. The suffix code provides example usage and cleanup, ensuring that the configuration file is properly removed after the test. This scenario is practical and tests both functionality and adherence to common Python patterns.", "assertions": "config_path = 'config.json'\nconfig_manager = ConfigManager(config_path)\nconfig_manager.set('username', 'test_user')\nassert config_manager.get('username') == 'test_user'\nconfig_manager.delete('username')\nassert config_manager.get('username') is None\n\n# Cleanup\nif os.path.exists(config_path):\n    os.remove(config_path)\n", "DeepSeek-V3-0324_completion_0": "        if key in self.config:\n            del self.config[key]", "DeepSeek-V3-0324_completion_1": "        if key in self.config:\n            del self.config[key]", "DeepSeek-V3-0324_completion_2": "        if key in self.config:\n            del self.config[key]", "DeepSeek-V3-0324_completion_3": "        if key in self.config:\n            del self.config[key]", "DeepSeek-V3-0324_completion_4": "        if key in self.config:\n            del self.config[key]", "DeepSeek-V3-0324_completions": ["        if key in self.config:\n            del self.config[key]", "        if key in self.config:\n            del self.config[key]", "        if key in self.config:\n            del self.config[key]", "        if key in self.config:\n            del self.config[key]", "        if key in self.config:\n            del self.config[key]"]}
{"id": "25", "testsource": "devbench-pattern-matching", "language": "python", "prefix": "import functools\n\nclass AuthenticationError(Exception):\n    pass\n\nclass Authenticator:\n    def __init__(self, valid_tokens):\n        self.valid_tokens = valid_tokens\n\n    def validate_token(self, token):\n        if token not in self.valid_tokens:\n            raise AuthenticationError(\"Invalid token\")\n\n    def require_authentication(self, func):\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            token = kwargs.get('token')\n            self.validate_token(token)\n            return func(*args, **kwargs)\n        return wrapper\n\n# Usage example of the Authenticator with a secured function\nvalid_tokens = {'token123', 'token456'}\nauthenticator = Authenticator(valid_tokens)\n\n@authenticator.require_authentication\n", "suffix": "def unprotected_function(data):\n    return f\"Unprotected data: {data}\"\n\n# Test cases\ntry:\n    assert protected_function(data=\"Sensitive Data\", token='token123') == \"Sensitive Data\"\n    assert protected_function(data=\"More Sensitive Data\", token='token456') == \"More Sensitive Data\"\n    try:\n        protected_function(data=\"No Token Data\")\n    except AuthenticationError:\n        pass\n    else:\n        assert False, \"Expected AuthenticationError\"\n    try:\n        protected_function(data=\"Invalid Token Data\", token='invalid')\n    except AuthenticationError:\n        pass\n    else:\n        assert False, \"Expected AuthenticationError\"\nfinally:\n    # Cleanup code if any\n    pass\n", "golden_completion": "def protected_function(data, token=None):\n    return data\n", "LLM_justification": "This test case evaluates an LLM's ability to recognize and continue a pattern involving the use of decorators for authentication in a security context. The Authenticator class and its require_authentication decorator establish a pattern where functions are wrapped to ensure valid tokens before execution. The completion should show the correct continuation of this pattern with a protected function that uses the decorator. The assertions verify that authentication works correctly and handles both valid and invalid tokens. This is a realistic and practical scenario for developers working with security and authentication in Python.", "assertions": "assert protected_function(data=\"Sensitive Data\", token='token123') == \"Sensitive Data\"\nassert protected_function(data=\"More Sensitive Data\", token='token456') == \"More Sensitive Data\"\ntry:\n    protected_function(data=\"No Token Data\")\nexcept AuthenticationError:\n    pass\nelse:\n    assert False, \"Expected AuthenticationError\"\ntry:\n    protected_function(data=\"Invalid Token Data\", token='invalid')\nexcept AuthenticationError:\n    pass\nelse:\n    assert False, \"Expected AuthenticationError\"", "DeepSeek-V3-0324_completion_0": "def protected_function(data, token=None):\n    return data", "DeepSeek-V3-0324_completion_1": "def protected_function(data, token=None):\n    return data", "DeepSeek-V3-0324_completion_2": "def protected_function(data, token=None):\n    return data", "DeepSeek-V3-0324_completion_3": "def protected_function(data, token=None):\n    return data", "DeepSeek-V3-0324_completion_4": "def protected_function(data, token=None):\n    return data", "DeepSeek-V3-0324_completions": ["def protected_function(data, token=None):\n    return data", "def protected_function(data, token=None):\n    return data", "def protected_function(data, token=None):\n    return data", "def protected_function(data, token=None):\n    return data", "def protected_function(data, token=None):\n    return data"]}
{"id": "26", "testsource": "devbench-pattern-matching", "language": "python", "prefix": "import functools\nimport time\n\nclass TimeLogger:\n    def __init__(self, func):\n        self.func = func\n        functools.update_wrapper(self, func)\n\n    def __call__(self, *args, **kwargs):\n        start_time = time.time()\n        try:\n            result = self.func(*args, **kwargs)\n        finally:\n            end_time = time.time()\n            print(f\"{self.func.__name__} took {end_time - start_time:.4f} seconds\")\n        return result\n\n@TimeLogger\n", "suffix": "def add(a, b):\n    return a + b\n\n@TimeLogger\ndef multiply(a, b):\n    return a * b\n\n# Test the decorated functions\nassert add(2, 3) == 5\nassert multiply(2, 3) == 6\nassert add(10, 20) == 30\nassert multiply(5, 4) == 20\n\n# Ensure the decorator prints the time\nimport io\nimport sys\ncaptured_output = io.StringIO()\nsys.stdout = captured_output\nadd(2, 3)\nsys.stdout = sys.__stdout__\nassert 'add took' in captured_output.getvalue()\n\n# Clean up\ncaptured_output.close()\n", "golden_completion": "def subtract(a, b):\n    return a - b\n\n@TimeLogger\n", "LLM_justification": "This test case is a good example of decorators/metaprogramming in the context of tool automation (timing function calls). It tests the LLM's ability to recognize and continue a pattern of using a custom decorator to log the execution time of functions. The prompt establishes the pattern with the TimeLogger decorator, and the golden completion requires the LLM to apply this pattern to a new function. Assertions verify that the decorator works as intended, ensuring both pattern adherence and functionality.", "assertions": "assert subtract(5, 3) == 2\nassert subtract(10, 5) == 5\n\n# Ensure the decorator prints the time\nimport io\nimport sys\ncaptured_output = io.StringIO()\nsys.stdout = captured_output\nsubtract(5, 3)\nsys.stdout = sys.__stdout__\nassert 'subtract took' in captured_output.getvalue()\n\n# Clean up\ncaptured_output.close()\n", "DeepSeek-V3-0324_completion_0": "def add(a, b):\n    return a + b", "DeepSeek-V3-0324_completion_1": "def add(a, b):\n    return a + b", "DeepSeek-V3-0324_completion_2": "def add(a, b):\n    return a + b", "DeepSeek-V3-0324_completion_3": "def add(a, b):\n    return a + b", "DeepSeek-V3-0324_completion_4": "def add(a, b):\n    return a + b", "DeepSeek-V3-0324_completions": ["def add(a, b):\n    return a + b", "def add(a, b):\n    return a + b", "def add(a, b):\n    return a + b", "def add(a, b):\n    return a + b", "def add(a, b):\n    return a + b"]}
{"id": "27", "testsource": "devbench-pattern-matching", "language": "python", "prefix": "import requests\n\nclass APIClient:\n    def __init__(self, base_url):\n        self.base_url = base_url\n\n    def get_resource(self, resource_id):\n        url = f\"{self.base_url}/{resource_id}\"\n        try:\n            response = requests.get(url)\n            response.raise_for_status()\n", "suffix": "            return response.json()\n        except requests.exceptions.HTTPError as http_err:\n            print(f\"HTTP error occurred: {http_err}\")\n        except Exception as err:\n            print(f\"Other error occurred: {err}\")\n        return None\n\nclient = APIClient(\"https://jsonplaceholder.typicode.com/posts\")\nresult = client.get_resource(\"1\")\n\nassert result is not None\nassert isinstance(result, dict)\nprint(f\"Resource fetched successfully: {result}\")", "golden_completion": "            return response.json()\n        except requests.exceptions.RequestException as req_err:\n            print(f\"Request error occurred: {req_err}\")\n", "LLM_justification": "This test case demonstrates error handling in the context of network protocols (APIs). It establishes a pattern of making an HTTP GET request and handling potential exceptions. The completion requires correctly identifying and handling a specific type of exception (RequestException), which is a common pattern in robust API clients. This scenario tests the LLM's ability to recognize and continue the error handling pattern while adhering to best practices.", "assertions": "bad_result = client.get_resource(\"999999\")\nprint(f\"Result for non-existent resource: {bad_result}\")\n\nuser_client = APIClient(\"https://jsonplaceholder.typicode.com/users\")\nuser_result = user_client.get_resource(\"1\")  # Get user with ID 1\nuser_result = user_client.get_resource(\"1\")  # Get user with ID 1\nassert isinstance(user_result, dict)\nprint(f\"User resource fetched successfully: {user_result['name']}\")\n", "DeepSeek-V3-0324_completion_0": "            return response.json()", "DeepSeek-V3-0324_completion_1": "            return response.json()", "DeepSeek-V3-0324_completion_2": "            return response.json()", "DeepSeek-V3-0324_completion_3": "            data = response.json()", "DeepSeek-V3-0324_completion_4": "            return response.json()", "DeepSeek-V3-0324_completions": ["            return response.json()", "            return response.json()", "            return response.json()", "            data = response.json()", "            return response.json()"]}
{"id": "28", "testsource": "devbench-pattern-matching", "language": "python", "prefix": "import functools\nimport time\n\n# Decorator to measure the execution time of functions\nclass Timer:\n    def __init__(self, func):\n        self.func = func\n        functools.update_wrapper(self, func)\n\n    def __call__(self, *args, **kwargs):\n        start_time = time.time()\n        result = self.func(*args, **kwargs)\n        end_time = time.time()\n        elapsed_time = end_time - start_time\n        print(f\"{self.func.__name__} took {elapsed_time:.4f} seconds to execute.\")\n        return result\n\n@Timer\n", "suffix": "def fast_function():\n    return \"Fast\"\n\nfast_result = fast_function()\n\n@Timer\ndef slow_function():\n    time.sleep(2)\n    return \"Slow\"\n\nslow_result = slow_function()\n\n# Assertions to verify the functionality and adherence to the pattern\nassert fast_result == \"Fast\"\nassert slow_result == \"Slow\"\n\n# Cleanup (nothing to cleanup in this example)\n", "golden_completion": "def example_function():\n    time.sleep(1)\n    return \"Example\"\n\nexample_result = example_function()\n", "LLM_justification": "This example tests the LLM's ability to recognize and complete a pattern involving decorators in a practical scenario. The Timer decorator pattern measures the execution time of functions. The prompt establishes the Timer class and its usage, and the suffix continues with different functions using this decorator. The golden completion requires the LLM to correctly apply the Timer decorator to a new function, demonstrating an understanding of the established pattern. The assertions ensure that the decorator works as expected and the functions return the correct values.", "assertions": "assert example_result == \"Example\"\n", "DeepSeek-V3-0324_completion_0": "def fast_function():\n    return \"Fast\"", "DeepSeek-V3-0324_completion_1": "def fast_function():\n    return \"Fast\"", "DeepSeek-V3-0324_completion_2": "def fast_function():\n    return \"Fast\"", "DeepSeek-V3-0324_completion_3": "def fast_function():\n    return \"Fast\"", "DeepSeek-V3-0324_completion_4": "def fast_function():\n    return \"Fast\"", "DeepSeek-V3-0324_completions": ["def fast_function():\n    return \"Fast\"", "def fast_function():\n    return \"Fast\"", "def fast_function():\n    return \"Fast\"", "def fast_function():\n    return \"Fast\"", "def fast_function():\n    return \"Fast\""]}
{"id": "29", "testsource": "devbench-pattern-matching", "language": "python", "prefix": "import requests\n\nclass ApiClient:\n    def __init__(self, base_url):\n        self.base_url = base_url\n\n    def get(self, endpoint):\n        url = f\"{self.base_url}/{endpoint}\"\n        response = requests.get(url)\n        response.raise_for_status()\n        return response.json()\n\n    def post(self, endpoint, data):\n        url = f\"{self.base_url}/{endpoint}\"\n        response = requests.post(url, json=data)\n        response.raise_for_status()\n        return response.json()\n\n    def put(self, endpoint, data):\n        url = f\"{self.base_url}/{endpoint}\"\n        response = requests.put(url, json=data)\n        response.raise_for_status()\n", "suffix": "        return response.json()\n\n# Testing the ApiClient class\nclient = ApiClient(\"http://example.com/api\")\n\n# Mocking requests library\nfrom unittest.mock import patch, Mock\n\nwith patch(\"requests.delete\") as mock_delete:\n    mock_response = Mock()\n    mock_response.status_code = 204\n    mock_response.json.return_value = {}\n    mock_delete.return_value = mock_response\n    response = client.delete(\"resource/1\")\n    assert response == {}\n\nprint(\"All tests passed!\")", "golden_completion": "        return response.json()\n\n    def delete(self, endpoint):\n        url = f\"{self.base_url}/{endpoint}\"\n        response = requests.delete(url)\n        response.raise_for_status()", "LLM_justification": "This example tests the LLM's ability to recognize and complete an established pattern of API CRUD operations within a class. The pattern involves defining HTTP methods (get, post, put) that construct a URL, make a request, handle errors, and return the JSON response. The golden completion requires the LLM to continue this pattern correctly for the delete method. The assertions check if the delete method is implemented and behaves correctly, verifying both functional and pattern adherence.", "assertions": "assert response == {}\n\nprint(\"All tests passed!\")", "DeepSeek-V3-0324_completion_0": "        return response.json()\n\n    def delete(self, endpoint):\n        url = f\"{self.base_url}/{endpoint}\"\n        response = requests.delete(url)\n        response.raise_for_status()", "DeepSeek-V3-0324_completion_1": "        return response.json()\n\n    def delete(self, endpoint):\n        url = f\"{self.base_url}/{endpoint}\"\n        response = requests.delete(url)\n        response.raise_for_status()", "DeepSeek-V3-0324_completion_2": "        return response.json()\n\n    def delete(self, endpoint):\n        url = f\"{self.base_url}/{endpoint}\"\n        response = requests.delete(url)\n        response.raise_for_status()", "DeepSeek-V3-0324_completion_3": "        return response.json()\n\n    def delete(self, endpoint):\n        url = f\"{self.base_url}/{endpoint}\"\n        response = requests.delete(url)\n        response.raise_for_status()", "DeepSeek-V3-0324_completion_4": "        return response.json()\n\n    def delete(self, endpoint):\n        url = f\"{self.base_url}/{endpoint}\"\n        response = requests.delete(url)\n        response.raise_for_status()", "DeepSeek-V3-0324_completions": ["        return response.json()\n\n    def delete(self, endpoint):\n        url = f\"{self.base_url}/{endpoint}\"\n        response = requests.delete(url)\n        response.raise_for_status()", "        return response.json()\n\n    def delete(self, endpoint):\n        url = f\"{self.base_url}/{endpoint}\"\n        response = requests.delete(url)\n        response.raise_for_status()", "        return response.json()\n\n    def delete(self, endpoint):\n        url = f\"{self.base_url}/{endpoint}\"\n        response = requests.delete(url)\n        response.raise_for_status()", "        return response.json()\n\n    def delete(self, endpoint):\n        url = f\"{self.base_url}/{endpoint}\"\n        response = requests.delete(url)\n        response.raise_for_status()", "        return response.json()\n\n    def delete(self, endpoint):\n        url = f\"{self.base_url}/{endpoint}\"\n        response = requests.delete(url)\n        response.raise_for_status()"]}
{"id": "30", "testsource": "devbench-pattern-matching", "language": "python", "prefix": "import json\nimport os\n\nclass ConfigLoader:\n    def __init__(self, config_path):\n        self.config_path = config_path\n        self.config_data = None\n\n    def load_config(self):\n        try:\n            with open(self.config_path, 'r') as file:\n                self.config_data = json.load(file)\n        except FileNotFoundError:\n            print(f\"Config file not found: {self.config_path}\")\n            self.config_data = {}\n        except json.JSONDecodeError:\n            print(f\"Error decoding JSON from file: {self.config_path}\")\n            self.config_data = {}\n\n    def get(self, key, default=None):\n        if self.config_data is None:\n            self.load_config()\n        return self.config_data.get(key, default)\n\n    def save_config(self):\n        try:\n            with open(self.config_path, 'w') as file:\n                json.dump(self.config_data, file, indent=4)\n        except Exception as e:\n            print(f\"Error saving config: {e}\")\n\n", "suffix": "    def update(self, key, value):\n        if self.config_data is None:\n            self.load_config()\n        if self.config_data is None:\n            self.config_data = {}\n        self.config_data[key] = value\n\nconfig_path = 'config.json'\nloader = ConfigLoader(config_path)\nloader.update('new_key', 'new_value')\nloader.save_config()\n\ntry:\n    with open(config_path, 'r') as file:\n        saved_data = json.load(file)\n    assert saved_data['new_key'] == 'new_value'\nfinally:\n    os.remove(config_path)", "golden_completion": "    def delete(self, key):\n        if self.config_data is None:\n            self.load_config()\n        if key in self.config_data:\n            del self.config_data[key]\n        else:\n            print(f\"Key '{key}' not found in config\")\n\n", "LLM_justification": "This test case evaluates the LLM's ability to recognize and continue patterns in an OOP context for error handling and data manipulation within a configuration loader class. The golden completion demonstrates the pattern of checking if configuration data is loaded before performing operations and handling errors gracefully. This is a realistic scenario for developers working with configuration files and ensures the model can maintain consistency in method implementations.", "assertions": "config_path = 'config.json'\nloader = ConfigLoader(config_path)\nloader.update('key_to_delete', 'value_to_delete')\nloader.save_config()\n\nloader.delete('key_to_delete')\nloader.save_config()\n\ntry:\n    with open(config_path, 'r') as file:\n        saved_data = json.load(file)\n    assert 'key_to_delete' not in saved_data\nfinally:\n    os.remove(config_path)", "DeepSeek-V3-0324_completion_0": "    def update(self, key, value):\n        if self.config_data is None:\n            self.load_config()\n        if self.config_data is None:\n            self.config_data = {}\n        self.config_data[key] = value", "DeepSeek-V3-0324_completion_1": "    def update(self, key, value):\n        if self.config_data is None:\n            self.load_config()\n        if self.config_data is None:\n            self.config_data = {}\n        self.config_data[key] = value", "DeepSeek-V3-0324_completion_2": "    def update(self, key, value):\n        if self.config_data is None:\n            self.load_config()\n        if self.config_data is None:\n            self.config_data = {}\n        self.config_data[key] = value", "DeepSeek-V3-0324_completion_3": "    def update(self, key, value):\n        if self.config_data is None:\n            self.load_config()\n        if self.config_data is None:\n            self.config_data = {}\n        self.config_data[key] = value", "DeepSeek-V3-0324_completion_4": "    def update(self, key, value):\n        if self.config_data is None:\n            self.load_config()\n        if self.config_data is None:\n            self.config_data = {}\n        self.config_data[key] = value", "DeepSeek-V3-0324_completions": ["    def update(self, key, value):\n        if self.config_data is None:\n            self.load_config()\n        if self.config_data is None:\n            self.config_data = {}\n        self.config_data[key] = value", "    def update(self, key, value):\n        if self.config_data is None:\n            self.load_config()\n        if self.config_data is None:\n            self.config_data = {}\n        self.config_data[key] = value", "    def update(self, key, value):\n        if self.config_data is None:\n            self.load_config()\n        if self.config_data is None:\n            self.config_data = {}\n        self.config_data[key] = value", "    def update(self, key, value):\n        if self.config_data is None:\n            self.load_config()\n        if self.config_data is None:\n            self.config_data = {}\n        self.config_data[key] = value", "    def update(self, key, value):\n        if self.config_data is None:\n            self.load_config()\n        if self.config_data is None:\n            self.config_data = {}\n        self.config_data[key] = value"]}
{"id": "31", "testsource": "devbench-pattern-matching", "language": "python", "prefix": "import json\n\ndef process_log_entry(log_entry):\n    try:\n        log_data = json.loads(log_entry)\n        event_type = log_data.get('event_type')\n        if event_type == 'ERROR':\n            handle_error(log_data)\n        elif event_type == 'INFO':\n            handle_info(log_data)\n        else:\n            handle_generic(log_data)\n    except json.JSONDecodeError:\n        print('Invalid JSON format')\n\ndef handle_error(log_data):\n    # Logic to handle error logs\n    print(f\"Error: {log_data.get('message')}\")\n\ndef handle_info(log_data):\n    # Logic to handle info logs\n    print(f\"Info: {log_data.get('message')}\")\n", "suffix": "\n\n# Sample log entries for testing\nerror_log = '{\"event_type\": \"ERROR\", \"message\": \"Something went wrong\"}'\ninfo_log = '{\"event_type\": \"INFO\", \"message\": \"System is running smoothly\"}'\ngeneric_log = '{\"event_type\": \"DEBUG\", \"message\": \"Debugging details\"}'\n\nprocess_log_entry(error_log)\nprocess_log_entry(info_log)\nprocess_log_entry(generic_log)\n\nassert process_log_entry(error_log) is None\nassert process_log_entry(info_log) is None\nassert process_log_entry(generic_log) is None", "golden_completion": "def handle_generic(log_data):\n    # Generic log handling logic\n    print(f\"Log: {log_data.get('message')}\")\n\n", "LLM_justification": "This test case focuses on event handling patterns within the context of processing log entries. The completion demonstrates understanding of handling various log event types and processing them accordingly. The semantic pattern is established through handling different 'event_type' values within the JSON log entries. The completion should correctly implement the 'handle_generic' function, maintaining logical consistency with the other handlers and ensuring proper log processing. This tests the LLM's ability to understand the event handling pattern and apply it appropriately in a real-world logging scenario.", "assertions": "assert process_log_entry('{\"event_type\": \"ERROR\", \"message\": \"Something went wrong\"}') is None\nassert process_log_entry('{\"event_type\": \"INFO\", \"message\": \"System is running smoothly\"}') is None\nassert process_log_entry('{\"event_type\": \"DEBUG\", \"message\": \"Debugging details\"}') is None\n", "DeepSeek-V3-0324_completion_0": "def handle_generic(log_data):\n    # Logic to handle generic logs\n    print(f\"Generic: {log_data.get('message')}\")", "DeepSeek-V3-0324_completion_1": "def handle_generic(log_data):\n    # Logic to handle generic logs\n    print(f\"Generic: {log_data.get('message')}\")", "DeepSeek-V3-0324_completion_2": "def handle_generic(log_data):\n    # Logic to handle generic logs\n    print(f\"Generic: {log_data.get('message')}\")", "DeepSeek-V3-0324_completion_3": "def handle_generic(log_data):\n    # Logic to handle generic logs\n    print(f\"Generic: {log_data.get('message')}\")", "DeepSeek-V3-0324_completion_4": "def handle_generic(log_data):\n    # Logic to handle generic logs\n    print(f\"Generic: {log_data.get('message')}\")", "DeepSeek-V3-0324_completions": ["def handle_generic(log_data):\n    # Logic to handle generic logs\n    print(f\"Generic: {log_data.get('message')}\")", "def handle_generic(log_data):\n    # Logic to handle generic logs\n    print(f\"Generic: {log_data.get('message')}\")", "def handle_generic(log_data):\n    # Logic to handle generic logs\n    print(f\"Generic: {log_data.get('message')}\")", "def handle_generic(log_data):\n    # Logic to handle generic logs\n    print(f\"Generic: {log_data.get('message')}\")", "def handle_generic(log_data):\n    # Logic to handle generic logs\n    print(f\"Generic: {log_data.get('message')}\")"]}
{"id": "32", "testsource": "devbench-pattern-matching", "language": "python", "prefix": "import requests\n\nclass APIFetcher:\n    def __init__(self, base_url):\n        self.base_url = base_url\n\n    def fetch(self, endpoint):\n        response = requests.get(f'{self.base_url}/{endpoint}')\n        response.raise_for_status()\n        return response.json()\n\n    def fetch_user(self, user_id):\n        endpoint = f'users/{user_id}'\n        user_data = self.fetch(endpoint)\n        return user_data\n\n    def fetch_post(self, post_id):\n        endpoint = f'posts/{post_id}'\n        post_data = self.fetch(endpoint)\n        return post_data\n\n    def fetch_comment(self, comment_id):\n        endpoint = f'comments/{comment_id}'\n        comment_data = self.fetch(endpoint)\n        return comment_data\n\n", "suffix": "api_fetcher = APIFetcher('https://jsonplaceholder.typicode.com')\n\nuser_data = api_fetcher.fetch_user(1)\npost_data = api_fetcher.fetch_post(1)\ncomment_data = api_fetcher.fetch_comment(1)\n\n# Assertions\nassert 'id' in user_data\nassert 'id' in post_data\nassert 'id' in comment_data\n\n# Cleanup (none needed in this context)\n", "golden_completion": "    def fetch_todo(self, todo_id):\n        endpoint = f'todos/{todo_id}'\n        todo_data = self.fetch(endpoint)\n        return todo_data\n", "LLM_justification": "This example tests the LLM's ability to recognize a clear pattern in a class that fetches different types of data from an API. The pattern involves defining methods that construct an endpoint string based on the provided ID, fetch the data, and return the JSON response. The LLM must recognize this pattern and continue it by implementing a new method that follows the same structure for fetching a 'todo' item. The assertions verify that the methods work correctly by checking the presence of 'id' in the returned data.", "assertions": "api_fetcher = APIFetcher('https://jsonplaceholder.typicode.com')\ntodo_data = api_fetcher.fetch_todo(1)\nassert 'id' in todo_data\n", "DeepSeek-V3-0324_completion_0": "api_fetcher = APIFetcher('https://jsonplaceholder.typicode.com')", "DeepSeek-V3-0324_completion_1": "api_fetcher = APIFetcher('https://jsonplaceholder.typicode.com')", "DeepSeek-V3-0324_completion_2": "api_fetcher = APIFetcher('https://jsonplaceholder.typicode.com')", "DeepSeek-V3-0324_completion_3": "api_fetcher = APIFetcher('https://jsonplaceholder.typicode.com')", "DeepSeek-V3-0324_completion_4": "api_fetcher = APIFetcher('https://jsonplaceholder.typicode.com')", "DeepSeek-V3-0324_completions": ["api_fetcher = APIFetcher('https://jsonplaceholder.typicode.com')", "api_fetcher = APIFetcher('https://jsonplaceholder.typicode.com')", "api_fetcher = APIFetcher('https://jsonplaceholder.typicode.com')", "api_fetcher = APIFetcher('https://jsonplaceholder.typicode.com')", "api_fetcher = APIFetcher('https://jsonplaceholder.typicode.com')"]}
{"id": "33", "testsource": "devbench-pattern-matching", "language": "python", "prefix": "import logging\n\nclass SystemMonitor:\n    def __init__(self):\n        self.logger = logging.getLogger('SystemMonitor')\n        self.logger.setLevel(logging.INFO)\n        handler = logging.StreamHandler()\n        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n        handler.setFormatter(formatter)\n        self.logger.addHandler(handler)\n\n    def log_info(self, message):\n        self.logger.info(message)\n\n    def log_warning(self, message):\n        self.logger.warning(message)\n\n    def log_error(self, message):\n        self.logger.error(message)\n\n    # Additional logging levels need to be added\n", "suffix": "\nmonitor = SystemMonitor()\nmonitor.log_info('This is an info message')\nmonitor.log_warning('This is a warning message')\nmonitor.log_error('This is an error message')\nmonitor.log_critical('This is a critical message')\nmonitor.log_debug('This is a debug message')", "golden_completion": "    def log_critical(self, message):\n        self.logger.critical(message)\n\n    def log_debug(self, message):\n        self.logger.debug(message)\n\n", "LLM_justification": "This test case is suitable because it tests the LLM's ability to recognize and continue a pattern of logging methods in a class. The prefix clearly establishes a pattern of method definitions for different logging levels (`log_info`, `log_warning`, `log_error`). The golden completion requires the LLM to continue this pattern by adding methods for `log_critical` and `log_debug`, maintaining consistency with the established method signatures and functionality. The suffix further uses these methods, ensuring the pattern is correctly identified and completed.", "assertions": "monitor = SystemMonitor()\nmonitor.log_info('This is an info message')\nmonitor.log_warning('This is a warning message')\nmonitor.log_error('This is an error message')\nmonitor.log_critical('This is a critical message')\nmonitor.log_debug('This is a debug message')\nassert monitor.logger.hasHandlers(), 'Logger should have handlers attached'\nfor handler in monitor.logger.handlers:\n    assert isinstance(handler, logging.StreamHandler), 'Handler should be a StreamHandler'\n    assert isinstance(handler.formatter, logging.Formatter), 'Handler should have a Formatter attached'\n    assert handler.formatter._fmt == '%(asctime)s - %(name)s - %(levelname)s - %(message)s', 'Formatter should match the specified format'", "DeepSeek-V3-0324_completion_0": "    def log_critical(self, message):\n        self.logger.critical(message)\n\n    def log_debug(self, message):\n        self.logger.debug(message)", "DeepSeek-V3-0324_completion_1": "    def log_critical(self, message):\n        self.logger.critical(message)\n\n    def log_debug(self, message):\n        self.logger.debug(message)", "DeepSeek-V3-0324_completion_2": "    def log_critical(self, message):\n        self.logger.critical(message)\n\n    def log_debug(self, message):\n        self.logger.debug(message)", "DeepSeek-V3-0324_completion_3": "    def log_critical(self, message):\n        self.logger.critical(message)\n\n    def log_debug(self, message):\n        self.logger.debug(message)", "DeepSeek-V3-0324_completion_4": "    def log_critical(self, message):\n        self.logger.critical(message)\n\n    def log_debug(self, message):\n        self.logger.debug(message)", "DeepSeek-V3-0324_completions": ["    def log_critical(self, message):\n        self.logger.critical(message)\n\n    def log_debug(self, message):\n        self.logger.debug(message)", "    def log_critical(self, message):\n        self.logger.critical(message)\n\n    def log_debug(self, message):\n        self.logger.debug(message)", "    def log_critical(self, message):\n        self.logger.critical(message)\n\n    def log_debug(self, message):\n        self.logger.debug(message)", "    def log_critical(self, message):\n        self.logger.critical(message)\n\n    def log_debug(self, message):\n        self.logger.debug(message)", "    def log_critical(self, message):\n        self.logger.critical(message)\n\n    def log_debug(self, message):\n        self.logger.debug(message)"]}
{"id": "34", "testsource": "devbench-pattern-matching", "language": "python", "prefix": "import logging\n\nclass Logger:\n    def __init__(self, name: str):\n        self.logger = logging.getLogger(name)\n        self.logger.setLevel(logging.DEBUG)\n        handler = logging.StreamHandler()\n        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n        handler.setFormatter(formatter)\n        self.logger.addHandler(handler)\n\n    def debug(self, message: str):\n        self.logger.debug(message)\n\n    def info(self, message: str):\n        self.logger.info(message)\n\n    def warning(self, message: str):\n        self.logger.warning(message)\n\n", "suffix": "    def critical(self, message: str):\n        self.logger.critical(message)\n\n# Testing the Logger class\nlog = Logger('test_logger')\nlog.debug('This is a debug message')\nlog.info('This is an info message')\nlog.warning('This is a warning message')\nlog.error('This is an error message')\nlog.critical('This is a critical message')\n\n# Assertions\nassert len(logging.getLogger('test_logger').handlers) > 0\nassert logging.getLogger('test_logger').level == logging.DEBUG\n", "golden_completion": "    def error(self, message: str):\n        self.logger.error(message)\n\n", "LLM_justification": "This test case is designed to evaluate the LLM's ability to recognize and follow a common OOP pattern in system operations, specifically for logging. The Logger class demonstrates a clear, repetitive pattern of defining logging methods (debug, info, warning). The golden completion requires the LLM to continue this pattern by defining the 'error' method, which fits seamlessly within the established structure. This tests the LLM's ability to adhere to and extend established patterns in a realistic, practical scenario.", "assertions": "log = Logger('test_logger')\nlog.debug('This is a debug message')\nlog.info('This is an info message')\nlog.warning('This is a warning message')\nlog.error('This is an error message')\nlog.critical('This is a critical message')\n\nassert len(logging.getLogger('test_logger').handlers) > 0\nassert logging.getLogger('test_logger').level == logging.DEBUG\n", "DeepSeek-V3-0324_completion_0": "    def error(self, message: str):\n        self.logger.error(message)", "DeepSeek-V3-0324_completion_1": "    def error(self, message: str):\n        self.logger.error(message)", "DeepSeek-V3-0324_completion_2": "    def error(self, message: str):\n        self.logger.error(message)", "DeepSeek-V3-0324_completion_3": "    def error(self, message: str):\n        self.logger.error(message)", "DeepSeek-V3-0324_completion_4": "    def error(self, message: str):\n        self.logger.error(message)", "DeepSeek-V3-0324_completions": ["    def error(self, message: str):\n        self.logger.error(message)", "    def error(self, message: str):\n        self.logger.error(message)", "    def error(self, message: str):\n        self.logger.error(message)", "    def error(self, message: str):\n        self.logger.error(message)", "    def error(self, message: str):\n        self.logger.error(message)"]}
{"id": "35", "testsource": "devbench-pattern-matching", "language": "python", "prefix": "import logging\nimport time\n\nclass SystemMonitor:\n    def __init__(self, log_file):\n        self.logger = logging.getLogger('SystemMonitor')\n        self.logger.setLevel(logging.DEBUG)\n        handler = logging.FileHandler(log_file)\n        handler.setFormatter(logging.Formatter('%(asctime)s - %(levelname)s - %(message)s'))\n        self.logger.addHandler(handler)\n        self.handlers = [handler]\n\n    def log_cpu_usage(self, usage):\n        self.logger.info(f'CPU Usage: {usage}%')\n\n    def log_memory_usage(self, usage):\n        self.logger.info(f'Memory Usage: {usage}%')\n\n", "suffix": "\n    def log_disk_usage(self, usage):\n        self.logger.info(f'Disk Usage: {usage}%')\n    def close(self):\n        \"\"\"Close all log handlers to release file handles.\"\"\"\n        for handler in self.handlers:\n            self.logger.removeHandler(handler)\n            handler.close()\n\nif __name__ == '__main__':\n    monitor = SystemMonitor('system.log')\n    monitor.log_cpu_usage(45)\n    monitor.log_memory_usage(30)\n    monitor.log_disk_usage(70)\n\n# Ensure the log file is created and has the expected content\nwith open('system.log', 'r') as log_file:\n    logs = log_file.read()\nassert 'CPU Usage: 45%' in logs\nassert 'Memory Usage: 30%' in logs\nassert 'Disk Usage: 70%' in logs\n\nmonitor.close()\n\n# Clean up the log file\nimport os\nos.remove('system.log')\n", "golden_completion": "    def log_network_usage(self, usage):\n        self.logger.info(f'Network Usage: {usage}%')\n\n", "LLM_justification": "This test case is designed to evaluate the LLM's ability to recognize and continue a pattern in system operations logging. The prefix establishes a clear pattern of logging different system metrics (CPU and memory usage) with similar method structures. The golden completion should follow this pattern by adding a method to log network usage in a similar fashion. This tests the LLM's understanding of the established logging pattern and its ability to extend it consistently. The suffix continues the pattern by adding a method to log disk usage, which further reinforces the expected pattern for the golden completion.", "assertions": "monitor = SystemMonitor('system.log')\nmonitor.log_network_usage(50)\nwith open('system.log', 'r') as log_file:\n    logs = log_file.read()\nassert 'Network Usage: 50%' in logs\n\nmonitor.close()\nos.remove('system.log')", "DeepSeek-V3-0324_completion_0": "    def log_disk_usage(self, usage):\n        self.logger.info(f'Disk Usage: {usage}%')\n    def close(self):\n        \"\"\"Close all log handlers to release file handles.\"\"\"\n        for handler in self.handlers:\n            self.logger.removeHandler(handler)\n            handler.close()", "DeepSeek-V3-0324_completion_1": "    def log_disk_usage(self, usage):\n        self.logger.info(f'Disk Usage: {usage}%')", "DeepSeek-V3-0324_completion_2": "    def log_disk_usage(self, usage):\n        self.logger.info(f'Disk Usage: {usage}%')\n    def close(self):\n        \"\"\"Close all log handlers to release file handles.\"\"\"\n        for handler in self.handlers:\n            self.logger.removeHandler(handler)\n            handler.close()", "DeepSeek-V3-0324_completion_3": "    def log_disk_usage(self, usage):\n        self.logger.info(f'Disk Usage: {usage}%')\n    def close(self):\n        \"\"\"Close all log handlers to release file handles.\"\"\"\n        for handler in self.handlers:\n            self.logger.removeHandler(handler)\n            handler.close()", "DeepSeek-V3-0324_completion_4": "    def log_disk_usage(self, usage):\n        self.logger.info(f'Disk Usage: {usage}%')\n    def close(self):\n        \"\"\"Close all log handlers to release file handles.\"\"\"\n        for handler in self.handlers:\n            self.logger.removeHandler(handler)\n            handler.close()", "DeepSeek-V3-0324_completions": ["    def log_disk_usage(self, usage):\n        self.logger.info(f'Disk Usage: {usage}%')\n    def close(self):\n        \"\"\"Close all log handlers to release file handles.\"\"\"\n        for handler in self.handlers:\n            self.logger.removeHandler(handler)\n            handler.close()", "    def log_disk_usage(self, usage):\n        self.logger.info(f'Disk Usage: {usage}%')", "    def log_disk_usage(self, usage):\n        self.logger.info(f'Disk Usage: {usage}%')\n    def close(self):\n        \"\"\"Close all log handlers to release file handles.\"\"\"\n        for handler in self.handlers:\n            self.logger.removeHandler(handler)\n            handler.close()", "    def log_disk_usage(self, usage):\n        self.logger.info(f'Disk Usage: {usage}%')\n    def close(self):\n        \"\"\"Close all log handlers to release file handles.\"\"\"\n        for handler in self.handlers:\n            self.logger.removeHandler(handler)\n            handler.close()", "    def log_disk_usage(self, usage):\n        self.logger.info(f'Disk Usage: {usage}%')\n    def close(self):\n        \"\"\"Close all log handlers to release file handles.\"\"\"\n        for handler in self.handlers:\n            self.logger.removeHandler(handler)\n            handler.close()"]}
{"id": "36", "testsource": "devbench-pattern-matching", "language": "python", "prefix": "import csv\nimport statistics\nimport os\n\nclass DataAnalyzer:\n    def __init__(self, filepath):\n        self.filepath = filepath\n        self.data = []\n\n    def load_data(self):\n        with open(self.filepath, newline='') as csvfile:\n            reader = csv.reader(csvfile)\n            for row in reader:\n                self.data.append([int(value) for value in row])\n\n    def mean(self, column):\n        column_data = [row[column] for row in self.data]\n        return statistics.mean(column_data)\n\n    def median(self, column):\n        column_data = [row[column] for row in self.data]\n        return statistics.median(column_data)\n\n    def mode(self, column):\n        column_data = [row[column] for row in self.data]\n        return statistics.mode(column_data)\n\n", "suffix": "def create_test_csv(filename):\n    sample_data = [\n        [10, 20, 30],\n        [15, 25, 35],\n        [10, 30, 40],\n        [20, 20, 30]\n    ]\n    with open(filename, 'w', newline='') as csvfile:\n        writer = csv.writer(csvfile)\n        for row in sample_data:\n            writer.writerow(row)\n\n", "golden_completion": "    def variance(self, column):\n        column_data = [row[column] for row in self.data]\n        return statistics.variance(column_data)\n", "LLM_justification": "This test case evaluates the LLM's ability to recognize and continue a clear OOP pattern in the context of scientific computing. The DataAnalyzer class follows a pattern of statistical methods operating on columns of data. The completion should add a new method that continues this pattern, adhering to the established class structure and using the statistics module.", "assertions": "try:\n    create_test_csv('data.csv')\n\n    analyzer = DataAnalyzer('data.csv')\n    analyzer.load_data()\n\n    analyzer.load_data()\n    analyzer.load_data()\n    print('Mode:', analyzer.mode(0))\n    print('Variance:', analyzer.variance(0))\n\n    assert analyzer.mean(0) == statistics.mean([row[0] for row in analyzer.data])\n    assert analyzer.median(0) == statistics.median([row[0] for row in analyzer.data])\n    assert analyzer.mode(0) == statistics.mode([row[0] for row in analyzer.data])\n    assert analyzer.variance(0) == statistics.variance([row[0] for row in analyzer.data])\n\n    print(\"All tests passed!\")\n\nfinally:\n    if os.path.exists('data.csv'):\n     os.remove('data.csv')\n\n", "DeepSeek-V3-0324_completion_0": "    def create_test_csv(filename):\n        sample_data = [\n            [10, 20, 30],\n            [15, 25, 35],\n            [10, 30, 40],\n            [20, 20, 30]\n        ]\n        with open(filename, 'w', newline='') as csvfile:\n            writer = csv.writer(csvfile)\n            for row in sample_data:\n                writer.writerow(row)", "DeepSeek-V3-0324_completion_1": "    def create_test_csv(filename):\n        sample_data = [\n            [10, 20, 30],\n            [15, 25, 35],\n            [10, 30, 40],\n            [20, 20, 30]\n        ]\n        with open(filename, 'w', newline='') as csvfile:\n            writer = csv.writer(csvfile)\n            for row in sample_data:\n                writer.writerow(row)", "DeepSeek-V3-0324_completion_2": "    def create_test_csv(filename):\n        sample_data = [\n            [10, 20, 30],\n            [15, 25, 35],\n            [10, 30, 40],\n            [20, 20, 30]\n        ]\n        with open(filename, 'w', newline='') as csvfile:\n            writer = csv.writer(csvfile)\n            for row in sample_data:\n                writer.writerow(row)", "DeepSeek-V3-0324_completion_3": "    def create_test_csv(filename):\n        sample_data = [\n            [10, 20, 30],\n            [15, 25, 35],\n            [10, 30, 40],\n            [20, 20, 30]\n        ]\n        with open(filename, 'w', newline='') as csvfile:\n            writer = csv.writer(csvfile)\n            for row in sample_data:\n                writer.writerow(row)", "DeepSeek-V3-0324_completion_4": "    def create_test_csv(filename):\n        sample_data = [\n            [10, 20, 30],\n            [15, 25, 35],\n            [10, 30, 40],\n            [20, 20, 30]\n        ]\n        with open(filename, 'w', newline='') as csvfile:\n            writer = csv.writer(csvfile)\n            for row in sample_data:\n                writer.writerow(row)", "DeepSeek-V3-0324_completions": ["    def create_test_csv(filename):\n        sample_data = [\n            [10, 20, 30],\n            [15, 25, 35],\n            [10, 30, 40],\n            [20, 20, 30]\n        ]\n        with open(filename, 'w', newline='') as csvfile:\n            writer = csv.writer(csvfile)\n            for row in sample_data:\n                writer.writerow(row)", "    def create_test_csv(filename):\n        sample_data = [\n            [10, 20, 30],\n            [15, 25, 35],\n            [10, 30, 40],\n            [20, 20, 30]\n        ]\n        with open(filename, 'w', newline='') as csvfile:\n            writer = csv.writer(csvfile)\n            for row in sample_data:\n                writer.writerow(row)", "    def create_test_csv(filename):\n        sample_data = [\n            [10, 20, 30],\n            [15, 25, 35],\n            [10, 30, 40],\n            [20, 20, 30]\n        ]\n        with open(filename, 'w', newline='') as csvfile:\n            writer = csv.writer(csvfile)\n            for row in sample_data:\n                writer.writerow(row)", "    def create_test_csv(filename):\n        sample_data = [\n            [10, 20, 30],\n            [15, 25, 35],\n            [10, 30, 40],\n            [20, 20, 30]\n        ]\n        with open(filename, 'w', newline='') as csvfile:\n            writer = csv.writer(csvfile)\n            for row in sample_data:\n                writer.writerow(row)", "    def create_test_csv(filename):\n        sample_data = [\n            [10, 20, 30],\n            [15, 25, 35],\n            [10, 30, 40],\n            [20, 20, 30]\n        ]\n        with open(filename, 'w', newline='') as csvfile:\n            writer = csv.writer(csvfile)\n            for row in sample_data:\n                writer.writerow(row)"]}
{"id": "37", "testsource": "devbench-pattern-matching", "language": "python", "prefix": "class DataCleaner:\n    def __init__(self):\n        self.cleaned_data = []\n\n    def remove_nulls(self, data):\n        cleaned = [item for item in data if item is not None]\n        self.cleaned_data.append(cleaned)\n\n    def remove_empty_strings(self, data):\n        cleaned = [item for item in data if item != '']\n        self.cleaned_data.append(cleaned)\n\n", "suffix": "# Example data for testing\nraw_data = [1, None, '', -5, 2, 'test', -1, 0, 'valid']\n\n# Instantiate the DataCleaner class\ncleaner = DataCleaner()\n\n# Apply the cleaning methods\ncleaner.remove_nulls(raw_data)\ncleaner.remove_empty_strings(raw_data)\ncleaner.remove_negative_numbers(raw_data)\n", "golden_completion": "    def remove_negative_numbers(self, data):\n        cleaned = [item for item in data if not (isinstance(item, (int, float)) and item < 0)]\n        self.cleaned_data.append(cleaned)\n", "LLM_justification": "This example tests the LLM's ability to recognize and complete a pattern in method implementations within a class. The pattern established in the prefix involves cleaning data by removing specific types of undesirable values (nulls, empty strings, negative numbers). The golden completion must adhere to this pattern and correctly implement the `remove_negative_numbers` method. Assertions verify that the methods work as expected and follow the established pattern, ensuring both functional and semantic correctness.", "assertions": "assert cleaner.cleaned_data[0] == [1, '', -5, 2, 'test', -1, 0, 'valid']\nassert cleaner.cleaned_data[1] == [1, None, -5, 2, 'test', -1, 0, 'valid']\nassert cleaner.cleaned_data[2] == [1, None, '', 2, 'test', 0, 'valid']\n", "DeepSeek-V3-0324_completion_0": "    def remove_negative_numbers(self, data):\n        cleaned = [item for item in data if isinstance(item, (int, float)) and item >= 0]\n        self.cleaned_data.append(cleaned)", "DeepSeek-V3-0324_completion_1": "    def remove_negative_numbers(self, data):\n        cleaned = [item for item in data if isinstance(item, (int, float)) and item >= 0]\n        self.cleaned_data.append(cleaned)", "DeepSeek-V3-0324_completion_2": "    def remove_negative_numbers(self, data):\n        cleaned = [item for item in data if isinstance(item, (int, float)) and item >= 0]\n        self.cleaned_data.append(cleaned)", "DeepSeek-V3-0324_completion_3": "    def remove_negative_numbers(self, data):\n        cleaned = [item for item in data if isinstance(item, (int, float)) and item >= 0]\n        self.cleaned_data.append(cleaned)", "DeepSeek-V3-0324_completion_4": "    def remove_negative_numbers(self, data):\n        cleaned = [item for item in data if not isinstance(item, (int, float)) or item >= 0]\n        self.cleaned_data.append(cleaned)", "DeepSeek-V3-0324_completions": ["    def remove_negative_numbers(self, data):\n        cleaned = [item for item in data if isinstance(item, (int, float)) and item >= 0]\n        self.cleaned_data.append(cleaned)", "    def remove_negative_numbers(self, data):\n        cleaned = [item for item in data if isinstance(item, (int, float)) and item >= 0]\n        self.cleaned_data.append(cleaned)", "    def remove_negative_numbers(self, data):\n        cleaned = [item for item in data if isinstance(item, (int, float)) and item >= 0]\n        self.cleaned_data.append(cleaned)", "    def remove_negative_numbers(self, data):\n        cleaned = [item for item in data if isinstance(item, (int, float)) and item >= 0]\n        self.cleaned_data.append(cleaned)", "    def remove_negative_numbers(self, data):\n        cleaned = [item for item in data if not isinstance(item, (int, float)) or item >= 0]\n        self.cleaned_data.append(cleaned)"]}
{"id": "38", "testsource": "devbench-pattern-matching", "language": "python", "prefix": "# Import necessary modules\nimport statistics\n\n# Define a class for analyzing datasets\nclass DataAnalyzer:\n    def __init__(self, data):\n        self.data = data\n\n    def mean(self):\n        return statistics.mean(self.data)\n\n    def median(self):\n        return statistics.median(self.data)\n\n    def variance(self):\n        return statistics.variance(self.data)\n\n    def stdev(self):\n        return statistics.stdev(self.data)\n\n# Example data for testing\nsample_data = [2, 4, 4, 4, 5, 5, 7, 9]\n\n# Create an instance of DataAnalyzer\nanalyzer = DataAnalyzer(sample_data)\n\n# Calculate and print the mean\nprint('Mean:', analyzer.mean())\n\n# Calculate and print the median\nprint('Median:', analyzer.median())\n\n# Calculate and print the variance\nprint('Variance:', analyzer.variance())\n\n# Calculate and print the standard deviation\n", "suffix": "# Clean up resources if needed (not applicable in this simple example)\nprint('Analysis complete.')", "golden_completion": "print('Standard Deviation:', analyzer.stdev())", "LLM_justification": "This test case establishes a clear pattern in the prefix of defining methods for statistical calculations within a DataAnalyzer class, followed by their usage in instance methods. The pattern involves computing and printing various statistical measures (mean, median, variance) from a dataset. The golden completion should follow this established pattern by implementing the calculation and print statement for the standard deviation, ensuring the code remains consistent and functional.", "assertions": "assert analyzer.mean() == 5.0\nassert analyzer.median() == 4.5\nassert analyzer.variance() == 4.571428571428571\nassert analyzer.stdev() == 2.138089935299395", "DeepSeek-V3-0324_completion_0": "print('Standard deviation:', analyzer.stdev())", "DeepSeek-V3-0324_completion_1": "print('Standard Deviation:', analyzer.stdev())", "DeepSeek-V3-0324_completion_2": "print('Standard Deviation:', analyzer.stdev())", "DeepSeek-V3-0324_completion_3": "print('Standard Deviation:', analyzer.stdev())", "DeepSeek-V3-0324_completion_4": "print('Standard Deviation:', analyzer.stdev())", "DeepSeek-V3-0324_completions": ["print('Standard deviation:', analyzer.stdev())", "print('Standard Deviation:', analyzer.stdev())", "print('Standard Deviation:', analyzer.stdev())", "print('Standard Deviation:', analyzer.stdev())", "print('Standard Deviation:', analyzer.stdev())"]}
{"id": "39", "testsource": "devbench-pattern-matching", "language": "python", "prefix": "import numpy as np\nimport matplotlib.pyplot as plt\n\nclass DataAnalyzer:\n    def __init__(self, data):\n        self.data = data\n\n    def calculate_mean(self):\n        return np.mean(self.data)\n\n    def calculate_median(self):\n        return np.median(self.data)\n\n    def calculate_variance(self):\n        return np.var(self.data)\n\n    def plot_histogram(self):\n        plt.hist(self.data)\n        plt.title('Data Histogram')\n        plt.xlabel('Value')\n        plt.ylabel('Frequency')\n", "suffix": "    def plot_boxplot(self):\n        plt.boxplot(self.data)\n        plt.title('Data Boxplot')\n        plt.xlabel('Data')\n        plt.ylabel('Value')\n\n# Example usage\nif __name__ == \"__main__\":\n    data = np.random.randn(100)\n    analyzer = DataAnalyzer(data)\n    mean = analyzer.calculate_mean()\n    median = analyzer.calculate_median()\n    variance = analyzer.calculate_variance()\n    std_dev = analyzer.calculate_standard_deviation()\n    analyzer.plot_histogram()\n    analyzer.plot_boxplot()\n    plt.show()\n", "golden_completion": "    def calculate_standard_deviation(self):\n        return np.std(self.data)\n", "LLM_justification": "This test case evaluates the model's ability to recognize and complete an established pattern in an OOP context within the domain of scientific computing. The prefix defines multiple statistical methods and a plotting method within a class, establishing a clear pattern of statistical computations. The golden completion requires the model to follow this pattern by implementing a new method for standard deviation calculation. Assertions ensure functional correctness and adherence to the pattern.", "assertions": "assert isinstance(analyzer, DataAnalyzer)\nassert mean == np.mean(data)\nassert median == np.median(data)\nassert variance == np.var(data)\nassert std_dev == np.std(data)\n", "DeepSeek-V3-0324_completion_0": "        plt.show()", "DeepSeek-V3-0324_completion_1": "        plt.show()", "DeepSeek-V3-0324_completion_2": "    def calculate_standard_deviation(self):\n        return np.std(self.data)", "DeepSeek-V3-0324_completion_3": "        plt.show()", "DeepSeek-V3-0324_completion_4": "    def calculate_standard_deviation(self):\n        return np.std(self.data)", "DeepSeek-V3-0324_completions": ["        plt.show()", "        plt.show()", "    def calculate_standard_deviation(self):\n        return np.std(self.data)", "        plt.show()", "    def calculate_standard_deviation(self):\n        return np.std(self.data)"]}
{"id": "40", "testsource": "devbench-pattern-matching", "language": "python", "prefix": "import re\n\nclass LogFilter:\n    def __init__(self, pattern):\n        self.pattern = pattern\n\n    def filter(self, log):\n        return re.search(self.pattern, log) is not None\n\nclass LogProcessor:\n    def __init__(self, logs):\n        self.logs = logs\n        self.filters = []\n\n    def add_filter(self, log_filter):\n        self.filters.append(log_filter)\n\n    def process(self):\n        filtered_logs = []\n        for log in self.logs:\n            if any(log_filter.filter(log) for log_filter in self.filters):\n                filtered_logs.append(log)\n        return filtered_logs\n\nlogs = [\n    \"2023-01-01 ERROR Something failed\",\n    \"2023-01-02 INFO Initialization complete\",\n    \"2023-01-03 WARNING Disk space low\",\n    \"2023-01-04 ERROR Unable to connect to database\"\n]\n\nlog_processor = LogProcessor(logs)\nerror_filter = LogFilter(r'ERROR')\nlog_processor.add_filter(error_filter)\n", "suffix": "result = log_processor.process()\n\nassert len(result) == 3\nassert \"2023-01-01 ERROR Something failed\" in result\nassert \"2023-01-03 WARNING Disk space low\" in result\nassert \"2023-01-04 ERROR Unable to connect to database\" in result\n\nlog_processor.add_filter(LogFilter(r'connect'))\nresult = log_processor.process()\n\nassert len(result) == 3\nassert \"2023-01-04 ERROR Unable to connect to database\" in result\n", "golden_completion": "warning_filter = LogFilter(r'WARNING')\nlog_processor.add_filter(warning_filter)\n", "LLM_justification": "This test case is a good example of pattern matching in the context of system operations (logging and monitoring) using OOP patterns. The prefix establishes a clear pattern of creating log filters and adding them to a log processor. The golden_completion follows this pattern by creating another filter and adding it to the processor. The suffix then continues the pattern by applying this logic to validate the filtered logs. This tests the LLM's ability to recognize and continue the established pattern of filtering logs based on patterns using OOP principles.", "assertions": "assert log_processor.filters[-1].pattern == r'connect'\nresult = log_processor.process()\nassert len(result) == 3\n", "DeepSeek-V3-0324_completion_0": "warning_filter = LogFilter(r'WARNING')\nlog_processor.add_filter(warning_filter)\nresult = log_processor.process()", "DeepSeek-V3-0324_completion_1": "warning_filter = LogFilter(r'WARNING')\nlog_processor.add_filter(warning_filter)", "DeepSeek-V3-0324_completion_2": "warning_filter = LogFilter(r'WARNING')\nlog_processor.add_filter(warning_filter)", "DeepSeek-V3-0324_completion_3": "warning_filter = LogFilter(r'WARNING')\nlog_processor.add_filter(warning_filter)", "DeepSeek-V3-0324_completion_4": "warning_filter = LogFilter(r'WARNING')\nlog_processor.add_filter(warning_filter)", "DeepSeek-V3-0324_completions": ["warning_filter = LogFilter(r'WARNING')\nlog_processor.add_filter(warning_filter)\nresult = log_processor.process()", "warning_filter = LogFilter(r'WARNING')\nlog_processor.add_filter(warning_filter)", "warning_filter = LogFilter(r'WARNING')\nlog_processor.add_filter(warning_filter)", "warning_filter = LogFilter(r'WARNING')\nlog_processor.add_filter(warning_filter)", "warning_filter = LogFilter(r'WARNING')\nlog_processor.add_filter(warning_filter)"]}
{"id": "41", "testsource": "devbench-pattern-matching", "language": "python", "prefix": "import logging\nimport random\nimport io\n\nclass SystemMonitor:\n    def __init__(self):\n        self.log_stream = io.StringIO()\n        self.logger = logging.getLogger('SystemMonitor')\n        self.logger.setLevel(logging.INFO)\n        handler = logging.StreamHandler(self.log_stream)\n        handler.setFormatter(logging.Formatter('%(asctime)s - %(levelname)s - %(message)s'))\n        self.logger.addHandler(handler)\n\n    def log_cpu_usage(self):\n        usage = random.uniform(0, 100)\n        self.logger.info('CPU usage: %.2f%%', usage)\n        return usage\n\n    def log_memory_usage(self):\n        usage = random.uniform(0, 100)\n        self.logger.info('Memory usage: %.2f%%', usage)\n        return usage\n\n    def log_disk_usage(self):\n        usage = random.uniform(0, 100)\n        self.logger.info('Disk usage: %.2f%%', usage)\n        return usage\n\n    def log_network_usage(self):\n        usage = random.uniform(0, 100)\n        self.logger.info('Network usage: %.2f%%', usage)\n        return usage\n\n", "suffix": "    def log_temperature(self):\n        temperature = random.uniform(20, 80)\n        self.logger.info('Temperature: %.2f\u00b0C', temperature)\n        return temperature\n\n    def get_log_output(self):\n        return self.log_stream.getvalue()\n\n# Create an instance of SystemMonitor\nmonitor = SystemMonitor()\n\n# Log various system metrics\nmonitor.log_cpu_usage()\nmonitor.log_memory_usage()\nmonitor.log_disk_usage()\nmonitor.log_network_usage()\nmonitor.log_temperature()\n", "golden_completion": "    def log_power_usage(self):\n        usage = random.uniform(0, 100)\n        self.logger.info('Power usage: %.2f%%', usage)\n        return usage\n\n", "LLM_justification": "This example tests the LLM's ability to recognize and complete a pattern in a class method for logging various system metrics. The established pattern includes logging CPU, memory, disk, and network usage. The completion must follow this pattern by adding a method to log power usage, maintaining the same structure and logging format. This tests the LLM's understanding of both OOP patterns and system operations logging.", "assertions": "power_monitor = SystemMonitor()\npower_usage = power_monitor.log_power_usage()\nlog_output = power_monitor.get_log_output()\n\nassert 'Power usage:' in log_output\nassert '%.2f%%' % power_usage in log_output\n\n", "DeepSeek-V3-0324_completion_0": "    def log_temperature(self):\n        temperature = random.uniform(20, 80)\n        self.logger.info('Temperature: %.2f\u00b0C', temperature)\n        return temperature", "DeepSeek-V3-0324_completion_1": "    def log_temperature(self):\n        temperature = random.uniform(20, 80)\n        self.logger.info('Temperature: %.2f\u00b0C', temperature)\n        return temperature", "DeepSeek-V3-0324_completion_2": "    def log_temperature(self):\n        temperature = random.uniform(20, 80)\n        self.logger.info('Temperature: %.2f\u00b0C', temperature)\n        return temperature", "DeepSeek-V3-0324_completion_3": "    def log_temperature(self):\n        temperature = random.uniform(20, 80)\n        self.logger.info('Temperature: %.2f\u00b0C', temperature)\n        return temperature", "DeepSeek-V3-0324_completion_4": "    def log_temperature(self):\n        temperature = random.uniform(20, 80)\n        self.logger.info('Temperature: %.2f\u00b0C', temperature)\n        return temperature", "DeepSeek-V3-0324_completions": ["    def log_temperature(self):\n        temperature = random.uniform(20, 80)\n        self.logger.info('Temperature: %.2f\u00b0C', temperature)\n        return temperature", "    def log_temperature(self):\n        temperature = random.uniform(20, 80)\n        self.logger.info('Temperature: %.2f\u00b0C', temperature)\n        return temperature", "    def log_temperature(self):\n        temperature = random.uniform(20, 80)\n        self.logger.info('Temperature: %.2f\u00b0C', temperature)\n        return temperature", "    def log_temperature(self):\n        temperature = random.uniform(20, 80)\n        self.logger.info('Temperature: %.2f\u00b0C', temperature)\n        return temperature", "    def log_temperature(self):\n        temperature = random.uniform(20, 80)\n        self.logger.info('Temperature: %.2f\u00b0C', temperature)\n        return temperature"]}
{"id": "42", "testsource": "devbench-pattern-matching", "language": "python", "prefix": "import matplotlib.pyplot as plt\nimport numpy as np\n\nclass DataVisualizer:\n    def __init__(self, data):\n        self.data = data\n\n    def plot_line_chart(self):\n        plt.figure(figsize=(10, 5))\n        plt.plot(self.data)\n        plt.title('Line Chart')\n        plt.xlabel('X-axis')\n        plt.ylabel('Y-axis')\n        plt.grid(True)\n        plt.show()\n\n    def plot_bar_chart(self):\n        plt.figure(figsize=(10, 5))\n        plt.bar(range(len(self.data)), self.data)\n        plt.title('Bar Chart')\n        plt.xlabel('X-axis')\n        plt.ylabel('Y-axis')\n        plt.grid(True)\n        plt.show()\n\n    def plot_scatter_chart(self):\n", "suffix": "        plt.title('Scatter Chart')\n        plt.xlabel('X-axis')\n        plt.ylabel('Y-axis')\n        plt.grid(True)\n        plt.show()\n\ndata = np.random.rand(10)\nvisualizer = DataVisualizer(data)\nvisualizer.plot_line_chart()\nvisualizer.plot_bar_chart()\nvisualizer.plot_scatter_chart()\n", "golden_completion": "        plt.figure(figsize=(10, 5))\n        plt.scatter(range(len(self.data)), self.data)\n", "LLM_justification": "This scenario tests the LLM's ability to recognize and complete a pattern in a class that visualizes data using different types of charts. The pattern involves creating different plotting functions within the DataVisualizer class. The golden completion follows the pattern established by the previous methods (plot_line_chart and plot_bar_chart) by adding the missing implementation for the plot_scatter_chart method. This is a good test case because it requires understanding the structure and purpose of the class, the method signature, and the consistent use of the matplotlib library for visualizations.", "assertions": "data = np.random.rand(10)\nvisualizer = DataVisualizer(data)\nvisualizer.plot_scatter_chart()\nassert plt.gcf().number == 1  # Ensure three figures were created\nplt.close('all')  # Cleanup", "DeepSeek-V3-0324_completion_0": "        plt.figure(figsize=(10, 5))\n        plt.scatter(range(len(self.data)), self.data)", "DeepSeek-V3-0324_completion_1": "        plt.figure(figsize=(10, 5))\n        plt.scatter(range(len(self.data)), self.data)", "DeepSeek-V3-0324_completion_2": "        plt.figure(figsize=(10, 5))\n        plt.scatter(range(len(self.data)), self.data)", "DeepSeek-V3-0324_completion_3": "        plt.figure(figsize=(10, 5))\n        plt.scatter(range(len(self.data)), self.data)", "DeepSeek-V3-0324_completion_4": "        plt.figure(figsize=(10, 5))\n        plt.scatter(range(len(self.data)), self.data)", "DeepSeek-V3-0324_completions": ["        plt.figure(figsize=(10, 5))\n        plt.scatter(range(len(self.data)), self.data)", "        plt.figure(figsize=(10, 5))\n        plt.scatter(range(len(self.data)), self.data)", "        plt.figure(figsize=(10, 5))\n        plt.scatter(range(len(self.data)), self.data)", "        plt.figure(figsize=(10, 5))\n        plt.scatter(range(len(self.data)), self.data)", "        plt.figure(figsize=(10, 5))\n        plt.scatter(range(len(self.data)), self.data)"]}
{"id": "43", "testsource": "devbench-pattern-matching", "language": "python", "prefix": "import matplotlib.pyplot as plt\nimport numpy as np\n\nclass AnalyticsReport:\n    def __init__(self, data):\n        self.data = data\n\n    def generate_histogram(self, column):\n        plt.hist(self.data[column], bins=10, alpha=0.75)\n        plt.title(f'Histogram of {column}')\n        plt.xlabel(column)\n        plt.ylabel('Frequency')\n        plt.grid(True)\n\n    def generate_line_chart(self, x_column, y_column):\n        plt.plot(self.data[x_column], self.data[y_column], marker='o', linestyle='-')\n        plt.title(f'Line Chart of {y_column} vs {x_column}')\n        plt.xlabel(x_column)\n        plt.ylabel(y_column)\n        plt.grid(True)\n\n", "suffix": "\n    def generate_scatter_plot(self, x_column, y_column):\n        plt.scatter(self.data[x_column], self.data[y_column], alpha=0.75)\n        plt.title(f'Scatter Plot of {y_column} vs {x_column}')\n        plt.xlabel(x_column)\n        plt.ylabel(y_column)\n        plt.grid(True)\n\n# Example usage\nif __name__ == '__main__':\n    data = {\n        'age': np.random.randint(20, 50, size=100),\n        'height': np.random.randint(150, 200, size=100),\n        'weight': np.random.randint(50, 100, size=100)\n    }\n    report = AnalyticsReport(data)\n    report.generate_histogram('age')\n    report.generate_line_chart('height', 'weight')\n    plt.show()", "golden_completion": "    def generate_bar_chart(self, x_column, y_column):\n        plt.bar(self.data[x_column], self.data[y_column], alpha=0.75)\n        plt.title(f'Bar Chart of {y_column} vs {x_column}')\n        plt.xlabel(x_column)\n        plt.ylabel(y_column)\n        plt.grid(True)\n\n", "LLM_justification": "This test case is designed to evaluate the ability to recognize and continue a pattern of generating different types of charts using matplotlib within a class. The pattern established in the prefix involves methods that generate specific types of charts (histogram and line chart) with a consistent structure. The golden completion requires the addition of a method to generate a bar chart, following the same pattern. This ensures the LLM understands the pattern of chart generation methods and can extend it appropriately. The suffix then introduces a different method (scatter plot) to ensure the pattern is followed correctly without duplicating the golden completion.", "assertions": "data = {\n    'age': np.random.randint(20, 50, size=100),\n    'height': np.random.randint(150, 200, size=100),\n    'weight': np.random.randint(50, 100, size=100)\n}\nreport = AnalyticsReport(data)\nreport.generate_bar_chart('age', 'weight')\nassert hasattr(report, 'generate_bar_chart')\nassert callable(getattr(report, 'generate_bar_chart'))\nassert plt.gcf().get_axes()[-1].get_title() == 'Bar Chart of weight vs age'\nplt.close('all')", "DeepSeek-V3-0324_completion_0": "    def generate_scatter_plot(self, x_column, y_column):\n        plt.scatter(self.data[x_column], self.data[y_column], alpha=0.75)\n        plt.title(f'Scatter Plot of {y_column} vs {x_column}')\n        plt.xlabel(x_column)\n        plt.ylabel(y_column)\n        plt.grid(True)", "DeepSeek-V3-0324_completion_1": "    def generate_scatter_plot(self, x_column, y_column):\n        plt.scatter(self.data[x_column], self.data[y_column], alpha=0.75)\n        plt.title(f'Scatter Plot of {y_column} vs {x_column}')\n        plt.xlabel(x_column)\n        plt.ylabel(y_column)\n        plt.grid(True)", "DeepSeek-V3-0324_completion_2": "    def generate_scatter_plot(self, x_column, y_column):\n        plt.scatter(self.data[x_column], self.data[y_column], alpha=0.75)\n        plt.title(f'Scatter Plot of {y_column} vs {x_column}')\n        plt.xlabel(x_column)\n        plt.ylabel(y_column)\n        plt.grid(True)", "DeepSeek-V3-0324_completion_3": "    def generate_scatter_plot(self, x_column, y_column):\n        plt.scatter(self.data[x_column], self.data[y_column], alpha=0.75)\n        plt.title(f'Scatter Plot of {y_column} vs {x_column}')\n        plt.xlabel(x_column)\n        plt.ylabel(y_column)\n        plt.grid(True)", "DeepSeek-V3-0324_completion_4": "    def generate_scatter_plot(self, x_column, y_column):\n        plt.scatter(self.data[x_column], self.data[y_column], alpha=0.75)\n        plt.title(f'Scatter Plot of {y_column} vs {x_column}')\n        plt.xlabel(x_column)\n        plt.ylabel(y_column)\n        plt.grid(True)", "DeepSeek-V3-0324_completions": ["    def generate_scatter_plot(self, x_column, y_column):\n        plt.scatter(self.data[x_column], self.data[y_column], alpha=0.75)\n        plt.title(f'Scatter Plot of {y_column} vs {x_column}')\n        plt.xlabel(x_column)\n        plt.ylabel(y_column)\n        plt.grid(True)", "    def generate_scatter_plot(self, x_column, y_column):\n        plt.scatter(self.data[x_column], self.data[y_column], alpha=0.75)\n        plt.title(f'Scatter Plot of {y_column} vs {x_column}')\n        plt.xlabel(x_column)\n        plt.ylabel(y_column)\n        plt.grid(True)", "    def generate_scatter_plot(self, x_column, y_column):\n        plt.scatter(self.data[x_column], self.data[y_column], alpha=0.75)\n        plt.title(f'Scatter Plot of {y_column} vs {x_column}')\n        plt.xlabel(x_column)\n        plt.ylabel(y_column)\n        plt.grid(True)", "    def generate_scatter_plot(self, x_column, y_column):\n        plt.scatter(self.data[x_column], self.data[y_column], alpha=0.75)\n        plt.title(f'Scatter Plot of {y_column} vs {x_column}')\n        plt.xlabel(x_column)\n        plt.ylabel(y_column)\n        plt.grid(True)", "    def generate_scatter_plot(self, x_column, y_column):\n        plt.scatter(self.data[x_column], self.data[y_column], alpha=0.75)\n        plt.title(f'Scatter Plot of {y_column} vs {x_column}')\n        plt.xlabel(x_column)\n        plt.ylabel(y_column)\n        plt.grid(True)"]}
{"id": "44", "testsource": "devbench-pattern-matching", "language": "python", "prefix": "import matplotlib.pyplot as plt\n\nclass DataVisualizer:\n    def __init__(self, data):\n        self.data = data\n\n    def plot_bar_chart(self, title, xlabel, ylabel):\n        plt.figure(figsize=(10, 5))\n        plt.bar(self.data.keys(), self.data.values())\n        plt.title(title)\n        plt.xlabel(xlabel)\n        plt.ylabel(ylabel)\n        plt.show()\n\n    def plot_line_chart(self, title, xlabel, ylabel):\n        plt.figure(figsize=(10, 5))\n        plt.plot(list(self.data.keys()), list(self.data.values()), marker='o')\n        plt.title(title)\n        plt.xlabel(xlabel)\n        plt.ylabel(ylabel)\n        plt.show()\n\n    def plot_pie_chart(self, title):\n        plt.figure(figsize=(10, 5))\n        plt.pie(self.data.values(), labels=self.data.keys(), autopct='%1.1f%%')\n        plt.title(title)\n        plt.show()\n\n# Usage example\nif __name__ == '__main__':\n    data = {'A': 10, 'B': 20, 'C': 30, 'D': 40}\n    visualizer = DataVisualizer(data)\n", "suffix": "    visualizer.plot_pie_chart('Pie Chart Example')\n\n    # Clean up resources\n    plt.close('all')\n", "golden_completion": "    visualizer.plot_line_chart('Line Chart Example', 'Categories', 'Values')\n", "LLM_justification": "This example tests the ability to recognize and continue a pattern of creating chart plotting methods in a DataVisualizer class, and using these methods in a consistent manner. The prefix establishes a pattern by defining several methods for plotting different types of charts (bar, line, pie). The golden completion follows this pattern by adding a call to the line chart plotting method before calling the pie chart method in the suffix. The task requires understanding the pattern of method definitions and their usage, which is common in data visualization tasks.", "assertions": "assert hasattr(DataVisualizer, 'plot_bar_chart')\nassert hasattr(DataVisualizer, 'plot_line_chart')\nassert hasattr(DataVisualizer, 'plot_pie_chart')\nassert visualizer.plot_line_chart('Line Chart Example', 'Categories', 'Values') is None\n", "DeepSeek-V3-0324_completion_0": "    visualizer.plot_bar_chart('Bar Chart Example', 'Categories', 'Values')\n    visualizer.plot_line_chart('Line Chart Example', 'Categories', 'Values')", "DeepSeek-V3-0324_completion_1": "    visualizer.plot_bar_chart('Bar Chart Example', 'Categories', 'Values')\n    visualizer.plot_line_chart('Line Chart Example', 'Categories', 'Values')", "DeepSeek-V3-0324_completion_2": "    visualizer.plot_bar_chart('Bar Chart Example', 'Categories', 'Values')\n    visualizer.plot_line_chart('Line Chart Example', 'Categories', 'Values')", "DeepSeek-V3-0324_completion_3": "    visualizer.plot_bar_chart('Bar Chart Example', 'Categories', 'Values')\n    visualizer.plot_line_chart('Line Chart Example', 'Categories', 'Values')", "DeepSeek-V3-0324_completion_4": "    visualizer.plot_bar_chart('Bar Chart Example', 'Categories', 'Values')\n    visualizer.plot_line_chart('Line Chart Example', 'Categories', 'Values')", "DeepSeek-V3-0324_completions": ["    visualizer.plot_bar_chart('Bar Chart Example', 'Categories', 'Values')\n    visualizer.plot_line_chart('Line Chart Example', 'Categories', 'Values')", "    visualizer.plot_bar_chart('Bar Chart Example', 'Categories', 'Values')\n    visualizer.plot_line_chart('Line Chart Example', 'Categories', 'Values')", "    visualizer.plot_bar_chart('Bar Chart Example', 'Categories', 'Values')\n    visualizer.plot_line_chart('Line Chart Example', 'Categories', 'Values')", "    visualizer.plot_bar_chart('Bar Chart Example', 'Categories', 'Values')\n    visualizer.plot_line_chart('Line Chart Example', 'Categories', 'Values')", "    visualizer.plot_bar_chart('Bar Chart Example', 'Categories', 'Values')\n    visualizer.plot_line_chart('Line Chart Example', 'Categories', 'Values')"]}
{"id": "45", "testsource": "devbench-pattern-matching", "language": "python", "prefix": "import matplotlib.pyplot as plt\nimport numpy as np\n\nclass DataVisualizer:\n    def __init__(self, data):\n        self.data = data\n\n    def plot_line_chart(self, title, xlabel, ylabel):\n        plt.figure(figsize=(10, 5))\n        plt.plot(self.data)\n        plt.title(title)\n        plt.xlabel(xlabel)\n        plt.ylabel(ylabel)\n        plt.grid(True)\n        plt.show()\n\n    def plot_bar_chart(self, title, xlabel, ylabel):\n        plt.figure(figsize=(10, 5))\n        plt.bar(range(len(self.data)), self.data)\n        plt.title(title)\n        plt.xlabel(xlabel)\n        plt.ylabel(ylabel)\n        plt.grid(True)\n        plt.show()\n\n    def plot_scatter_chart(self, title, xlabel, ylabel):\n        plt.figure(figsize=(10, 5))\n        plt.scatter(range(len(self.data)), self.data)\n        plt.title(title)\n        plt.xlabel(xlabel)\n        plt.ylabel(ylabel)\n        plt.grid(True)\n", "suffix": "        plt.show()\n\n# Usage example\ndata = np.random.rand(100)\nvisualizer = DataVisualizer(data)\nvisualizer.plot_line_chart('Line Chart', 'X-axis', 'Y-axis')\nvisualizer.plot_bar_chart('Bar Chart', 'X-axis', 'Y-axis')\nvisualizer.plot_scatter_chart('Scatter Chart', 'X-axis', 'Y-axis')\n\n# Assertions\ndata = np.array([1, 2, 3, 4, 5])\nvisualizer = DataVisualizer(data)\ntry:\n    visualizer.plot_pie_chart('Pie Chart')\nexcept AttributeError:\n    pass # Expected, as plot_pie_chart is not defined\n", "golden_completion": "    def plot_histogram(self, title, xlabel, ylabel):\n        plt.figure(figsize=(10, 5))\n        plt.hist(self.data, bins=10)\n        plt.title(title)\n        plt.xlabel(xlabel)\n        plt.ylabel(ylabel)\n        plt.grid(True)\n", "LLM_justification": "This test case is a good example of pattern matching because it requires the LLM to recognize the repetitive structure of the plotting methods within the DataVisualizer class. The pattern involves creating a plot with specific attributes (title, xlabel, ylabel), configuring the figure, and displaying the plot. The golden completion follows this established pattern to add a new method for plotting a histogram. The assertions ensure that the new method fits seamlessly into the class and behaves as expected.", "assertions": "import numpy as np\n\n# Test data\nsample_data = np.random.rand(50)\nvisualizer = DataVisualizer(sample_data)\n\n# Test the new method\ntry:\n    visualizer.plot_histogram('Histogram', 'Bins', 'Frequency')\nexcept Exception as e:\n    assert False, f'plot_histogram raised an exception: {e}'\n\n# Validate the method is added correctly and callable\nassert hasattr(visualizer, 'plot_histogram'), 'plot_histogram method is not defined'\nassert callable(getattr(visualizer, 'plot_histogram')), 'plot_histogram is not callable'\n", "DeepSeek-V3-0324_completion_0": "        plt.show()", "DeepSeek-V3-0324_completion_1": "        plt.show()", "DeepSeek-V3-0324_completion_2": "        plt.show()", "DeepSeek-V3-0324_completion_3": "        plt.show()", "DeepSeek-V3-0324_completion_4": "        plt.show()", "DeepSeek-V3-0324_completions": ["        plt.show()", "        plt.show()", "        plt.show()", "        plt.show()", "        plt.show()"]}
{"id": "46", "testsource": "devbench-pattern-matching", "language": "python", "prefix": "import cv2\nimport numpy as np\nimport os\nimport time\n\n# Define a decorator to measure the execution time of functions\ndef timeit(func):\n    def wrapper(*args, **kwargs):\n        start_time = time.time()\n        result = func(*args, **kwargs)\n        end_time = time.time()\n        print(f\"Function {func.__name__} took {end_time - start_time:.4f} seconds\")\n        return result\n    return wrapper\n\n# Define a media processing function to apply a Gaussian blur to an image\n@timeit\ndef apply_gaussian_blur(image_path, kernel_size):\n    image = cv2.imread(image_path)\n    if image is None:\n        raise ValueError(f\"Image at path {image_path} could not be loaded.\")\n    blurred_image = cv2.GaussianBlur(image, (kernel_size, kernel_size), 0)\n    return blurred_image\n\n# Define another media processing function to convert an image to grayscale\n@timeit\ndef convert_to_grayscale(image_path):\n    image = cv2.imread(image_path)\n    if image is None:\n        raise ValueError(f\"Image at path {image_path} could not be loaded.\")\n    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n    return gray_image\n\n# Define a function to resize an image while keeping the aspect ratio\n@timeit\ndef resize_image(image_path, width):\n    image = cv2.imread(image_path)\n    if image is None:\n        raise ValueError(f\"Image at path {image_path} could not be loaded.\")\n    aspect_ratio = image.shape[1] / image.shape[0]\n    new_height = int(width / aspect_ratio)\n    resized_image = cv2.resize(image, (width, new_height))\n    return resized_image\n\ndef create_sample_image(filename, width=300, height=200):\n    image = np.zeros((height, width, 3), dtype=np.uint8)\n    for i in range(height):\n        for j in range(width):\n            b = int(255 * (1 - j / width))\n            r = int(255 * (j / width))\n            image[i, j] = [b, 0, r]\n\n    cv2.imwrite(filename, image)\n    return image\n\n# Example usage of the functions\nimage_path = 'example.jpg'\ncreate_sample_image(image_path)\nprint(f\"Created sample image at {image_path}\")\n\ntry:\n    blurred_image = apply_gaussian_blur(image_path, 5)\n    gray_image = convert_to_grayscale(image_path)\n", "suffix": "    original_image = cv2.imread(image_path)\n    if original_image is None:\n        raise ValueError(f\"Image at path {image_path} could not be loaded.\")\n    rotated_image = cv2.rotate(original_image, cv2.ROTATE_90_CLOCKWISE)\n    print(\"Image rotated successfully.\")\n\n    cv2.imwrite('blurred_example.jpg', blurred_image)\n    cv2.imwrite('gray_example.jpg', gray_image)\n    cv2.imwrite('resized_example.jpg', resized_image)\n    cv2.imwrite('resized_example.jpg', resized_image)\n\n    assert blurred_image is not None\n    assert gray_image is not None\n    assert resized_image is not None\n    assert resized_image.shape[1] == 100\n    assert cv2.imread('resized_example.jpg') is not None\n\n    print(\"All tests passed successfully.\")\n\nexcept ValueError as e:\n    print(e)\nfinally:\n    for file in ['example.jpg', 'blurred_example.jpg', 'gray_example.jpg', 'resized_example.jpg', 'rotated_example.jpg']:\n        if os.path.exists(file):\n            os.remove(file)\n            print(f\"Removed file: {file}\")\n", "golden_completion": "    resized_image = resize_image(image_path, 100)\n", "LLM_justification": "This test case is designed to evaluate the LLM's ability to recognize and continue a pattern involving media processing functions wrapped with a decorator for measuring execution time. The prefix establishes a clear pattern by defining multiple decorated functions for different image processing tasks, and the golden completion follows this pattern by adding another function call that matches the established pattern. The suffix continues the usage of processed images, further validating the pattern. This scenario is realistic for developers working on media processing tasks and tests the model's ability to adhere to established patterns in a practical context.", "assertions": "", "DeepSeek-V3-0324_completion_0": "    resized_image = resize_image(image_path, 100)\n    original_image = cv2.imread(image_path)", "DeepSeek-V3-0324_completion_1": "    resized_image = resize_image(image_path, 100)", "DeepSeek-V3-0324_completion_2": "    resized_image = resize_image(image_path, 100)\n    original_image = cv2.imread(image_path)\n    if original_image is None:\n        raise ValueError(f\"Image at path {image_path} could not be loaded.\")\n    rotated_image = cv2.rotate(original_image, cv2.ROTATE_90_CLOCKWISE)\n    print(\"Image rotated successfully.\")", "DeepSeek-V3-0324_completion_3": "    resized_image = resize_image(image_path, 100)\n    original_image = cv2.imread(image_path)", "DeepSeek-V3-0324_completion_4": "    resized_image = resize_image(image_path, 100)\n    original_image = cv2.imread(image_path)", "DeepSeek-V3-0324_completions": ["    resized_image = resize_image(image_path, 100)\n    original_image = cv2.imread(image_path)", "    resized_image = resize_image(image_path, 100)", "    resized_image = resize_image(image_path, 100)\n    original_image = cv2.imread(image_path)\n    if original_image is None:\n        raise ValueError(f\"Image at path {image_path} could not be loaded.\")\n    rotated_image = cv2.rotate(original_image, cv2.ROTATE_90_CLOCKWISE)\n    print(\"Image rotated successfully.\")", "    resized_image = resize_image(image_path, 100)\n    original_image = cv2.imread(image_path)", "    resized_image = resize_image(image_path, 100)\n    original_image = cv2.imread(image_path)"]}
{"id": "47", "testsource": "devbench-pattern-matching", "language": "python", "prefix": "import time\n\nclass EventListener:\n    def __init__(self):\n        self.handlers = []\n\n    def register_handler(self, handler):\n        self.handlers.append(handler)\n\n    def trigger_event(self, event):\n        for handler in self.handlers:\n            handler(event)\n\nclass MediaProcessor:\n    def __init__(self):\n        self.event_listener = EventListener()\n\n    def register_event_handler(self, handler):\n        self.event_listener.register_handler(handler)\n\n    def process_audio(self, audio_data):\n        print(\"Processing audio...\")\n        time.sleep(1)  # Simulate processing delay\n        self.event_listener.trigger_event({'type': 'audio', 'data': audio_data})\n\n    def process_video(self, video_data):\n        print(\"Processing video...\")\n        time.sleep(1)  # Simulate processing delay\n        self.event_listener.trigger_event({'type': 'video', 'data': video_data})\n\n    def process_image(self, image_data):\n", "suffix": "# Example usage\nmedia_processor = MediaProcessor()\n\n# Mock handlers to verify event triggering\naudio_event_triggered = False\nvideo_event_triggered = False\nimage_event_triggered = False\n\ndef audio_handler(event):\n    global audio_event_triggered\n    if event['type'] == 'audio':\n        audio_event_triggered = True\n\n\ndef video_handler(event):\n    global video_event_triggered\n    if event['type'] == 'video':\n        video_event_triggered = True\n\n\ndef image_handler(event):\n    global image_event_triggered\n    if event['type'] == 'image':\n        image_event_triggered = True\n\nmedia_processor.register_event_handler(audio_handler)\nmedia_processor.register_event_handler(video_handler)\nmedia_processor.register_event_handler(image_handler)\n\nmedia_processor.process_audio('audio_data')\nmedia_processor.process_video('video_data')\nmedia_processor.process_image('image_data')\n\nassert audio_event_triggered == True\nassert video_event_triggered == True\nassert image_event_triggered == True\n", "golden_completion": "        print(\"Processing image...\")\n        time.sleep(1)  # Simulate processing delay\n        self.event_listener.trigger_event({'type': 'image', 'data': image_data})\n", "LLM_justification": "This test case is a good example of pattern matching in the context of event handling within a media processing application. The pattern established in the prefix is the processing of different media types (audio, video) and triggering corresponding events. The `golden_completion` requires recognizing this pattern and correctly implementing the processing of image data, including the consistent triggering of an event. The assertions verify that the event handling mechanism works correctly for all media types, ensuring that the pattern is followed accurately.", "assertions": "assert audio_event_triggered == True\nassert video_event_triggered == True\nassert image_event_triggered == True\n", "DeepSeek-V3-0324_completion_0": "        print(\"Processing image...\")\n        time.sleep(1)  # Simulate processing delay\n        self.event_listener.trigger_event({'type': 'image', 'data': image_data})", "DeepSeek-V3-0324_completion_1": "        print(\"Processing image...\")\n        time.sleep(1)  # Simulate processing delay\n        self.event_listener.trigger_event({'type': 'image', 'data': image_data})", "DeepSeek-V3-0324_completion_2": "        print(\"Processing image...\")\n        time.sleep(1)  # Simulate processing delay\n        self.event_listener.trigger_event({'type': 'image', 'data': image_data})", "DeepSeek-V3-0324_completion_3": "        print(\"Processing image...\")\n        time.sleep(1)  # Simulate processing delay\n        self.event_listener.trigger_event({'type': 'image', 'data': image_data})", "DeepSeek-V3-0324_completion_4": "        print(\"Processing image...\")\n        time.sleep(1)  # Simulate processing delay\n        self.event_listener.trigger_event({'type': 'image', 'data': image_data})", "DeepSeek-V3-0324_completions": ["        print(\"Processing image...\")\n        time.sleep(1)  # Simulate processing delay\n        self.event_listener.trigger_event({'type': 'image', 'data': image_data})", "        print(\"Processing image...\")\n        time.sleep(1)  # Simulate processing delay\n        self.event_listener.trigger_event({'type': 'image', 'data': image_data})", "        print(\"Processing image...\")\n        time.sleep(1)  # Simulate processing delay\n        self.event_listener.trigger_event({'type': 'image', 'data': image_data})", "        print(\"Processing image...\")\n        time.sleep(1)  # Simulate processing delay\n        self.event_listener.trigger_event({'type': 'image', 'data': image_data})", "        print(\"Processing image...\")\n        time.sleep(1)  # Simulate processing delay\n        self.event_listener.trigger_event({'type': 'image', 'data': image_data})"]}
{"id": "48", "testsource": "devbench-pattern-matching", "language": "python", "prefix": "import time\nimport random\n\nclass EventListener:\n    def __init__(self):\n        self.handlers = []\n\n    def register_handler(self, handler):\n        self.handlers.append(handler)\n\n    def notify(self, event):\n        for handler in self.handlers:\n            handler(event)\n\nclass EventGenerator:\n    def __init__(self, listener):\n        self.listener = listener\n\n    def generate_events(self):\n        for i in range(3):\n            event = {'type': 'event_{}'.format(i), 'timestamp': time.time(), 'value': random.randint(1, 100)}\n            self.listener.notify(event)\n            time.sleep(1)\n\n# Setup event listener and generator\nlistener = EventListener()\n\n# Register handlers\nlistener.register_handler(lambda event: print('Handler 1 received:', event))\nlistener.register_handler(lambda event: print('Handler 2 received:', event))\n\n# Create event generator\ngenerator = EventGenerator(listener)\n\n# Start generating events\ngenerator.generate_events()\n", "suffix": "assert len(listener.handlers) == 3, 'There should be exactly three handlers registered'\nassert all(callable(handler) for handler in listener.handlers), 'All handlers should be callable'\n", "golden_completion": "listener.register_handler(lambda event: print('Handler 3 received:', event))\ngenerator.generate_events()\n", "LLM_justification": "This test case is a good example of event handling in the context of media processing. It involves setting up an event listener and generator, registering multiple handlers, and ensuring the handlers are called correctly when events are generated. The pattern of registering handlers and generating events is clearly established in the prefix. The golden completion follows this pattern by adding a new handler and generating events again. The assertions check that the correct number of handlers are registered and that they are all callable, ensuring the pattern is adhered to and the functionality is correct.", "assertions": "assert len(listener.handlers) == 3, 'There should be exactly three handlers registered'\nassert all(callable(handler) for handler in listener.handlers), 'All handlers should be callable'\n", "DeepSeek-V3-0324_completion_0": "listener.register_handler(lambda event: print('Handler 3 received:', event))", "DeepSeek-V3-0324_completion_1": "listener.register_handler(lambda event: print('Handler 3 received:', event))", "DeepSeek-V3-0324_completion_2": "listener.register_handler(lambda event: print('Handler 3 received:', event))", "DeepSeek-V3-0324_completion_3": "listener.register_handler(lambda event: print('Handler 3 received:', event))", "DeepSeek-V3-0324_completion_4": "listener.register_handler(lambda event: print('Handler 3 received:', event))", "DeepSeek-V3-0324_completions": ["listener.register_handler(lambda event: print('Handler 3 received:', event))", "listener.register_handler(lambda event: print('Handler 3 received:', event))", "listener.register_handler(lambda event: print('Handler 3 received:', event))", "listener.register_handler(lambda event: print('Handler 3 received:', event))", "listener.register_handler(lambda event: print('Handler 3 received:', event))"]}
{"id": "49", "testsource": "devbench-pattern-matching", "language": "python", "prefix": "class GameCharacter:\n    def __init__(self, name, health):\n        self.name = name\n        self.health = health\n        self.state = 'idle'\n\n    def idle(self):\n        self.state = 'idle'\n        print(f'{self.name} is now idling.')\n\n    def move(self):\n        self.state = 'moving'\n        print(f'{self.name} is now moving.')\n\n    def attack(self):\n        self.state = 'attacking'\n        print(f'{self.name} is attacking!')\n\n    def take_damage(self, amount):\n        self.health -= amount\n        print(f'{self.name} took {amount} damage. Health is now {self.health}.')\n\n    def update(self):\n        if self.state == 'idle':\n            self.idle()\n        elif self.state == 'moving':\n            self.move()\n        elif self.state == 'attacking':\n            self.attack()\n        else:\n            print(f'{self.name} is in an unknown state: {self.state}')\n\n# Test the GameCharacter class\ncharacter = GameCharacter('Hero', 100)\ncharacter.update()\ncharacter.state = 'moving'\ncharacter.update()\ncharacter.state = 'attacking'\ncharacter.update()\ncharacter.take_damage(10)\n", "suffix": "# Cleanup resources if needed\n# Here no explicit cleanup is required as we are not using external resources\n# The assertions are placed before any hypothetical cleanup\n", "golden_completion": "character.state = 'idle'\ncharacter.update()\n", "LLM_justification": "This example tests the model's ability to recognize and complete a state machine pattern in a game mechanics context. The prefix establishes a clear pattern where the character's state is updated based on the current state. The completion requires the model to continue this pattern by setting the state and calling the update method. The suffix completes the scenario without repeating the golden completion.", "assertions": "assert character.state == 'idle'\nassert character.health == 90\n", "DeepSeek-V3-0324_completion_0": "character.state = 'idle'\ncharacter.update()", "DeepSeek-V3-0324_completion_1": "character.state = 'idle'\ncharacter.update()", "DeepSeek-V3-0324_completion_2": "character.state = 'idle'\ncharacter.update()", "DeepSeek-V3-0324_completion_3": "character.state = 'idle'\ncharacter.update()", "DeepSeek-V3-0324_completion_4": "character.state = 'idle'\ncharacter.update()", "DeepSeek-V3-0324_completions": ["character.state = 'idle'\ncharacter.update()", "character.state = 'idle'\ncharacter.update()", "character.state = 'idle'\ncharacter.update()", "character.state = 'idle'\ncharacter.update()", "character.state = 'idle'\ncharacter.update()"]}
{"id": "50", "testsource": "devbench-pattern-matching", "language": "python", "prefix": "import time\n\nclass GameEvent:\n    def __init__(self, name):\n        self.name = name\n\nclass EventHandler:\n    def __init__(self):\n        self.events = []\n\n    def register_event(self, event):\n        print(f\"Registering event: {event.name}\")\n        self.events.append(event)\n\n    def process_events(self):\n        while self.events:\n            event = self.events.pop(0)\n            print(f\"Processing event: {event.name}\")\n            time.sleep(1)\n\nhandler = EventHandler()\nhandler.register_event(GameEvent(\"Start\"))\nhandler.register_event(GameEvent(\"Move\"))\nhandler.register_event(GameEvent(\"Attack\"))\n", "suffix": "handler.process_events()\nprint(\"All events processed.\")\n", "golden_completion": "handler.register_event(GameEvent(\"Defend\"))\n", "LLM_justification": "This example tests the LLM's ability to recognize and complete a pattern of event registration in a game event handler context. The pattern involves creating a GameEvent object and registering it with the EventHandler. The golden completion correctly follows this pattern by registering a new event, 'Defend', which fits the established sequence of events ('Start', 'Move', 'Attack'). This ensures that the model understands both the technical pattern of event handling and the domain context of game mechanics.", "assertions": "assert len(handler.events) == 0\n", "DeepSeek-V3-0324_completion_0": "handler.register_event(GameEvent(\"End\"))", "DeepSeek-V3-0324_completion_1": "handler.process_events()", "DeepSeek-V3-0324_completion_2": "handler.process_events()", "DeepSeek-V3-0324_completion_3": "handler.process_events()", "DeepSeek-V3-0324_completion_4": "handler.process_events()", "DeepSeek-V3-0324_completions": ["handler.register_event(GameEvent(\"End\"))", "handler.process_events()", "handler.process_events()", "handler.process_events()", "handler.process_events()"]}
